From c974d834ec6d1026ecbe045a86dcaf5e84c681de Mon Sep 17 00:00:00 2001
From: Munehisa Kamata <kamatam@amazon.com>
Date: Fri, 6 May 2016 18:23:00 +0000
Subject: amazon/net/ena: update to 0.6.4

Signed-off-by: Munehisa Kamata <kamatam@amazon.com>
Reviewed-by: Jonghun Yoo <jhyoo@amazon.de>
Reviewed-by: Imre Palik <imrep@amazon.de>
Reviewed-by: Netanel Belgazal <netanel@annapurnalabs.com>
Reviewed-by: Jesus Velazquez Reyes <jesuv@amazon.com>

CR: https://cr.amazon.com/r/5232617/
---
 drivers/amazon/net/ena/ena_admin_defs.h |  28 +-----
 drivers/amazon/net/ena/ena_com.h        |   2 +-
 drivers/amazon/net/ena/ena_eth_com.c    |   2 +-
 drivers/amazon/net/ena/ena_ethtool.c    |   3 +-
 drivers/amazon/net/ena/ena_netdev.c     | 161 +++++++++++++++++++++-----------
 drivers/amazon/net/ena/ena_netdev.h     |  29 ++++--
 6 files changed, 129 insertions(+), 96 deletions(-)

diff --git a/drivers/amazon/net/ena/ena_admin_defs.h b/drivers/amazon/net/ena/ena_admin_defs.h
index e0dc371..e687b3b 100644
--- a/drivers/amazon/net/ena/ena_admin_defs.h
+++ b/drivers/amazon/net/ena/ena_admin_defs.h
@@ -114,20 +114,6 @@ enum ena_admin_aq_feature_id {
 	/* max number of supported queues per for every queues type */
 	ENA_ADMIN_MAX_QUEUES_NUM = 2,
 
-	/* low latency queues capabilities (max entry size, depth) */
-	ENA_ADMIN_LLQ_CONFIG = 3,
-
-	/* power management capabilities */
-	ENA_ADMIN_POWER_MANAGEMENT_CONFIG = 4,
-
-	/* MAC address filters support, multicast, broadcast, and
-	 * promiscuous
-	 */
-	ENA_ADMIN_MAC_FILTERS_CONFIG = 5,
-
-	/* VLAN membership, frame format, etc.  */
-	ENA_ADMIN_VLAN_CONFIG = 6,
-
 	/* Receive Side Scaling (RSS) function */
 	ENA_ADMIN_RSS_HASH_FUNCTION = 10,
 
@@ -143,20 +129,9 @@ enum ena_admin_aq_feature_id {
 	/* Receive Side Scaling (RSS) hash input */
 	ENA_ADMIN_RSS_HASH_INPUT = 18,
 
-	/* overlay tunnels configuration */
-	ENA_ADMIN_TUNNEL_CONFIG = 19,
-
 	/* interrupt moderation parameters */
 	ENA_ADMIN_INTERRUPT_MODERATION = 20,
 
-	/* 1588v2 and Timing configuration */
-	ENA_ADMIN_1588_CONFIG = 21,
-
-	/* Packet Header format templates configuration for input and
-	 * output parsers
-	 */
-	ENA_ADMIN_PKT_HEADER_TEMPLATES_CONFIG = 23,
-
 	/* AENQ configuration */
 	ENA_ADMIN_AENQ_CONFIG = 26,
 
@@ -508,7 +483,8 @@ struct ena_admin_acq_create_cq_resp_desc {
 	/* cq identifier */
 	u16 cq_idx;
 
-	u16 reserved;
+	/* actual cq depth in # of entries */
+	u16 cq_actual_depth;
 
 	/* word 3 : cpu numa node address as an offset to PCIe MMIO REG BAR */
 	u32 numa_node_register_offset;
diff --git a/drivers/amazon/net/ena/ena_com.h b/drivers/amazon/net/ena/ena_com.h
index 3b1bb5e..ba614a4 100644
--- a/drivers/amazon/net/ena/ena_com.h
+++ b/drivers/amazon/net/ena/ena_com.h
@@ -62,7 +62,7 @@
 			ena_trc_err(					\
 				"Assert failed on %s:%s:%d:" format,	\
 				__FILE__, __func__, __LINE__, ##arg);	\
-			WARN_ON(cond);					\
+			WARN_ON(!(cond));				\
 		}							\
 	} while (0)
 
diff --git a/drivers/amazon/net/ena/ena_eth_com.c b/drivers/amazon/net/ena/ena_eth_com.c
index d5b607a..421e64b 100644
--- a/drivers/amazon/net/ena/ena_eth_com.c
+++ b/drivers/amazon/net/ena/ena_eth_com.c
@@ -419,7 +419,7 @@ int ena_com_rx_pkt(struct ena_com_io_cq *io_cq,
 	ena_trc_dbg("fetch rx packet: queue %d completed desc: %d\n",
 		    io_cq->qid, nb_hw_desc);
 
-	if (unlikely(nb_hw_desc >= ena_rx_ctx->max_bufs)) {
+	if (unlikely(nb_hw_desc > ena_rx_ctx->max_bufs)) {
 		ena_trc_err("Too many RX cdescs (%d) > MAX(%d)\n",
 			    nb_hw_desc, ena_rx_ctx->max_bufs);
 		return -ENOSPC;
diff --git a/drivers/amazon/net/ena/ena_ethtool.c b/drivers/amazon/net/ena/ena_ethtool.c
index 77f6329..9044adc 100644
--- a/drivers/amazon/net/ena/ena_ethtool.c
+++ b/drivers/amazon/net/ena/ena_ethtool.c
@@ -74,7 +74,8 @@ static const struct ena_stats ena_stats_tx_strings[] = {
 	ENA_STAT_TX_ENTRY(queue_stop),
 	ENA_STAT_TX_ENTRY(queue_wakeup),
 	ENA_STAT_TX_ENTRY(dma_mapping_err),
-	ENA_STAT_TX_ENTRY(unsupported_desc_num),
+	ENA_STAT_TX_ENTRY(linearize),
+	ENA_STAT_TX_ENTRY(linearize_failed),
 	ENA_STAT_TX_ENTRY(napi_comp),
 	ENA_STAT_TX_ENTRY(tx_poll),
 	ENA_STAT_TX_ENTRY(doorbells),
diff --git a/drivers/amazon/net/ena/ena_netdev.c b/drivers/amazon/net/ena/ena_netdev.c
index d1d2726..33ddd6f 100644
--- a/drivers/amazon/net/ena/ena_netdev.c
+++ b/drivers/amazon/net/ena/ena_netdev.c
@@ -65,7 +65,8 @@ MODULE_VERSION(DRV_MODULE_VERSION);
 
 #define ENA_NAPI_BUDGET 64
 
-#define DEFAULT_MSG_ENABLE (NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_LINK)
+#define DEFAULT_MSG_ENABLE (NETIF_MSG_DRV | NETIF_MSG_PROBE | NETIF_MSG_IFUP | \
+		NETIF_MSG_TX_DONE | NETIF_MSG_TX_ERR)
 static int debug = -1;
 module_param(debug, int, 0);
 MODULE_PARM_DESC(debug, "Debug level (0=none,...,16=all)");
@@ -102,7 +103,7 @@ static void ena_tx_timeout(struct net_device *dev)
 	netif_err(adapter, tx_err, dev, "Transmit timed out\n");
 
 	/* Change the state of the device to trigger reset */
-	adapter->trigger_reset = true;
+	set_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags);
 }
 
 static void update_rx_ring_mtu(struct ena_adapter *adapter, int mtu)
@@ -198,12 +199,14 @@ static void ena_init_io_rings(struct ena_adapter *adapter)
 		txr->ring_size = adapter->tx_ring_size;
 		txr->tx_max_header_size = ena_dev->tx_max_header_size;
 		txr->tx_mem_queue_type = ena_dev->tx_mem_queue_type;
+		txr->sgl_size = adapter->max_tx_sgl_size;
 		txr->smoothed_interval =
 			ena_com_get_nonadaptive_moderation_interval_tx(ena_dev);
 
 		/* RX specific ring state */
 		rxr->ring_size = adapter->rx_ring_size;
 		rxr->rx_small_copy_len = adapter->small_copy_len;
+		rxr->sgl_size = adapter->max_rx_sgl_size;
 		rxr->smoothed_interval =
 			ena_com_get_nonadaptive_moderation_interval_rx(ena_dev);
 	}
@@ -679,7 +682,7 @@ static int validate_tx_req_id(struct ena_ring *tx_ring, u16 req_id)
 	u64_stats_update_end(&tx_ring->syncp);
 
 	/* Trigger device reset */
-	tx_ring->adapter->trigger_reset = true;
+	set_bit(ENA_FLAG_TRIGGER_RESET, &tx_ring->adapter->flags);
 	return -EFAULT;
 }
 
@@ -984,7 +987,7 @@ static int ena_clean_rx_irq(struct ena_ring *rx_ring, struct napi_struct *napi,
 
 	do {
 		ena_rx_ctx.ena_bufs = rx_ring->ena_bufs;
-		ena_rx_ctx.max_bufs = ENA_PKT_MAX_BUFS;
+		ena_rx_ctx.max_bufs = rx_ring->sgl_size;
 		ena_rx_ctx.descs = 0;
 		rc = ena_com_rx_pkt(rx_ring->ena_com_io_cq,
 				    rx_ring->ena_com_io_sq,
@@ -1059,9 +1062,8 @@ error:
 	rx_ring->rx_stats.bad_desc_num++;
 	u64_stats_update_end(&rx_ring->syncp);
 
-	/* Too many desc from the device. Trigger reset
-	 */
-	adapter->trigger_reset = true;
+	/* Too many desc from the device. Trigger reset */
+	set_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags);
 
 	return 0;
 }
@@ -1128,6 +1130,11 @@ static int ena_io_poll(struct napi_struct *napi, int budget)
 
 	tx_budget = tx_ring->ring_size / ENA_TX_POLL_BUDGET_DEVIDER;
 
+	if (!test_bit(ENA_FLAG_DEV_UP, &tx_ring->adapter->flags)) {
+		napi_complete(napi);
+		return 0;
+	}
+
 	tx_work_done = ena_clean_tx_irq(tx_ring, tx_budget);
 	rx_work_done = ena_clean_rx_irq(rx_ring, napi, budget);
 
@@ -1172,7 +1179,10 @@ static irqreturn_t ena_intr_msix_mgmnt(int irq, void *data)
 	struct ena_adapter *adapter = (struct ena_adapter *)data;
 
 	ena_com_admin_q_comp_intr_handler(adapter->ena_dev);
-	ena_com_aenq_intr_handler(adapter->ena_dev, data);
+
+	/* Don't call the aenq hanadler before probe is done */
+	if (likely(test_bit(ENA_FLAG_DEVICE_RUNNING, &adapter->flags)))
+		ena_com_aenq_intr_handler(adapter->ena_dev, data);
 
 	return IRQ_HANDLED;
 }
@@ -1194,7 +1204,7 @@ static int ena_enable_msix(struct ena_adapter *adapter, int num_queues)
 {
 	int i, msix_vecs, rc;
 
-	if (adapter->msix_enabled) {
+	if (test_bit(ENA_FLAG_MSIX_ENABLED, &adapter->flags)) {
 		netif_err(adapter, probe, adapter->netdev,
 			  "Error, MSI-X is already enabled\n");
 		return -EPERM;
@@ -1232,7 +1242,7 @@ static int ena_enable_msix(struct ena_adapter *adapter, int num_queues)
 	}
 
 	adapter->msix_vecs = msix_vecs;
-	adapter->msix_enabled = true;
+	set_bit(ENA_FLAG_MSIX_ENABLED, &adapter->flags);
 
 	return 0;
 }
@@ -1309,7 +1319,7 @@ static int ena_request_io_irq(struct ena_adapter *adapter)
 	struct ena_irq *irq;
 	int rc = 0, i, k;
 
-	if (!adapter->msix_enabled) {
+	if (!test_bit(ENA_FLAG_MSIX_ENABLED, &adapter->flags)) {
 		netif_err(adapter, ifup, adapter->netdev,
 			  "Failed to request I/O IRQ: MSI-X is not enabled\n");
 		return -EINVAL;
@@ -1375,11 +1385,9 @@ static void ena_free_io_irq(struct ena_adapter *adapter)
 
 static void ena_disable_msix(struct ena_adapter *adapter)
 {
-	if (adapter->msix_enabled)
+	if (test_and_clear_bit(ENA_FLAG_MSIX_ENABLED, &adapter->flags))
 		pci_disable_msix(adapter->pdev);
 
-	adapter->msix_enabled = false;
-
 	if (adapter->msix_entries)
 		vfree(adapter->msix_entries);
 	adapter->msix_entries = NULL;
@@ -1666,14 +1674,14 @@ static int ena_up(struct ena_adapter *adapter)
 	if (rc)
 		goto err_up;
 
-	if (adapter->link_status)
+	if (test_bit(ENA_FLAG_LINK_UP, &adapter->flags))
 		netif_carrier_on(adapter->netdev);
 
 	u64_stats_update_begin(&adapter->syncp);
 	adapter->dev_stats.interface_up++;
 	u64_stats_update_end(&adapter->syncp);
 
-	adapter->up = true;
+	set_bit(ENA_FLAG_DEV_UP, &adapter->flags);
 
 	return rc;
 
@@ -1696,22 +1704,24 @@ static void ena_down(struct ena_adapter *adapter)
 {
 	netif_info(adapter, ifdown, adapter->netdev, "%s\n", __func__);
 
-	adapter->up = false;
+	clear_bit(ENA_FLAG_DEV_UP, &adapter->flags);
 
 	u64_stats_update_begin(&adapter->syncp);
 	adapter->dev_stats.interface_down++;
 	u64_stats_update_end(&adapter->syncp);
 
+	/* After this point the napi handler won't enable the tx queue */
+	ena_napi_disable_all(adapter);
 	netif_carrier_off(adapter->netdev);
 	netif_tx_disable(adapter->netdev);
 
+	/* After destroy the queue there won't be any new interrupts */
+	ena_destroy_all_io_queues(adapter);
+
 	ena_disable_io_intr_sync(adapter);
-	ena_napi_disable_all(adapter);
 	ena_free_io_irq(adapter);
 	ena_del_napi(adapter);
 
-	ena_destroy_all_io_queues(adapter);
-
 	ena_free_all_tx_bufs(adapter);
 	ena_free_all_rx_bufs(adapter);
 	ena_free_all_io_tx_resources(adapter);
@@ -1770,7 +1780,7 @@ static int ena_close(struct net_device *netdev)
 
 	netif_dbg(adapter, ifdown, netdev, "%s\n", __func__);
 
-	if (adapter->up)
+	if (test_bit(ENA_FLAG_DEV_UP, &adapter->flags))
 		ena_down(adapter);
 
 	return 0;
@@ -1826,6 +1836,35 @@ static void ena_tx_csum(struct ena_com_tx_ctx *ena_tx_ctx, struct sk_buff *skb)
 	}
 }
 
+static int ena_check_and_linearize_skb(struct ena_ring *tx_ring,
+				       struct sk_buff *skb)
+{
+	int num_frags, header_len, rc;
+
+	num_frags = skb_shinfo(skb)->nr_frags;
+	header_len = skb_headlen(skb);
+
+	if (num_frags < tx_ring->sgl_size)
+		return 0;
+
+	if ((num_frags == tx_ring->sgl_size) &&
+	    (header_len < tx_ring->tx_max_header_size))
+		return 0;
+
+	u64_stats_update_begin(&tx_ring->syncp);
+	tx_ring->tx_stats.linearize++;
+	u64_stats_update_end(&tx_ring->syncp);
+
+	rc = skb_linearize(skb);
+	if (unlikely(rc)) {
+		u64_stats_update_begin(&tx_ring->syncp);
+		tx_ring->tx_stats.linearize_failed++;
+		u64_stats_update_end(&tx_ring->syncp);
+	}
+
+	return rc;
+}
+
 /* Called with netif_tx_lock. */
 static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 {
@@ -1851,8 +1890,11 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	tx_ring = &adapter->tx_ring[qid];
 	txq = netdev_get_tx_queue(dev, qid);
 
-	skb_tx_timestamp(skb);
+	rc = ena_check_and_linearize_skb(tx_ring, skb);
+	if (unlikely(rc))
+		return NETDEV_TX_BUSY;
 
+	skb_tx_timestamp(skb);
 	len = skb_headlen(skb);
 
 	next_to_use = tx_ring->next_to_use;
@@ -1897,19 +1939,6 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	}
 
 	last_frag = skb_shinfo(skb)->nr_frags;
-	if (unlikely(last_frag > (ENA_PKT_MAX_BUFS - 2))) {
-		netif_err(adapter, tx_queued, dev,
-			  "too many descriptors. last_frag %d!\n", last_frag);
-		for (i = 0; i <= last_frag; i++)
-			netif_err(adapter, tx_queued, dev,
-				  "frag[%d]: addr:0x%llx, len 0x%x\n", i,
-				  (unsigned long long)tx_info->bufs[i].paddr,
-				  tx_info->bufs[i].len);
-		u64_stats_update_begin(&tx_ring->syncp);
-		tx_ring->tx_stats.unsupported_desc_num++;
-		u64_stats_update_end(&tx_ring->syncp);
-		goto dma_error;
-	}
 
 	for (i = 0; i < last_frag; i++) {
 		const skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
@@ -1975,10 +2004,11 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	wmb();
 
 	/* stop the queue when no more space available, the packet can have up
-	 * to MAX_SKB_FRAGS + 1 buffers and a meta descriptor
+	 * to sgl_size + 2. one for the meta descriptor and one for header
+	 * (if the header is larger than tx_max_header_size).
 	 */
-	if (unlikely(ena_com_sq_empty_space(tx_ring->ena_com_io_sq)
-		< (MAX_SKB_FRAGS + 2))) {
+	if (unlikely(ena_com_sq_empty_space(tx_ring->ena_com_io_sq) <
+		     (tx_ring->sgl_size + 2))) {
 		netif_dbg(adapter, tx_queued, dev, "%s stop queue %d\n",
 			  __func__, qid);
 
@@ -2135,7 +2165,7 @@ static struct rtnl_link_stats64 *ena_get_stats64(struct net_device *netdev,
 	struct ena_admin_basic_stats ena_stats;
 	int rc;
 
-	if (!adapter->up)
+	if (!test_bit(ENA_FLAG_DEV_UP, &adapter->flags))
 		return NULL;
 
 	rc = ena_com_get_dev_basic_stats(adapter->ena_dev, &ena_stats);
@@ -2219,8 +2249,7 @@ static void ena_device_io_resume(struct work_struct *work)
 }
 
 static int ena_device_validate_params(struct ena_adapter *adapter,
-				      struct ena_com_dev_get_features_ctx
-				      *get_feat_ctx)
+				      struct ena_com_dev_get_features_ctx *get_feat_ctx)
 {
 	struct net_device *netdev = adapter->netdev;
 	int rc;
@@ -2406,7 +2435,7 @@ static void ena_fw_reset_device(struct work_struct *work)
 
 	rtnl_lock();
 
-	dev_up = adapter->up;
+	dev_up = test_bit(ENA_FLAG_DEV_UP, &adapter->flags);
 
 	ena_sysfs_terminate(&pdev->dev);
 
@@ -2508,7 +2537,7 @@ static void check_for_missing_tx_completions(struct ena_adapter *adapter)
 	/* Make sure the driver doesn't turn the device in other process */
 	smp_rmb();
 
-	if (!adapter->up)
+	if (!test_bit(ENA_FLAG_DEV_UP, &adapter->flags))
 		return;
 
 	budget = ENA_MONITORED_TX_QUEUES;
@@ -2520,9 +2549,9 @@ static void check_for_missing_tx_completions(struct ena_adapter *adapter)
 			tx_buf = &tx_ring->tx_buffer_info[j];
 			last_jiffies = tx_buf->last_jiffies;
 			if (unlikely(last_jiffies && time_is_before_jiffies(last_jiffies + TX_TIMEOUT))) {
-				netif_err(adapter, tx_err, adapter->netdev,
-					  "Found a Tx that wasn't completed on time, qid %d, index %d.\n",
-					  tx_ring->qid, j);
+				netif_notice(adapter, tx_err, adapter->netdev,
+					     "Found a Tx that wasn't completed on time, qid %d, index %d.\n",
+					     tx_ring->qid, j);
 
 				u64_stats_update_begin(&tx_ring->syncp);
 				missed_tx = tx_ring->tx_stats.missing_tx_comp++;
@@ -2533,8 +2562,12 @@ static void check_for_missing_tx_completions(struct ena_adapter *adapter)
 				 */
 				tx_buf->last_jiffies = 0;
 
-				if (unlikely(missed_tx > MAX_NUM_OF_TIMEOUTED_PACKETS))
-					adapter->trigger_reset = true;
+				if (unlikely(missed_tx > MAX_NUM_OF_TIMEOUTED_PACKETS)) {
+					netif_err(adapter, tx_err, adapter->netdev,
+						  "The number of lost tx completion is above the threshold (%d > %d). Reset the device\n",
+						  missed_tx, MAX_NUM_OF_TIMEOUTED_PACKETS);
+					set_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags);
+				}
 			}
 		}
 
@@ -2562,7 +2595,7 @@ static void check_for_missing_keep_alive(struct ena_adapter *adapter)
 		u64_stats_update_begin(&adapter->syncp);
 		adapter->dev_stats.wd_expired++;
 		u64_stats_update_end(&adapter->syncp);
-		adapter->trigger_reset = true;
+		set_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags);
 	}
 }
 
@@ -2574,7 +2607,7 @@ static void check_for_admin_com_state(struct ena_adapter *adapter)
 		u64_stats_update_begin(&adapter->syncp);
 		adapter->dev_stats.admin_q_pause++;
 		u64_stats_update_end(&adapter->syncp);
-		adapter->trigger_reset = true;
+		set_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags);
 	}
 }
 
@@ -2592,10 +2625,9 @@ static void ena_timer_service(unsigned long data)
 	if (debug_area)
 		ena_dump_stats_to_buf(adapter, debug_area);
 
-	if (unlikely(adapter->trigger_reset)) {
+	if (unlikely(test_and_clear_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags))) {
 		netif_err(adapter, drv, adapter->netdev,
 			  "Trigger reset is on\n");
-		adapter->trigger_reset = false;
 		ena_dump_stats_to_dmesg(adapter);
 		queue_work(ena_wq, &adapter->reset_task);
 		return;
@@ -2789,6 +2821,8 @@ static void ena_release_bars(struct ena_com_dev *ena_dev, struct pci_dev *pdev)
 
 static int ena_calc_queue_size(struct pci_dev *pdev,
 			       struct ena_com_dev *ena_dev,
+			       u16 *max_tx_sgl_size,
+			       u16 *max_rx_sgl_size,
 			       struct ena_com_dev_get_features_ctx *get_feat_ctx)
 {
 	u32 queue_size = ENA_DEFAULT_RING_SIZE;
@@ -2809,6 +2843,11 @@ static int ena_calc_queue_size(struct pci_dev *pdev,
 		return -EFAULT;
 	}
 
+	*max_tx_sgl_size = min_t(u16, ENA_PKT_MAX_BUFS,
+				 get_feat_ctx->max_queues.max_packet_tx_descs);
+	*max_rx_sgl_size = min_t(u16, ENA_PKT_MAX_BUFS,
+				 get_feat_ctx->max_queues.max_packet_rx_descs);
+
 	return queue_size;
 }
 
@@ -2830,10 +2869,9 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	struct ena_adapter *adapter;
 	struct ena_com_dev *ena_dev = NULL;
 	static int adapters_found;
-	int io_queue_num;
+	int io_queue_num, bars, rc;
 	int queue_size;
-	int bars;
-	int rc;
+	u16 tx_sgl_size, rx_sgl_size;
 
 	dev_dbg(&pdev->dev, "%s\n", __func__);
 
@@ -2900,7 +2938,8 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	*/
 	ena_dev->intr_moder_tx_interval = ENA_INTR_INITIAL_TX_INTERVAL_USECS;
 	io_queue_num = ena_calc_io_queue_num(pdev, ena_dev, &get_feat_ctx);
-	queue_size = ena_calc_queue_size(pdev, ena_dev, &get_feat_ctx);
+	queue_size = ena_calc_queue_size(pdev, ena_dev, &tx_sgl_size,
+					 &rx_sgl_size, &get_feat_ctx);
 	if ((queue_size <= 0) || (io_queue_num <= 0)) {
 		rc = -EFAULT;
 		goto err_device_destroy;
@@ -2933,6 +2972,9 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	adapter->tx_ring_size = queue_size;
 	adapter->rx_ring_size = queue_size;
 
+	adapter->max_tx_sgl_size = tx_sgl_size;
+	adapter->max_rx_sgl_size = rx_sgl_size;
+
 	adapter->num_queues = io_queue_num;
 	adapter->last_monitored_tx_qid = 0;
 
@@ -2990,6 +3032,8 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 
 	memcpy(adapter->netdev->perm_addr, adapter->mac_addr, netdev->addr_len);
 
+	netif_carrier_off(netdev);
+
 	rc = register_netdev(netdev);
 	if (rc) {
 		dev_err(&pdev->dev, "Cannot register net device\n");
@@ -3000,6 +3044,8 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 		 DEVICE_NAME, (long)pci_resource_start(pdev, 0),
 		 netdev->dev_addr, io_queue_num);
 
+	set_bit(ENA_FLAG_DEVICE_RUNNING, &adapter->flags);
+
 	adapters_found++;
 
 	return 0;
@@ -3180,11 +3226,12 @@ static void ena_update_on_link_change(void *adapter_data,
 
 	if (status) {
 		netdev_dbg(adapter->netdev, "%s\n", __func__);
+		set_bit(ENA_FLAG_LINK_UP, &adapter->flags);
 		netif_carrier_on(adapter->netdev);
 	} else {
+		clear_bit(ENA_FLAG_LINK_UP, &adapter->flags);
 		netif_carrier_off(adapter->netdev);
 	}
-	adapter->link_status = status;
 }
 
 static void ena_keep_alive_wd(void *adapter_data,
diff --git a/drivers/amazon/net/ena/ena_netdev.h b/drivers/amazon/net/ena/ena_netdev.h
index 283c311..f1d3344 100644
--- a/drivers/amazon/net/ena/ena_netdev.h
+++ b/drivers/amazon/net/ena/ena_netdev.h
@@ -45,7 +45,7 @@
 
 #define DRV_MODULE_VER_MAJOR	0
 #define DRV_MODULE_VER_MINOR	6
-#define DRV_MODULE_VER_SUBMINOR	1
+#define DRV_MODULE_VER_SUBMINOR 4
 
 #define DRV_MODULE_NAME		"ena"
 #ifndef DRV_MODULE_VERSION
@@ -54,7 +54,7 @@
 	__stringify(DRV_MODULE_VER_MINOR) "."	\
 	__stringify(DRV_MODULE_VER_SUBMINOR)
 #endif
-#define DRV_MODULE_RELDATE      "14-APRIL-2016"
+#define DRV_MODULE_RELDATE      "05-MAY-2016"
 
 #define DEVICE_NAME	"Elastic Network Adapter (ENA)"
 
@@ -169,7 +169,8 @@ struct ena_stats_tx {
 	u64 prepare_ctx_err;
 	u64 queue_wakeup;
 	u64 dma_mapping_err;
-	u64 unsupported_desc_num;
+	u64 linearize;
+	u64 linearize_failed;
 	u64 napi_comp;
 	u64 tx_poll;
 	u64 doorbells;
@@ -212,7 +213,9 @@ struct ena_ring {
 	u16 rx_small_copy_len;
 	u16 qid;
 	u16 mtu;
-	/* The maximum length the driver can push to the device (For LLQ) */
+	u16 sgl_size;
+
+	/* The maximum header length the device can handle */
 	u8 tx_max_header_size;
 
 	/* cpu for TPH */
@@ -243,6 +246,14 @@ struct ena_stats_dev {
 	u64 admin_q_pause;
 };
 
+enum ena_flags_t {
+	ENA_FLAG_DEVICE_RUNNING,
+	ENA_FLAG_DEV_UP,
+	ENA_FLAG_LINK_UP,
+	ENA_FLAG_MSIX_ENABLED,
+	ENA_FLAG_TRIGGER_RESET
+};
+
 /* adapter specific private data structure */
 struct ena_adapter {
 	struct ena_com_dev *ena_dev;
@@ -250,8 +261,6 @@ struct ena_adapter {
 	struct net_device *netdev;
 	struct pci_dev *pdev;
 
-	u32 msix_enabled;
-
 	/* rx packets that shorter that this len will be copied to the skb
 	 * header
 	 */
@@ -271,14 +280,14 @@ struct ena_adapter {
 
 	u32 msg_enable;
 
+	u16 max_tx_sgl_size;
+	u16 max_rx_sgl_size;
+
 	u8 mac_addr[ETH_ALEN];
 
 	char name[ENA_NAME_MAX_LEN];
-	bool link_status;
-
-	bool up;
-	bool trigger_reset;
 
+	unsigned long flags;
 	/* TX */
 	struct ena_ring tx_ring[ENA_MAX_NUM_IO_QUEUES]
 		____cacheline_aligned_in_smp;
-- 
2.7.4

