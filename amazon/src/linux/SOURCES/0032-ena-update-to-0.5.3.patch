From 449e924225dc02647f9e3b80b404e9b12f9b2e32 Mon Sep 17 00:00:00 2001
From: Munehisa Kamata <kamatam@amazon.com>
Date: Fri, 1 Apr 2016 17:19:17 +0000
Subject: ena: update to 0.5.3

Signed-off-by: Munehisa Kamata <kamatam@amazon.com>
Reviewed-by: Netanel Belgazal <netanel@annapurnalabs.com>
Reviewed-by: Rashika Kheria <rashika@amazon.de>
Reviewed-by: Matt Nierzwicki <nierzwic@amazon.com>

CR: https://cr.amazon.com/r/5132188/
---
 drivers/amazon/ena/README        | 281 ---------------------------------------
 drivers/amazon/ena/ena_com.c     |  35 ++---
 drivers/amazon/ena/ena_com.h     |  21 +--
 drivers/amazon/ena/ena_eth_com.c |  12 +-
 drivers/amazon/ena/ena_netdev.c  |  27 ++--
 drivers/amazon/ena/ena_netdev.h  |   2 +-
 6 files changed, 56 insertions(+), 322 deletions(-)
 delete mode 100644 drivers/amazon/ena/README

diff --git a/drivers/amazon/ena/README b/drivers/amazon/ena/README
deleted file mode 100644
index 78a2b20..0000000
--- a/drivers/amazon/ena/README
+++ /dev/null
@@ -1,281 +0,0 @@
-Linux kernel driver for Elastic Network Adapter (ENA)
-This network driver is speed-independent, providing a high-performance,
-low-latency network interface for virtual machines and bare metal environment.
-ENA negotiates supported features with the device, to enable future upgrades and
-various systems with a single driver.
-
-Files Structure:
-===============
-ena_com/ena_defs - Holds the ENA descriptors and ENA register structures.
-ena_com - Communication layer. This layer is responsible for handling all
-communications between the ENA device and the driver.
-ena_netdev.c/.h - Main driver.
-
-Arch:
-====
-This driver implements a standard Linux Ethernet driver. The kernel communicates
-with the driver using the net_device_ops (defined at include/linux/netdevice.h).
-the driver uses the PCI interface for probing the adapter and various other
-management functions.
-
-Management Interface:
-====================
-All management of the ENA device is performed by 2 queues.
-The Admin queue (AQ) and the asynchronous event notification queue (AENQ).
-The admin queue has the following commands:
-* Create IO submission queue.
-* Create IO completion queue.
-* Destroy IO submission queue.
-* Destroy IO completion queue.
-* Suspend IO submission queue.
-* Flush IO submission queue.
-* Get feature.
-* Set feature.
-* Configure AENQ.
-* Get statistics.
-
-The create and and destroy commands are fully implemented. The get/set feature
-is partially implemented and the rest of the commands will be implemented in a
-later version.
-To examine all the properties of the set/get feature command, refer to
-ena_com/ena_defs/ena_admin_defs.h.
-
-AENQ is a single-side queue (from the ENA device to the host driver), which
-sends events that cannot be reported using the Admin Completion Queue (ACQ).
-Each event is divided into group and syndrom.
-The events are:
-	Group		Syndrom                         Notes
-	Link change	- X -
-	Fatal error	- X -
-	Warning		Thermal threshold		PF only
-	Warning		Logging fifo overflow		PF only
-	Warning		Dirty page logging		PF only
-	Warning		Malicious mmio access		PF only
-	Warning 	CQ full
-	notification	suspend traffic
-	notification	resume traffic
-	Keep Alive	- X -
-
-Currently the driver implements handlers for:
-link change, suspend/resume trafic, keep alive tracking and fatal error.
-
-Queue Operating Modes:
-======================
-
-The driver supports 2 Queue Operation modes for Transmit (Tx) queues:
-* Low Latency Queue (LLQ) or push-mode.
- ** In this mode the driver pushes the transmit descriptors and the first 128
-bytes of the packet directly to the ENA device memory space. The rest of the
-packet payload is fetched by the device. For this operation mode the host use
-a dedicated PCIe device memory BAR that is non-cacheable but with write-combine
-enabled.
-
-* Regular mode
-** In this mode the ENA device fetches the ENA Tx descriptors and the packet
-data from host memory.
-
-For RX queues the ENA device supports only the regular mode.
-
-***Note: Not all the ENA devices support LLQ, and this feature is negotiated
-with the device upon initialization.
-
-If the ENA device does not support LLQ mode, the driver will fall back to
-regular mode.
-
-Interrupt Modes:
-================
-The ENA device is built with modern muti-core and parallel processing in mind,
-thus it has an interrupt controller that can generate an MSI-X interrupt per
-queue.
-
-The driver assigns a single MSI-X vector per queue pair (for both the Tx and the
-Rx directions). In addition, the driver assigns another dedicated MSI-X
-vector for management (for admin completions and asynchronous events
-notification queues).
-
-Management interrupt registration is performed when the Linux kernel probes the
-adapter, and it is de-registered when the adapter is removed.
-The I/O queues interrupts registeration is performed when the linux interface
-of the adapter is opened, and it is de-registered when
-the interface is closed. The systems interrupts status can be viewed in the
-/proc/interrupts pseudo file.
-
-The registered interrupt name is:
-ena-mgmnt@pci:<pci device name of the adapter>
-and for each queue, an interrupt is registered with the following name:
-<interface name><queue index>.
-
-Memory Allocations:
-==================
-DMA Coherent buffers for the following DMA rings:
-- Tx submission ring (For regular mode; for LLQ mode it is allocated using
-kzalloc)
-- Tx completion ring.
-- Rx submission ring.
-- Rx completion ring.
-- Admin submition ring.
-- Admin completion ring.
-- AENQ ring.
-- MMIO Readless mechanisem buffer.
-
-The ENA device admin, aenq and the mmio read and buffers are allocated on
-probe and freed on termination.
-
-Regular allocations:
-- Tx buffers info ring.
-- Tx free indexes ring.
-- Rx buffers info ring.
-- MSI-X table.
-- ENA device.
-
-Tx/Rx buffers and the MSI-X table are allocated on Open and freed on Close.
-
-Rx buffer allocation modes:
-
-The driver supports two allocation modes:
-1. Frag allocation (default): Buffer is allocated using netdev_alloc_frag().
-2. Page allocation: Buffer is allocated using alloc_page().
-
-Rx buffers allocation in both modes is performed as follows:
-1. When enabling an interface -- open().
-2. Once per Rx poll for all the frames received and not copied to the new
-   allocated SKB (len < small_packet_len).
-
-These buffers are freed on close().
-
-The small_packet_len is initialized by default to ENA_DEFAULT_SMALL_PACKET_LEN
-and can be configured
-by the sysfs pseudo file
-/sys/bus/pci/devices/<pci device name of the adapter>/small_packet_len.
-
-SKB:
-The driver-allocated SKB for frames received from Rx handling using
-NAPI context. The allocation method depends on size of the packet.
-If the frame length is larger than small_packet_len,
-build_skb() is used, otherwise netdev_alloc_skb_ip_align() is
-used, the buffer content is copied (by CPU) to the skb and the buffer
-is recycled.
-
-MULTIQUEUE:
-===========
-The driver supports multiqueue mode for both Tx and Rx.
-This mode has various benefits when queues are allocated to different CPU
-cores/threads.
-1. Reduced CPU/thread/process contention on a given Ethernet port, when
-transmitting a packet.
-2. Cache miss rate on transmit completion is reduced, particularly for data
-cache lines
-   that hold the sk_buff structures.
-3. Increased process-level parallelism when handling received packets.
-4. Increased data cache hit rate by steering kernel processing of packets to the
-CPU, where the application thread consuming the packet is running.
-5. In hardware interrupt re-direction.
-
-RSS:
-For TCP/UDP packets the ENA device calculates the 4-tuple and steers the packet
-according to this value (module #queue). Other packets are steered to queue 0.
-
-VFs steering:
-To steer between VFs, the ENA device uses the least significant byte of the
-destination MAC address to determain the VF index. ARP packets are passed to PF.
-This logic will be fixed in the next releases.
-
-Interrupts Affinity:
--------------------
-To utilize the multiqueue benefits, the user must set the interrupts affinity of
-each of the queue's pair.  The general recommendation is to have the interrupt
-of Tx and Rx queues N routed to core N.
-
-DATA PATH:
-==========
-Tx:
----
-end_start_xmit() is called by the stack. This function does the following:
-- map data buffers (skb->data and frags).
-- Populate ena_buf for the push buffer (if the driver works in push mode.)
-- Prepare ENA bufs for the remaining frags.
-- Allocate a new request ID from the empty req_id ring (The request ID is the
-index of the packet in the Tx ring. This is used for OOO TX completions.)
-- Add the packet to the proper place in the Tx ring.
-- Call ena_prepare_tx(), an ENA communication layer that converts the ena_bufs
-  to ENA descriptors (and adds meta ENA descriptors when needed.)
-  This function also copies the ENA descriptors and the push buffer to the
-device
-  memory space (depending on the working mode.)
-- Write doorbell to ENA device.
-- When the ENA device finishes sending the packet, a completion interrupt is
-raised.
-- The interrupt handler schedules NAPI.
-- The ena_clean_tx_irq function is called. This function handles the completion
-descriptors generated by the ENA,
-  with a single completion descriptor per completed packet.
-Retrives the req_id from the completion descriptor. Gets the tx_info of the
-packet, according to the req_id. Unmaps the data buffers and returns req_id
-to the empty requester-id ring.
-  The function stops when the completion descriptors are completed or the
-budget is reached.
-
-Rx:
----
-- When a packet is received by the ENA device, it is written to the host
-memory, where the previous ENA RX buffer was allocated. The driver makes sure
-to set the INT bit in each of the ENA Rx descriptors, so an interrupt will be
-triggered (if unmasked )when a new packet is written to that descriptor.
-- The interrupt handler schedules NAPI.
-- The aena_clean_rx_irq function is called. This functions calls aena_rx_pkt(),
-an ENA communication layer function, which returns the number of descriptors
-used for a new unhandled packet, and zero if no new packet is found.
-Then it calls the ena_clean_rx_irq() function.
-- ena_eth_rx_skb checks packet length:
-  If the packet is too small (len less than small_packet_len), the driver
-allocates an SKB structure for the new packet, and copies the packet payload
-into the SKB data buffer.
-In this way the original data buffer is not passed to the stack and is reused
-for the next Rx packets.
-Otherwise the function unmaps the Rx buffer, then allocates he new SKB
-structure and hooks the Rx buffer to the SKB frags.
-  (*) Copying the packet payload into the SKB data buffer for short packets is
-a common optimization in Linux network drivers.
-This method saves allocating and mapping large buffers.
-  (**) Allocating SKB on packet reception is also a common method, which has the
-following benefits:
-  (i) SKB is used and accessed immediately after allocation.
-This reduces possible cache misses.
-  (ii) The number of 'inuse' sk_buff can be reduced to the very minimum,
-especially when packets are dropped by the stack.
-- The new SKB is updated with the necessary information (protocol, checksum hw
-calc result, etc), and then passed to the network stack, using the NAPI interface
-function napi_gro_receive().
-
-Note:
-The Rx and Tx queues share the same interrut so for each interrupt issued by
-the device both ena_clean_rx_irq and ena_clean_tx_irq will be called.
-
-MMIO Readless mechanisem:
-There are two new WO registers in the MMIO Regs.
-Register Index - index of the register that should be read + coockie
-MMIO Response Addr  (High/Low) address in Device Driver memory where the
-response should be written by the device.
-Whenever the driver wants to issue a read he writes the register offset
-and a coockie to the register index register.
-The device will write back the data to the MMIO response reg together
-with the cokie.
-
-Keep Alive mechanisem:
-The device sends to the driver a Keep alive event every 1 sec.
-When the driver doesn't receive the keep alive event for a long
-period he will try to reset the ena device.
-
-
-Missing features:
-================
- - Rx queue select
- - Ethtool for rxnfs (RFS)
- - CSUM for IPv6
- - counters for failed - sync with sysfs
- - adaptive coalescing
- - update completion head
- - tx_pkt_watchdog proper handeling
- - reset SQ in failure
- - multicast
- - dynamic ring size
diff --git a/drivers/amazon/ena/ena_com.c b/drivers/amazon/ena/ena_com.c
index ce92169..b1e75920 100644
--- a/drivers/amazon/ena/ena_com.c
+++ b/drivers/amazon/ena/ena_com.c
@@ -693,8 +693,8 @@ static void ena_com_io_queue_free(struct ena_com_dev *ena_dev,
 	}
 }
 
-static int wait_for_reset_state(struct ena_com_dev *ena_dev,
-				u32 timeout, u16 exp_state)
+static int wait_for_reset_state(struct ena_com_dev *ena_dev, u32 timeout,
+				u16 exp_state)
 {
 	u32 val, i;
 
@@ -875,7 +875,7 @@ static int ena_com_indirect_table_allocate(struct ena_com_dev *ena_dev,
 		return -EINVAL;
 	}
 
-	tbl_size = (1 << log_size) *
+	tbl_size = (1ULL << log_size) *
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
 	rss->rss_ind_tbl =
@@ -886,7 +886,7 @@ static int ena_com_indirect_table_allocate(struct ena_com_dev *ena_dev,
 	if (unlikely(!rss->rss_ind_tbl))
 		goto mem_err1;
 
-	tbl_size = (1 << log_size) * sizeof(u16);
+	tbl_size = (1ULL << log_size) * sizeof(u16);
 	rss->host_rss_ind_tbl =
 		devm_kzalloc(ena_dev->dmadev, tbl_size, GFP_KERNEL);
 	if (unlikely(!rss->host_rss_ind_tbl))
@@ -897,7 +897,7 @@ static int ena_com_indirect_table_allocate(struct ena_com_dev *ena_dev,
 	return 0;
 
 mem_err2:
-	tbl_size = (1 << log_size) *
+	tbl_size = (1ULL << log_size) *
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
 	dma_free_coherent(ena_dev->dmadev,
@@ -913,7 +913,7 @@ mem_err1:
 static int ena_com_indirect_table_destroy(struct ena_com_dev *ena_dev)
 {
 	struct ena_rss *rss = &ena_dev->rss;
-	size_t tbl_size = (1 << rss->tbl_log_size) *
+	size_t tbl_size = (1ULL << rss->tbl_log_size) *
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
 	if (rss->rss_ind_tbl)
@@ -1029,17 +1029,18 @@ static int ena_com_ind_tbl_convert_to_device(struct ena_com_dev *ena_dev)
 
 static int ena_com_ind_tbl_convert_from_device(struct ena_com_dev *ena_dev)
 {
-	u16 dev_idx_to_host_tbl[ENA_TOTAL_NUM_QUEUES] = { -1 };
+	u16 dev_idx_to_host_tbl[ENA_TOTAL_NUM_QUEUES] = { (u16)-1 };
 	struct ena_rss *rss = &ena_dev->rss;
-	u16 idx, i;
+	u8 idx;
+	u16 i;
 
 	for (i = 0; i < ENA_TOTAL_NUM_QUEUES; i++)
 		dev_idx_to_host_tbl[ena_dev->io_sq_queues[i].idx] = i;
 
 	for (i = 0; i < 1 << rss->tbl_log_size; i++) {
-		idx = rss->rss_ind_tbl[i].cq_idx;
-		if (idx > ENA_TOTAL_NUM_QUEUES)
+		if (rss->rss_ind_tbl[i].cq_idx > ENA_TOTAL_NUM_QUEUES)
 			return -EINVAL;
+		idx = (u8)rss->rss_ind_tbl[i].cq_idx;
 
 		if (dev_idx_to_host_tbl[idx] > ENA_TOTAL_NUM_QUEUES)
 			return -EINVAL;
@@ -1066,7 +1067,7 @@ static int ena_com_init_interrupt_moderation_table(struct ena_com_dev *ena_dev)
 }
 
 static void ena_com_update_intr_delay_resolution(struct ena_com_dev *ena_dev,
-						 unsigned int intr_delay_resolution)
+						 u16 intr_delay_resolution)
 {
 	struct ena_intr_moder_entry *intr_moder_tbl = ena_dev->intr_moder_tbl;
 	unsigned int i;
@@ -1620,7 +1621,7 @@ int ena_com_create_io_queue(struct ena_com_dev *ena_dev,
 	if (direction == ENA_COM_IO_QUEUE_DIRECTION_TX)
 		/* header length is limited to 8 bits */
 		io_sq->tx_max_header_size =
-			min_t(u16, ena_dev->tx_max_header_size, SZ_256);
+			min_t(u32, ena_dev->tx_max_header_size, SZ_256);
 
 	ret = ena_com_init_io_sq(ena_dev, io_sq);
 	if (ret)
@@ -2126,7 +2127,7 @@ int ena_com_get_hash_function(struct ena_com_dev *ena_dev,
 		*func = rss->hash_func;
 
 	if (key)
-		memcpy(key, hash_key->key, hash_key->keys_num << 2);
+		memcpy(key, hash_key->key, (size_t)(hash_key->keys_num) << 2);
 
 	return 0;
 }
@@ -2268,7 +2269,7 @@ int ena_com_fill_hash_ctrl(struct ena_com_dev *ena_dev,
 	u16 supported_fields;
 	int rc;
 
-	if (proto > ENA_ADMIN_RSS_PROTO_NUM) {
+	if (proto >= ENA_ADMIN_RSS_PROTO_NUM) {
 		ena_trc_err("Invalid proto num (%u)\n", proto);
 		return -EINVAL;
 	}
@@ -2350,7 +2351,7 @@ int ena_com_indirect_table_set(struct ena_com_dev *ena_dev)
 		return ret;
 	}
 
-	cmd.control_buffer.length = (1 << rss->tbl_log_size) *
+	cmd.control_buffer.length = (1ULL << rss->tbl_log_size) *
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
 	ret = ena_com_execute_admin_command(admin_queue,
@@ -2374,7 +2375,7 @@ int ena_com_indirect_table_get(struct ena_com_dev *ena_dev, u32 *ind_tbl)
 	u32 tbl_size;
 	int i, rc;
 
-	tbl_size = (1 << rss->tbl_log_size) *
+	tbl_size = (1ULL << rss->tbl_log_size) *
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
 	rc = ena_com_get_feature_ex(ena_dev, &get_resp,
@@ -2601,7 +2602,7 @@ void ena_com_destroy_interrupt_moderation(struct ena_com_dev *ena_dev)
 int ena_com_init_interrupt_moderation(struct ena_com_dev *ena_dev)
 {
 	struct ena_admin_get_feat_resp get_resp;
-	u32 delay_resolution;
+	u16 delay_resolution;
 	int rc;
 
 	rc = ena_com_get_feature(ena_dev, &get_resp,
diff --git a/drivers/amazon/ena/ena_com.h b/drivers/amazon/ena/ena_com.h
index 8239ccc..d0203fe 100644
--- a/drivers/amazon/ena/ena_com.h
+++ b/drivers/amazon/ena/ena_com.h
@@ -141,8 +141,8 @@ struct ena_com_rx_buf_info {
 };
 
 struct ena_com_io_desc_addr {
-	void  __iomem *pbuf_dev_addr; /* LLQ address */
-	void  *virt_addr;
+	u8  __iomem *pbuf_dev_addr; /* LLQ address */
+	u8  *virt_addr;
 	dma_addr_t phys_addr;
 };
 
@@ -209,7 +209,7 @@ struct ena_com_io_sq {
 	u16 idx;
 	u16 tail;
 	u16 next_to_comp;
-	u16 tx_max_header_size;
+	u32 tx_max_header_size;
 	u8 phase;
 	u8 desc_entry_size;
 	u8 dma_addr_bits;
@@ -328,12 +328,10 @@ struct ena_com_dev {
 	void *dmadev;
 
 	enum ena_admin_placement_policy_type tx_mem_queue_type;
-
+	u32 tx_max_header_size;
 	u16 stats_func; /* Selected function for extended statistic dump */
 	u16 stats_queue; /* Selected queue for extended statistic dump */
 
-	u16 tx_max_header_size;
-
 	struct ena_com_mmio_read mmio_read;
 
 	struct ena_rss rss;
@@ -976,7 +974,7 @@ static inline void ena_com_calculate_interrupt_delay(struct ena_com_dev *ena_dev
 		 */
 		return;
 
-	curr_moder_idx = *moder_tbl_idx;
+	curr_moder_idx = (enum ena_intr_moder_level)(*moder_tbl_idx);
 	if (unlikely(curr_moder_idx >=  ENA_INTR_MAX_NUM_OF_LEVELS)) {
 		ena_trc_err("Wrong moderation index %u\n", curr_moder_idx);
 		return;
@@ -988,17 +986,20 @@ static inline void ena_com_calculate_interrupt_delay(struct ena_com_dev *ena_dev
 	if (curr_moder_idx == ENA_INTR_MODER_LOWEST) {
 		if ((pkts > curr_moder_entry->pkts_per_interval) ||
 		    (bytes > curr_moder_entry->bytes_per_interval))
-			new_moder_idx = curr_moder_idx + 1;
+			new_moder_idx =
+				(enum ena_intr_moder_level)(curr_moder_idx + 1);
 	} else {
 		pred_moder_entry = &intr_moder_tbl[curr_moder_idx - 1];
 
 		if ((pkts <= pred_moder_entry->pkts_per_interval) ||
 		    (bytes <= pred_moder_entry->bytes_per_interval))
-			new_moder_idx = curr_moder_idx - 1;
+			new_moder_idx =
+				(enum ena_intr_moder_level)(curr_moder_idx - 1);
 		else if ((pkts > curr_moder_entry->pkts_per_interval) ||
 			 (bytes > curr_moder_entry->bytes_per_interval)) {
 			if (curr_moder_idx != ENA_INTR_MODER_HIGHEST)
-				new_moder_idx = curr_moder_idx + 1;
+				new_moder_idx =
+				(enum ena_intr_moder_level)(curr_moder_idx + 1);
 		}
 	}
 	new_moder_entry = &intr_moder_tbl[new_moder_idx];
diff --git a/drivers/amazon/ena/ena_eth_com.c b/drivers/amazon/ena/ena_eth_com.c
index 51d7457..d5b607a 100644
--- a/drivers/amazon/ena/ena_eth_com.c
+++ b/drivers/amazon/ena/ena_eth_com.c
@@ -72,7 +72,7 @@ static inline void *get_sq_desc(struct ena_com_io_sq *io_sq)
 
 	offset = tail_masked * io_sq->desc_entry_size;
 
-	return io_sq->desc_addr.virt_addr + offset;
+	return (void *)((uintptr_t)io_sq->desc_addr.virt_addr + offset);
 }
 
 static inline void ena_com_copy_curr_sq_desc_to_dev(struct ena_com_io_sq *io_sq)
@@ -119,8 +119,9 @@ static inline struct ena_eth_io_rx_cdesc_base *
 	ena_com_rx_cdesc_idx_to_ptr(struct ena_com_io_cq *io_cq, u16 idx)
 {
 	idx &= (io_cq->q_depth - 1);
-	return (struct ena_eth_io_rx_cdesc_base *)(io_cq->cdesc_addr.virt_addr +
-			idx * io_cq->cdesc_entry_size_in_bytes);
+	return (struct ena_eth_io_rx_cdesc_base *)
+		((uintptr_t)io_cq->cdesc_addr.virt_addr +
+		idx * io_cq->cdesc_entry_size_in_bytes);
 }
 
 static inline int ena_com_cdesc_rx_pkt_get(struct ena_com_io_cq *io_cq,
@@ -487,8 +488,9 @@ int ena_com_tx_comp_req_id_get(struct ena_com_io_cq *io_cq, u16 *req_id)
 	masked_head = io_cq->head & (io_cq->q_depth - 1);
 	expected_phase = io_cq->phase;
 
-	cdesc = (struct ena_eth_io_tx_cdesc *)(io_cq->cdesc_addr.virt_addr
-		+ (masked_head * io_cq->cdesc_entry_size_in_bytes));
+	cdesc = (struct ena_eth_io_tx_cdesc *)
+		((uintptr_t)io_cq->cdesc_addr.virt_addr +
+		(masked_head * io_cq->cdesc_entry_size_in_bytes));
 
 	cdesc_phase = cdesc->flags & ENA_ETH_IO_TX_CDESC_PHASE_MASK;
 	if (cdesc_phase != expected_phase)
diff --git a/drivers/amazon/ena/ena_netdev.c b/drivers/amazon/ena/ena_netdev.c
index 823cc9d..f1452b8 100644
--- a/drivers/amazon/ena/ena_netdev.c
+++ b/drivers/amazon/ena/ena_netdev.c
@@ -32,7 +32,9 @@
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
+#ifdef CONFIG_RFS_ACCEL
 #include <linux/cpu_rmap.h>
+#endif /* CONFIG_RFS_ACCEL */
 #include <linux/ethtool.h>
 #include <linux/if_vlan.h>
 #include <linux/kernel.h>
@@ -135,6 +137,7 @@ static int ena_change_mtu(struct net_device *dev, int new_mtu)
 
 static int ena_init_rx_cpu_rmap(struct ena_adapter *adapter)
 {
+#ifdef CONFIG_RFS_ACCEL
 	u32 i;
 	int rc;
 
@@ -152,6 +155,7 @@ static int ena_init_rx_cpu_rmap(struct ena_adapter *adapter)
 			return rc;
 		}
 	}
+#endif /* CONFIG_RFS_ACCEL */
 	return 0;
 }
 
@@ -1018,7 +1022,7 @@ static int ena_clean_rx_irq(struct ena_ring *rx_ring, struct napi_struct *napi,
 
 		if (rx_ring->ena_bufs[0].len <= rx_ring->rx_small_copy_len) {
 			total_len += rx_ring->ena_bufs[0].len;
-			small_copy_pkt = 1;
+			small_copy_pkt++;
 			napi_gro_receive(napi, skb);
 		} else {
 			total_len += skb->len;
@@ -1326,10 +1330,12 @@ static void ena_free_io_irq(struct ena_adapter *adapter)
 	struct ena_irq *irq;
 	int i;
 
+#ifdef CONFIG_RFS_ACCEL
 	if (adapter->msix_vecs >= 1) {
 		free_irq_cpu_rmap(adapter->netdev->rx_cpu_rmap);
 		adapter->netdev->rx_cpu_rmap = NULL;
 	}
+#endif /* CONFIG_RFS_ACCEL */
 
 	for (i = ENA_IO_IRQ_FIRST_IDX; i < adapter->msix_vecs; i++) {
 		irq = &adapter->irq_tbl[i];
@@ -1780,8 +1786,7 @@ static void ena_tx_csum(struct ena_com_tx_ctx *ena_tx_ctx, struct sk_buff *skb)
 }
 
 /* Called with netif_tx_lock. */
-static netdev_tx_t ena_start_xmit(struct sk_buff *skb,
-				  struct net_device *dev)
+static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 {
 	struct ena_adapter *adapter = netdev_priv(dev);
 	struct ena_tx_buffer *tx_info;
@@ -2800,7 +2805,6 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	}
 
 	pci_set_master(pdev);
-	pci_save_state(pdev);
 
 	ena_dev = vzalloc(sizeof(*ena_dev));
 	if (!ena_dev) {
@@ -3024,7 +3028,7 @@ static void ena_remove(struct pci_dev *pdev)
 {
 	struct ena_adapter *adapter = pci_get_drvdata(pdev);
 	struct ena_com_dev *ena_dev;
-	struct net_device *dev;
+	struct net_device *netdev;
 
 	if (!adapter)
 		/* This device didn't load properly and it's resources
@@ -3033,9 +3037,16 @@ static void ena_remove(struct pci_dev *pdev)
 		return;
 
 	ena_dev = adapter->ena_dev;
-	dev = adapter->netdev;
+	netdev = adapter->netdev;
 
-	unregister_netdev(dev);
+#ifdef CONFIG_RFS_ACCEL
+	if ((adapter->msix_vecs >= 1) && (netdev->rx_cpu_rmap)) {
+		free_irq_cpu_rmap(netdev->rx_cpu_rmap);
+		netdev->rx_cpu_rmap = NULL;
+	}
+#endif /* CONFIG_RFS_ACCEL */
+
+	unregister_netdev(netdev);
 
 	ena_sysfs_terminate(&pdev->dev);
 
@@ -3053,7 +3064,7 @@ static void ena_remove(struct pci_dev *pdev)
 
 	ena_disable_msix(adapter);
 
-	free_netdev(dev);
+	free_netdev(netdev);
 
 	ena_com_mmio_reg_read_request_destroy(ena_dev);
 
diff --git a/drivers/amazon/ena/ena_netdev.h b/drivers/amazon/ena/ena_netdev.h
index 481f3cb..f602a4c 100644
--- a/drivers/amazon/ena/ena_netdev.h
+++ b/drivers/amazon/ena/ena_netdev.h
@@ -45,7 +45,7 @@
 
 #define DRV_MODULE_VER_MAJOR	0
 #define DRV_MODULE_VER_MINOR	5
-#define DRV_MODULE_VER_SUBMINOR	2
+#define DRV_MODULE_VER_SUBMINOR	3
 
 #define DRV_MODULE_NAME		"ena"
 #ifndef DRV_MODULE_VERSION
-- 
2.7.4

