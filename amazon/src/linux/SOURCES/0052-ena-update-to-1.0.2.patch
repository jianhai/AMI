From 57c6b4788ab9ee46b8268a27654afce7ba9e9c94 Mon Sep 17 00:00:00 2001
From: Vineeth Remanan Pillai <vineethp@amazon.com>
Date: Tue, 2 Aug 2016 17:49:15 +0000
Subject: ena: update to 1.0.2

Signed-off-by: Vineeth Remanan Pillai <vineethp@amazon.com>
Reviewed-by: Munehisa Kamatam <kamatam@amazon.com>
Reviewed-by: Erik Quanstrom <quanstro@amazon.com>

CR: https://cr.amazon.com/r/5680546/
---
 drivers/amazon/net/ena/Makefile          |   9 +-
 drivers/amazon/net/ena/ena_admin_defs.h  | 627 ++++++++----------------------
 drivers/amazon/net/ena/ena_com.c         | 641 +++++++++++++------------------
 drivers/amazon/net/ena/ena_com.h         |  41 +-
 drivers/amazon/net/ena/ena_common_defs.h |  10 +-
 drivers/amazon/net/ena/ena_eth_com.c     |  60 ++-
 drivers/amazon/net/ena/ena_eth_com.h     |  10 +-
 drivers/amazon/net/ena/ena_eth_io_defs.h | 216 +++--------
 drivers/amazon/net/ena/ena_ethtool.c     |  97 +++--
 drivers/amazon/net/ena/ena_gen_info.h    |  37 --
 drivers/amazon/net/ena/ena_includes.h    |   4 -
 drivers/amazon/net/ena/ena_netdev.c      | 140 +++----
 drivers/amazon/net/ena/ena_netdev.h      |  21 +-
 drivers/amazon/net/ena/ena_pci_id_tbl.h  |   4 +-
 drivers/amazon/net/ena/ena_regs_defs.h   |   2 +-
 drivers/amazon/net/ena/ena_sysfs.c       |  72 +---
 drivers/amazon/net/ena/ena_sysfs.h       |   2 +-
 17 files changed, 687 insertions(+), 1306 deletions(-)
 delete mode 100644 drivers/amazon/net/ena/ena_gen_info.h
 delete mode 100644 drivers/amazon/net/ena/ena_includes.h

diff --git a/drivers/amazon/net/ena/Makefile b/drivers/amazon/net/ena/Makefile
index 9df162a..b7d4cdc 100644
--- a/drivers/amazon/net/ena/Makefile
+++ b/drivers/amazon/net/ena/Makefile
@@ -1,2 +1,9 @@
+#
+# Makefile for the Elastic Network Adapter (ENA) device drivers.
+#
+
 obj-$(CONFIG_AMAZON_ENA) += ena.o
-ena-objs := ena_com.o ena_ethtool.o ena_eth_com.o ena_netdev.o ena_sysfs.o
+
+ena-y := ena_netdev.o ena_com.o ena_eth_com.o ena_ethtool.o
+
+ena-$(CONFIG_SYSFS) += ena_sysfs.o
diff --git a/drivers/amazon/net/ena/ena_admin_defs.h b/drivers/amazon/net/ena/ena_admin_defs.h
index e687b3b..a46e749 100644
--- a/drivers/amazon/net/ena/ena_admin_defs.h
+++ b/drivers/amazon/net/ena/ena_admin_defs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -32,198 +32,138 @@
 #ifndef _ENA_ADMIN_H_
 #define _ENA_ADMIN_H_
 
-/* admin commands opcodes */
 enum ena_admin_aq_opcode {
-	/* create submission queue */
-	ENA_ADMIN_CREATE_SQ = 1,
+	ENA_ADMIN_CREATE_SQ	= 1,
 
-	/* destroy submission queue */
-	ENA_ADMIN_DESTROY_SQ = 2,
+	ENA_ADMIN_DESTROY_SQ	= 2,
 
-	/* create completion queue */
-	ENA_ADMIN_CREATE_CQ = 3,
+	ENA_ADMIN_CREATE_CQ	= 3,
 
-	/* destroy completion queue */
-	ENA_ADMIN_DESTROY_CQ = 4,
+	ENA_ADMIN_DESTROY_CQ	= 4,
 
-	/* get capabilities of particular feature */
-	ENA_ADMIN_GET_FEATURE = 8,
+	ENA_ADMIN_GET_FEATURE	= 8,
 
-	/* get capabilities of particular feature */
-	ENA_ADMIN_SET_FEATURE = 9,
+	ENA_ADMIN_SET_FEATURE	= 9,
 
-	/* get statistics */
-	ENA_ADMIN_GET_STATS = 11,
+	ENA_ADMIN_GET_STATS	= 11,
 };
 
-/* privileged amdin commands opcodes */
-enum ena_admin_aq_opcode_privileged {
-	/* get device capabilities */
-	ENA_ADMIN_IDENTIFY = 48,
-
-	/* configure device */
-	ENA_ADMIN_CONFIGURE_PF_DEVICE = 49,
-
-	/* setup SRIOV PCIe Virtual Function capabilities */
-	ENA_ADMIN_SETUP_VF = 50,
-
-	/* load firmware to the controller */
-	ENA_ADMIN_LOAD_FIRMWARE = 52,
-
-	/* commit previously loaded firmare */
-	ENA_ADMIN_COMMIT_FIRMWARE = 53,
-
-	/* quiesce virtual function */
-	ENA_ADMIN_QUIESCE_VF = 54,
-
-	/* load virtual function from migrates context */
-	ENA_ADMIN_MIGRATE_VF = 55,
-};
-
-/* admin command completion status codes */
 enum ena_admin_aq_completion_status {
-	/* Request completed successfully */
-	ENA_ADMIN_SUCCESS = 0,
+	ENA_ADMIN_SUCCESS			= 0,
 
-	/* no resources to satisfy request */
-	ENA_ADMIN_RESOURCE_ALLOCATION_FAILURE = 1,
+	ENA_ADMIN_RESOURCE_ALLOCATION_FAILURE	= 1,
 
-	/* Bad opcode in request descriptor */
-	ENA_ADMIN_BAD_OPCODE = 2,
+	ENA_ADMIN_BAD_OPCODE			= 2,
 
-	/* Unsupported opcode in request descriptor */
-	ENA_ADMIN_UNSUPPORTED_OPCODE = 3,
+	ENA_ADMIN_UNSUPPORTED_OPCODE		= 3,
 
-	/* Wrong request format */
-	ENA_ADMIN_MALFORMED_REQUEST = 4,
+	ENA_ADMIN_MALFORMED_REQUEST		= 4,
 
-	/* One of parameters is not valid. Provided in ACQ entry
-	 * extended_status
-	 */
-	ENA_ADMIN_ILLEGAL_PARAMETER = 5,
+	/* Additional status is provided in ACQ entry extended_status */
+	ENA_ADMIN_ILLEGAL_PARAMETER		= 5,
 
-	/* unexpected error */
-	ENA_ADMIN_UNKNOWN_ERROR = 6,
+	ENA_ADMIN_UNKNOWN_ERROR			= 6,
 };
 
-/* get/set feature subcommands opcodes */
 enum ena_admin_aq_feature_id {
-	/* list of all supported attributes/capabilities in the ENA */
-	ENA_ADMIN_DEVICE_ATTRIBUTES = 1,
+	ENA_ADMIN_DEVICE_ATTRIBUTES		= 1,
 
-	/* max number of supported queues per for every queues type */
-	ENA_ADMIN_MAX_QUEUES_NUM = 2,
+	ENA_ADMIN_MAX_QUEUES_NUM		= 2,
 
-	/* Receive Side Scaling (RSS) function */
-	ENA_ADMIN_RSS_HASH_FUNCTION = 10,
+	ENA_ADMIN_RSS_HASH_FUNCTION		= 10,
 
-	/* stateless TCP/UDP/IP offload capabilities. */
-	ENA_ADMIN_STATELESS_OFFLOAD_CONFIG = 11,
+	ENA_ADMIN_STATELESS_OFFLOAD_CONFIG	= 11,
 
-	/* Multiple tuples flow table configuration */
-	ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG = 12,
+	ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG	= 12,
 
-	/* max MTU, current MTU */
-	ENA_ADMIN_MTU = 14,
+	ENA_ADMIN_MTU				= 14,
 
-	/* Receive Side Scaling (RSS) hash input */
-	ENA_ADMIN_RSS_HASH_INPUT = 18,
+	ENA_ADMIN_RSS_HASH_INPUT		= 18,
 
-	/* interrupt moderation parameters */
-	ENA_ADMIN_INTERRUPT_MODERATION = 20,
+	ENA_ADMIN_INTERRUPT_MODERATION		= 20,
 
-	/* AENQ configuration */
-	ENA_ADMIN_AENQ_CONFIG = 26,
+	ENA_ADMIN_AENQ_CONFIG			= 26,
 
-	/* Link configuration */
-	ENA_ADMIN_LINK_CONFIG = 27,
+	ENA_ADMIN_LINK_CONFIG			= 27,
 
-	/* Host attributes configuration */
-	ENA_ADMIN_HOST_ATTR_CONFIG = 28,
+	ENA_ADMIN_HOST_ATTR_CONFIG		= 28,
 
-	/* Number of valid opcodes */
-	ENA_ADMIN_FEATURES_OPCODE_NUM = 32,
+	ENA_ADMIN_FEATURES_OPCODE_NUM		= 32,
 };
 
-/* descriptors and headers placement */
 enum ena_admin_placement_policy_type {
-	/* descriptors and headers are in OS memory */
-	ENA_ADMIN_PLACEMENT_POLICY_HOST = 1,
+	/* descriptors and headers are in host memory */
+	ENA_ADMIN_PLACEMENT_POLICY_HOST	= 1,
 
-	/* descriptors and headers in device memory (a.k.a Low Latency
+	/* descriptors and headers are in device memory (a.k.a Low Latency
 	 * Queue)
 	 */
-	ENA_ADMIN_PLACEMENT_POLICY_DEV = 3,
+	ENA_ADMIN_PLACEMENT_POLICY_DEV	= 3,
 };
 
-/* link speeds */
 enum ena_admin_link_types {
-	ENA_ADMIN_LINK_SPEED_1G = 0x1,
+	ENA_ADMIN_LINK_SPEED_1G		= 0x1,
 
-	ENA_ADMIN_LINK_SPEED_2_HALF_G = 0x2,
+	ENA_ADMIN_LINK_SPEED_2_HALF_G	= 0x2,
 
-	ENA_ADMIN_LINK_SPEED_5G = 0x4,
+	ENA_ADMIN_LINK_SPEED_5G		= 0x4,
 
-	ENA_ADMIN_LINK_SPEED_10G = 0x8,
+	ENA_ADMIN_LINK_SPEED_10G	= 0x8,
 
-	ENA_ADMIN_LINK_SPEED_25G = 0x10,
+	ENA_ADMIN_LINK_SPEED_25G	= 0x10,
 
-	ENA_ADMIN_LINK_SPEED_40G = 0x20,
+	ENA_ADMIN_LINK_SPEED_40G	= 0x20,
 
-	ENA_ADMIN_LINK_SPEED_50G = 0x40,
+	ENA_ADMIN_LINK_SPEED_50G	= 0x40,
 
-	ENA_ADMIN_LINK_SPEED_100G = 0x80,
+	ENA_ADMIN_LINK_SPEED_100G	= 0x80,
 
-	ENA_ADMIN_LINK_SPEED_200G = 0x100,
+	ENA_ADMIN_LINK_SPEED_200G	= 0x100,
 
-	ENA_ADMIN_LINK_SPEED_400G = 0x200,
+	ENA_ADMIN_LINK_SPEED_400G	= 0x200,
 };
 
-/* completion queue update policy */
 enum ena_admin_completion_policy_type {
-	/* cqe for each sq descriptor */
-	ENA_ADMIN_COMPLETION_POLICY_DESC = 0,
+	/* completion queue entry for each sq descriptor */
+	ENA_ADMIN_COMPLETION_POLICY_DESC		= 0,
 
-	/* cqe upon request in sq descriptor */
-	ENA_ADMIN_COMPLETION_POLICY_DESC_ON_DEMAND = 1,
+	/* completion queue entry upon request in sq descriptor */
+	ENA_ADMIN_COMPLETION_POLICY_DESC_ON_DEMAND	= 1,
 
 	/* current queue head pointer is updated in OS memory upon sq
 	 * descriptor request
 	 */
-	ENA_ADMIN_COMPLETION_POLICY_HEAD_ON_DEMAND = 2,
+	ENA_ADMIN_COMPLETION_POLICY_HEAD_ON_DEMAND	= 2,
 
 	/* current queue head pointer is updated in OS memory for each sq
 	 * descriptor
 	 */
-	ENA_ADMIN_COMPLETION_POLICY_HEAD = 3,
+	ENA_ADMIN_COMPLETION_POLICY_HEAD		= 3,
 };
 
-/* type of get statistics command */
+/* basic stats return ena_admin_basic_stats while extanded stats return a
+ * buffer (string format) with additional statistics per queue and per
+ * device id
+ */
 enum ena_admin_get_stats_type {
-	/* Basic statistics */
-	ENA_ADMIN_GET_STATS_TYPE_BASIC = 0,
+	ENA_ADMIN_GET_STATS_TYPE_BASIC		= 0,
 
-	/* Extended statistics */
-	ENA_ADMIN_GET_STATS_TYPE_EXTENDED = 1,
+	ENA_ADMIN_GET_STATS_TYPE_EXTENDED	= 1,
 };
 
-/* scope of get statistics command */
 enum ena_admin_get_stats_scope {
-	ENA_ADMIN_SPECIFIC_QUEUE = 0,
+	ENA_ADMIN_SPECIFIC_QUEUE	= 0,
 
-	ENA_ADMIN_ETH_TRAFFIC = 1,
+	ENA_ADMIN_ETH_TRAFFIC		= 1,
 };
 
-/* ENA Admin Queue (AQ) common descriptor */
 struct ena_admin_aq_common_desc {
-	/* word 0 : */
-	/* command identificator to associate it with the completion
-	 * 11:0 : command_id
+	/* 11:0 : command_id
 	 * 15:12 : reserved12
 	 */
 	u16 command_id;
 
-	/* as appears in ena_aq_opcode */
+	/* as appears in ena_admin_aq_opcode */
 	u8 opcode;
 
 	/* 0 : phase
@@ -236,24 +176,17 @@ struct ena_admin_aq_common_desc {
 	u8 flags;
 };
 
-/* used in ena_aq_entry. Can point directly to control data, or to a page
- * list chunk. Used also at the end of indirect mode page list chunks, for
- * chaining.
+/* used in ena_admin_aq_entry. Can point directly to control data, or to a
+ * page list chunk. Used also at the end of indirect mode page list chunks,
+ * for chaining.
  */
 struct ena_admin_ctrl_buff_info {
-	/* word 0 : indicates length of the buffer pointed by
-	 * control_buffer_address.
-	 */
 	u32 length;
 
-	/* words 1:2 : points to control buffer (direct or indirect) */
 	struct ena_common_mem_addr address;
 };
 
-/* submission queue full identification */
 struct ena_admin_sq {
-	/* word 0 : */
-	/* queue id */
 	u16 sq_idx;
 
 	/* 4:0 : reserved
@@ -264,36 +197,25 @@ struct ena_admin_sq {
 	u8 reserved1;
 };
 
-/* AQ entry format */
 struct ena_admin_aq_entry {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* words 1:3 :  */
 	union {
-		/* command specific inline data */
 		u32 inline_data_w1[3];
 
-		/* words 1:3 : points to control buffer (direct or
-		 * indirect, chained if needed)
-		 */
 		struct ena_admin_ctrl_buff_info control_buffer;
 	} u;
 
-	/* command specific inline data */
 	u32 inline_data_w4[12];
 };
 
-/* ENA Admin Completion Queue (ACQ) common descriptor */
 struct ena_admin_acq_common_desc {
-	/* word 0 : */
 	/* command identifier to associate it with the aq descriptor
 	 * 11:0 : command_id
 	 * 15:12 : reserved12
 	 */
 	u16 command;
 
-	/* status of request execution */
 	u8 status;
 
 	/* 0 : phase
@@ -301,33 +223,21 @@ struct ena_admin_acq_common_desc {
 	 */
 	u8 flags;
 
-	/* word 1 : */
-	/* provides additional info */
 	u16 extended_status;
 
-	/* submission queue head index, serves as a hint what AQ entries can
-	 *    be revoked
-	 */
+	/* serves as a hint what AQ entries can be revoked */
 	u16 sq_head_indx;
 };
 
-/* ACQ entry format */
 struct ena_admin_acq_entry {
-	/* words 0:1 :  */
 	struct ena_admin_acq_common_desc acq_common_descriptor;
 
-	/* response type specific data */
 	u32 response_specific_data[14];
 };
 
-/* ENA AQ Create Submission Queue command. Placed in control buffer pointed
- * by AQ entry
- */
 struct ena_admin_aq_create_sq_cmd {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* word 1 : */
 	/* 4:0 : reserved0_w1
 	 * 7:5 : sq_direction - 0x1 - Tx, 0x2 - Rx
 	 */
@@ -359,7 +269,6 @@ struct ena_admin_aq_create_sq_cmd {
 	 */
 	u8 sq_caps_3;
 
-	/* word 2 : */
 	/* associated completion queue id. This CQ must be created prior to
 	 *    SQ creation
 	 */
@@ -368,85 +277,62 @@ struct ena_admin_aq_create_sq_cmd {
 	/* submission queue depth in entries */
 	u16 sq_depth;
 
-	/* words 3:4 : SQ physical base address in OS memory. This field
-	 * should not be used for Low Latency queues. Has to be page
-	 * aligned.
+	/* SQ physical base address in OS memory. This field should not be
+	 * used for Low Latency queues. Has to be page aligned.
 	 */
 	struct ena_common_mem_addr sq_ba;
 
-	/* words 5:6 : specifies queue head writeback location in OS
-	 * memory. Valid if completion_policy is set to
-	 * completion_policy_head_on_demand or completion_policy_head. Has
-	 * to be cache aligned
+	/* specifies queue head writeback location in OS memory. Valid if
+	 * completion_policy is set to completion_policy_head_on_demand or
+	 * completion_policy_head. Has to be cache aligned
 	 */
 	struct ena_common_mem_addr sq_head_writeback;
 
-	/* word 7 : reserved word */
 	u32 reserved0_w7;
 
-	/* word 8 : reserved word */
 	u32 reserved0_w8;
 };
 
-/* submission queue direction */
 enum ena_admin_sq_direction {
-	ENA_ADMIN_SQ_DIRECTION_TX = 1,
+	ENA_ADMIN_SQ_DIRECTION_TX	= 1,
 
-	ENA_ADMIN_SQ_DIRECTION_RX = 2,
+	ENA_ADMIN_SQ_DIRECTION_RX	= 2,
 };
 
-/* ENA Response for Create SQ Command. Appears in ACQ entry as
- * response_specific_data
- */
 struct ena_admin_acq_create_sq_resp_desc {
-	/* words 0:1 : Common Admin Queue completion descriptor */
 	struct ena_admin_acq_common_desc acq_common_desc;
 
-	/* word 2 : */
-	/* sq identifier */
 	u16 sq_idx;
 
 	u16 reserved;
 
-	/* word 3 : queue doorbell address as an offset to PCIe MMIO REG BAR */
+	/* queue doorbell address as an offset to PCIe MMIO REG BAR */
 	u32 sq_doorbell_offset;
 
-	/* word 4 : low latency queue ring base address as an offset to
-	 * PCIe MMIO LLQ_MEM BAR
+	/* low latency queue ring base address as an offset to PCIe MMIO
+	 * LLQ_MEM BAR
 	 */
 	u32 llq_descriptors_offset;
 
-	/* word 5 : low latency queue headers' memory as an offset to PCIe
-	 * MMIO LLQ_MEM BAR
+	/* low latency queue headers' memory as an offset to PCIe MMIO
+	 * LLQ_MEM BAR
 	 */
 	u32 llq_headers_offset;
 };
 
-/* ENA AQ Destroy Submission Queue command. Placed in control buffer
- * pointed by AQ entry
- */
 struct ena_admin_aq_destroy_sq_cmd {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* words 1 :  */
 	struct ena_admin_sq sq;
 };
 
-/* ENA Response for Destroy SQ Command. Appears in ACQ entry as
- * response_specific_data
- */
 struct ena_admin_acq_destroy_sq_resp_desc {
-	/* words 0:1 : Common Admin Queue completion descriptor */
 	struct ena_admin_acq_common_desc acq_common_desc;
 };
 
-/* ENA AQ Create Completion Queue command */
 struct ena_admin_aq_create_cq_cmd {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* word 1 : */
 	/* 4:0 : reserved5
 	 * 5 : interrupt_mode_enabled - if set, cq operates
 	 *    in interrupt mode, otherwise - polling
@@ -463,62 +349,39 @@ struct ena_admin_aq_create_cq_cmd {
 	/* completion queue depth in # of entries. must be power of 2 */
 	u16 cq_depth;
 
-	/* word 2 : msix vector assigned to this cq */
+	/* msix vector assigned to this cq */
 	u32 msix_vector;
 
-	/* words 3:4 : cq physical base address in OS memory. CQ must be
-	 * physically contiguous
+	/* cq physical base address in OS memory. CQ must be physically
+	 * contiguous
 	 */
 	struct ena_common_mem_addr cq_ba;
 };
 
-/* ENA Response for Create CQ Command. Appears in ACQ entry as response
- * specific data
- */
 struct ena_admin_acq_create_cq_resp_desc {
-	/* words 0:1 : Common Admin Queue completion descriptor */
 	struct ena_admin_acq_common_desc acq_common_desc;
 
-	/* word 2 : */
-	/* cq identifier */
 	u16 cq_idx;
 
-	/* actual cq depth in # of entries */
+	/* actual cq depth in number of entries */
 	u16 cq_actual_depth;
 
-	/* word 3 : cpu numa node address as an offset to PCIe MMIO REG BAR */
 	u32 numa_node_register_offset;
 
-	/* word 4 : completion head doorbell address as an offset to PCIe
-	 * MMIO REG BAR
-	 */
 	u32 cq_head_db_register_offset;
 
-	/* word 5 : interrupt unmask register address as an offset into
-	 * PCIe MMIO REG BAR
-	 */
 	u32 cq_interrupt_unmask_register_offset;
 };
 
-/* ENA AQ Destroy Completion Queue command. Placed in control buffer
- * pointed by AQ entry
- */
 struct ena_admin_aq_destroy_cq_cmd {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* word 1 : */
-	/* associated queue id. */
 	u16 cq_idx;
 
 	u16 reserved1;
 };
 
-/* ENA Response for Destroy CQ Command. Appears in ACQ entry as
- * response_specific_data
- */
 struct ena_admin_acq_destroy_cq_resp_desc {
-	/* words 0:1 : Common Admin Queue completion descriptor */
 	struct ena_admin_acq_common_desc acq_common_desc;
 };
 
@@ -526,21 +389,15 @@ struct ena_admin_acq_destroy_cq_resp_desc {
  * buffer pointed by AQ entry
  */
 struct ena_admin_aq_get_stats_cmd {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* words 1:3 :  */
 	union {
 		/* command specific inline data */
 		u32 inline_data_w1[3];
 
-		/* words 1:3 : points to control buffer (direct or
-		 * indirect, chained if needed)
-		 */
 		struct ena_admin_ctrl_buff_info control_buffer;
 	} u;
 
-	/* word 4 : */
 	/* stats type as defined in enum ena_admin_get_stats_type */
 	u8 type;
 
@@ -549,7 +406,6 @@ struct ena_admin_aq_get_stats_cmd {
 
 	u16 reserved3;
 
-	/* word 5 : */
 	/* queue id. used when scope is specific_queue */
 	u16 queue_idx;
 
@@ -561,89 +417,60 @@ struct ena_admin_aq_get_stats_cmd {
 
 /* Basic Statistics Command. */
 struct ena_admin_basic_stats {
-	/* word 0 :  */
 	u32 tx_bytes_low;
 
-	/* word 1 :  */
 	u32 tx_bytes_high;
 
-	/* word 2 :  */
 	u32 tx_pkts_low;
 
-	/* word 3 :  */
 	u32 tx_pkts_high;
 
-	/* word 4 :  */
 	u32 rx_bytes_low;
 
-	/* word 5 :  */
 	u32 rx_bytes_high;
 
-	/* word 6 :  */
 	u32 rx_pkts_low;
 
-	/* word 7 :  */
 	u32 rx_pkts_high;
 
-	/* word 8 :  */
 	u32 rx_drops_low;
 
-	/* word 9 :  */
 	u32 rx_drops_high;
 };
 
-/* ENA Response for Get Statistics Command. Appears in ACQ entry as
- * response_specific_data
- */
 struct ena_admin_acq_get_stats_resp {
-	/* words 0:1 : Common Admin Queue completion descriptor */
 	struct ena_admin_acq_common_desc acq_common_desc;
 
-	/* words 2:11 :  */
 	struct ena_admin_basic_stats basic_stats;
 };
 
-/* ENA Get/Set Feature common descriptor. Appears as inline word in
- * ena_aq_entry
- */
 struct ena_admin_get_set_feature_common_desc {
-	/* word 0 : */
 	/* 1:0 : select - 0x1 - current value; 0x3 - default
 	 *    value
 	 * 7:3 : reserved3
 	 */
 	u8 flags;
 
-	/* as appears in ena_feature_id */
+	/* as appears in ena_admin_aq_feature_id */
 	u8 feature_id;
 
-	/* reserved16 */
 	u16 reserved16;
 };
 
-/* ENA Device Attributes Feature descriptor. */
 struct ena_admin_device_attr_feature_desc {
-	/* word 0 : implementation id */
 	u32 impl_id;
 
-	/* word 1 : device version */
 	u32 device_version;
 
-	/* word 2 : bit map of which bits are supported value of 1
-	 * indicated that this feature is supported and can perform SET/GET
-	 * for it
-	 */
+	/* bitmap of ena_admin_aq_feature_id */
 	u32 supported_features;
 
-	/* word 3 :  */
 	u32 reserved3;
 
-	/* word 4 : Indicates how many bits are used physical address
-	 * access.
-	 */
+	/* Indicates how many bits are used physical address access. */
 	u32 phys_addr_width;
 
-	/* word 5 : Indicates how many bits are used virtual address access. */
+	/* Indicates how many bits are used virtual address access. */
 	u32 virt_addr_width;
 
 	/* unicast MAC address (in Network byte order) */
@@ -651,36 +478,27 @@ struct ena_admin_device_attr_feature_desc {
 
 	u8 reserved7[2];
 
-	/* word 8 : Max supported MTU value */
 	u32 max_mtu;
 };
 
-/* ENA Max Queues Feature descriptor. */
 struct ena_admin_queue_feature_desc {
-	/* word 0 : Max number of submission queues (including LLQs) */
+	/* including LLQs */
 	u32 max_sq_num;
 
-	/* word 1 : Max submission queue depth */
 	u32 max_sq_depth;
 
-	/* word 2 : Max number of completion queues */
 	u32 max_cq_num;
 
-	/* word 3 : Max completion queue depth */
 	u32 max_cq_depth;
 
-	/* word 4 : Max number of LLQ submission queues */
 	u32 max_llq_num;
 
-	/* word 5 : Max submission queue depth of LLQ */
 	u32 max_llq_depth;
 
-	/* word 6 : Max header size */
 	u32 max_header_size;
 
-	/* word 7 : */
-	/* Maximum Descriptors number, including meta descriptors, allowed
-	 *    for a single Tx packet
+	/* Maximum Descriptors number, including meta descriptor, allowed for
+	 *    a single Tx packet
 	 */
 	u16 max_packet_tx_descs;
 
@@ -688,86 +506,69 @@ struct ena_admin_queue_feature_desc {
 	u16 max_packet_rx_descs;
 };
 
-/* ENA MTU Set Feature descriptor. */
 struct ena_admin_set_feature_mtu_desc {
-	/* word 0 : mtu size including L2 */
+	/* exclude L2 */
 	u32 mtu;
 };
 
-/* ENA host attributes Set Feature descriptor. */
 struct ena_admin_set_feature_host_attr_desc {
-	/* words 0:1 : host OS info base address in OS memory. host info is
-	 * 4KB of physically contiguous
+	/* host OS info base address in OS memory. host info is 4KB of
+	 * physically contiguous
 	 */
 	struct ena_common_mem_addr os_info_ba;
 
-	/* words 2:3 : host debug area base address in OS memory. debug
-	 * area must be physically contiguous
+	/* host debug area base address in OS memory. debug area must be
+	 * physically contiguous
 	 */
 	struct ena_common_mem_addr debug_ba;
 
-	/* word 4 : debug area size */
+	/* debug area size */
 	u32 debug_area_size;
 };
 
-/* ENA Interrupt Moderation Get Feature descriptor. */
 struct ena_admin_feature_intr_moder_desc {
-	/* word 0 : */
 	/* interrupt delay granularity in usec */
 	u16 intr_delay_resolution;
 
 	u16 reserved;
 };
 
-/* ENA Link Get Feature descriptor. */
 struct ena_admin_get_feature_link_desc {
-	/* word 0 : Link speed in Mb */
+	/* Link speed in Mb */
 	u32 speed;
 
-	/* word 1 : supported speeds (bit field of enum ena_admin_link
-	 * types)
-	 */
+	/* bit field of enum ena_admin_link types */
 	u32 supported;
 
-	/* word 2 : */
-	/* 0 : autoneg - auto negotiation
+	/* 0 : autoneg
 	 * 1 : duplex - Full Duplex
 	 * 31:2 : reserved2
 	 */
 	u32 flags;
 };
 
-/* ENA AENQ Feature descriptor. */
 struct ena_admin_feature_aenq_desc {
-	/* word 0 : bitmask for AENQ groups the device can report */
+	/* bitmask for AENQ groups the device can report */
 	u32 supported_groups;
 
-	/* word 1 : bitmask for AENQ groups to report */
+	/* bitmask for AENQ groups to report */
 	u32 enabled_groups;
 };
 
-/* ENA Stateless Offload Feature descriptor. */
 struct ena_admin_feature_offload_desc {
-	/* word 0 : */
-	/* Trasmit side stateless offload
-	 * 0 : TX_L3_csum_ipv4 - IPv4 checksum
-	 * 1 : TX_L4_ipv4_csum_part - TCP/UDP over IPv4
-	 *    checksum, the checksum field should be initialized
-	 *    with pseudo header checksum
-	 * 2 : TX_L4_ipv4_csum_full - TCP/UDP over IPv4
-	 *    checksum
-	 * 3 : TX_L4_ipv6_csum_part - TCP/UDP over IPv6
-	 *    checksum, the checksum field should be initialized
-	 *    with pseudo header checksum
-	 * 4 : TX_L4_ipv6_csum_full - TCP/UDP over IPv6
-	 *    checksum
-	 * 5 : tso_ipv4 - TCP/IPv4 Segmentation Offloading
-	 * 6 : tso_ipv6 - TCP/IPv6 Segmentation Offloading
-	 * 7 : tso_ecn - TCP Segmentation with ECN
+	/* 0 : TX_L3_csum_ipv4
+	 * 1 : TX_L4_ipv4_csum_part - The checksum field
+	 *    should be initialized with pseudo header checksum
+	 * 2 : TX_L4_ipv4_csum_full
+	 * 3 : TX_L4_ipv6_csum_part - The checksum field
+	 *    should be initialized with pseudo header checksum
+	 * 4 : TX_L4_ipv6_csum_full
+	 * 5 : tso_ipv4
+	 * 6 : tso_ipv6
+	 * 7 : tso_ecn
 	 */
 	u32 tx;
 
-	/* word 1 : */
 	/* Receive side supported stateless offload
 	 * 0 : RX_L3_csum_ipv4 - IPv4 checksum
 	 * 1 : RX_L4_ipv4_csum - TCP/UDP/IPv4 checksum
@@ -776,135 +577,98 @@ struct ena_admin_feature_offload_desc {
 	 */
 	u32 rx_supported;
 
-	/* word 2 : */
-	/* Receive side enabled stateless offload */
 	u32 rx_enabled;
 };
 
-/* hash functions */
 enum ena_admin_hash_functions {
-	/* Toeplitz hash */
-	ENA_ADMIN_TOEPLITZ = 1,
+	ENA_ADMIN_TOEPLITZ	= 1,
 
-	/* CRC32 hash */
-	ENA_ADMIN_CRC32 = 2,
+	ENA_ADMIN_CRC32		= 2,
 };
 
-/* ENA RSS flow hash control buffer structure */
 struct ena_admin_feature_rss_flow_hash_control {
-	/* word 0 : number of valid keys */
 	u32 keys_num;
 
-	/* word 1 :  */
 	u32 reserved;
 
-	/* Toeplitz keys */
 	u32 key[10];
 };
 
-/* ENA RSS Flow Hash Function */
 struct ena_admin_feature_rss_flow_hash_function {
-	/* word 0 : */
-	/* supported hash functions
-	 * 7:0 : funcs - supported hash functions (bitmask
-	 *    accroding to ena_admin_hash_functions)
-	 */
+	/* 7:0 : funcs - bitmask of ena_admin_hash_functions */
 	u32 supported_func;
 
-	/* word 1 : */
-	/* selected hash func
-	 * 7:0 : selected_func - selected hash function
-	 *    (bitmask accroding to ena_admin_hash_functions)
+	/* 7:0 : selected_func - bitmask of
+	 *    ena_admin_hash_functions
 	 */
 	u32 selected_func;
 
-	/* word 2 : initial value */
+	/* initial value */
 	u32 init_val;
 };
 
 /* RSS flow hash protocols */
 enum ena_admin_flow_hash_proto {
-	/* tcp/ipv4 */
-	ENA_ADMIN_RSS_TCP4 = 0,
+	ENA_ADMIN_RSS_TCP4	= 0,
 
-	/* udp/ipv4 */
-	ENA_ADMIN_RSS_UDP4 = 1,
+	ENA_ADMIN_RSS_UDP4	= 1,
 
-	/* tcp/ipv6 */
-	ENA_ADMIN_RSS_TCP6 = 2,
+	ENA_ADMIN_RSS_TCP6	= 2,
 
-	/* udp/ipv6 */
-	ENA_ADMIN_RSS_UDP6 = 3,
+	ENA_ADMIN_RSS_UDP6	= 3,
 
-	/* ipv4 not tcp/udp */
-	ENA_ADMIN_RSS_IP4 = 4,
+	ENA_ADMIN_RSS_IP4	= 4,
 
-	/* ipv6 not tcp/udp */
-	ENA_ADMIN_RSS_IP6 = 5,
+	ENA_ADMIN_RSS_IP6	= 5,
 
-	/* fragmented ipv4 */
-	ENA_ADMIN_RSS_IP4_FRAG = 6,
+	ENA_ADMIN_RSS_IP4_FRAG	= 6,
 
-	/* not ipv4/6 */
-	ENA_ADMIN_RSS_NOT_IP = 7,
+	ENA_ADMIN_RSS_NOT_IP	= 7,
 
-	/* max number of protocols */
-	ENA_ADMIN_RSS_PROTO_NUM = 16,
+	ENA_ADMIN_RSS_PROTO_NUM	= 16,
 };
 
 /* RSS flow hash fields */
 enum ena_admin_flow_hash_fields {
 	/* Ethernet Dest Addr */
-	ENA_ADMIN_RSS_L2_DA = 0,
+	ENA_ADMIN_RSS_L2_DA	= 0,
 
 	/* Ethernet Src Addr */
-	ENA_ADMIN_RSS_L2_SA = 1,
+	ENA_ADMIN_RSS_L2_SA	= 1,
 
 	/* ipv4/6 Dest Addr */
-	ENA_ADMIN_RSS_L3_DA = 2,
+	ENA_ADMIN_RSS_L3_DA	= 2,
 
 	/* ipv4/6 Src Addr */
-	ENA_ADMIN_RSS_L3_SA = 5,
+	ENA_ADMIN_RSS_L3_SA	= 5,
 
 	/* tcp/udp Dest Port */
-	ENA_ADMIN_RSS_L4_DP = 6,
+	ENA_ADMIN_RSS_L4_DP	= 6,
 
 	/* tcp/udp Src Port */
-	ENA_ADMIN_RSS_L4_SP = 7,
+	ENA_ADMIN_RSS_L4_SP	= 7,
 };
 
-/* hash input fields for flow protocol */
 struct ena_admin_proto_input {
-	/* word 0 : */
 	/* flow hash fields (bitwise according to ena_admin_flow_hash_fields) */
 	u16 fields;
 
-	/* 0 : inner - for tunneled packet, select the fields
-	 *    from inner header
-	 */
-	u16 flags;
+	u16 reserved2;
 };
 
-/* ENA RSS hash control buffer structure */
 struct ena_admin_feature_rss_hash_control {
-	/* supported input fields */
 	struct ena_admin_proto_input supported_fields[ENA_ADMIN_RSS_PROTO_NUM];
 
-	/* selected input fields */
 	struct ena_admin_proto_input selected_fields[ENA_ADMIN_RSS_PROTO_NUM];
 
-	/* supported input fields for inner header */
-	struct ena_admin_proto_input supported_inner_fields[ENA_ADMIN_RSS_PROTO_NUM];
+	struct ena_admin_proto_input reserved2[ENA_ADMIN_RSS_PROTO_NUM];
 
-	/* selected input fields */
-	struct ena_admin_proto_input selected_inner_fields[ENA_ADMIN_RSS_PROTO_NUM];
+	struct ena_admin_proto_input reserved3[ENA_ADMIN_RSS_PROTO_NUM];
 };
 
-/* ENA RSS flow hash input */
 struct ena_admin_feature_rss_flow_hash_input {
-	/* word 0 : */
 	/* supported hash input sorting
-	 * 1 : L3_sort - support swap L3 addresses if DA
+	 * 1 : L3_sort - support swap L3 addresses if DA is
 	 *    smaller than SA
 	 * 2 : L4_sort - support swap L4 ports if DP smaller
 	 *    SP
@@ -920,46 +684,37 @@ struct ena_admin_feature_rss_flow_hash_input {
 	u16 enabled_input_sort;
 };
 
-/* Operating system type */
 enum ena_admin_os_type {
-	/* Linux OS */
-	ENA_ADMIN_OS_LINUX = 1,
+	ENA_ADMIN_OS_LINUX	= 1,
 
-	/* Windows OS */
-	ENA_ADMIN_OS_WIN = 2,
+	ENA_ADMIN_OS_WIN	= 2,
 
-	/* DPDK OS */
-	ENA_ADMIN_OS_DPDK = 3,
+	ENA_ADMIN_OS_DPDK	= 3,
 
-	/* FreeBSD OS */
-	ENA_ADMIN_OS_FREE_BSD = 4,
+	ENA_ADMIN_OS_FREEBSD	= 4,
 
-	/* PXE OS */
-	ENA_ADMIN_OS_PXE = 5,
+	ENA_ADMIN_OS_IPXE	= 5,
 };
 
-/* host info */
 struct ena_admin_host_info {
-	/* word 0 : OS type defined in enum ena_os_type */
+	/* defined in enum ena_admin_os_type */
 	u32 os_type;
 
 	/* os distribution string format */
 	u8 os_dist_str[128];
 
-	/* word 33 : OS distribution numeric format */
+	/* OS distribution numeric format */
 	u32 os_dist;
 
 	/* kernel version string format */
 	u8 kernel_ver_str[32];
 
-	/* word 42 : Kernel version numeric format */
+	/* Kernel version numeric format */
 	u32 kernel_ver;
 
-	/* word 43 : */
-	/* driver version
-	 * 7:0 : major - major
-	 * 15:8 : minor - minor
-	 * 23:16 : sub_minor - sub minor
+	/* 7:0 : major
+	 * 15:8 : minor
+	 * 23:16 : sub_minor
 	 */
 	u32 driver_version;
 
@@ -967,220 +722,163 @@ struct ena_admin_host_info {
 	u32 supported_network_features[4];
 };
 
-/* ENA RSS indirection table entry */
 struct ena_admin_rss_ind_table_entry {
-	/* word 0 : */
-	/* cq identifier */
 	u16 cq_idx;
 
 	u16 reserved;
 };
 
-/* ENA RSS indirection table */
 struct ena_admin_feature_rss_ind_table {
-	/* word 0 : */
 	/* min supported table size (2^min_size) */
 	u16 min_size;
 
 	/* max supported table size (2^max_size) */
 	u16 max_size;
 
-	/* word 1 : */
 	/* table size (2^size) */
 	u16 size;
 
 	u16 reserved;
 
-	/* word 2 : index of the inline entry. 0xFFFFFFFF means invalid */
+	/* index of the inline entry. 0xFFFFFFFF means invalid */
 	u32 inline_index;
 
-	/* words 3 : used for updating single entry, ignored when setting
-	 * the entire table through the control buffer.
+	/* used for updating single entry, ignored when setting the entire
+	 * table through the control buffer.
 	 */
 	struct ena_admin_rss_ind_table_entry inline_entry;
 };
 
-/* ENA Get Feature command */
 struct ena_admin_get_feat_cmd {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* words 1:3 : points to control buffer (direct or indirect,
-	 * chained if needed)
-	 */
 	struct ena_admin_ctrl_buff_info control_buffer;
 
-	/* words 4 :  */
 	struct ena_admin_get_set_feature_common_desc feat_common;
 
-	/* words 5:15 :  */
-	union {
-		/* raw words */
-		u32 raw[11];
-	} u;
+	u32 raw[11];
 };
 
-/* ENA Get Feature command response */
 struct ena_admin_get_feat_resp {
-	/* words 0:1 :  */
 	struct ena_admin_acq_common_desc acq_common_desc;
 
-	/* words 2:15 :  */
 	union {
-		/* raw words */
 		u32 raw[14];
 
-		/* words 2:10 : Get Device Attributes */
 		struct ena_admin_device_attr_feature_desc dev_attr;
 
-		/* words 2:5 : Max queues num */
 		struct ena_admin_queue_feature_desc max_queue;
 
-		/* words 2:3 : AENQ configuration */
 		struct ena_admin_feature_aenq_desc aenq;
 
-		/* words 2:4 : Get Link configuration */
 		struct ena_admin_get_feature_link_desc link;
 
-		/* words 2:4 : offload configuration */
 		struct ena_admin_feature_offload_desc offload;
 
-		/* words 2:4 : rss flow hash function */
 		struct ena_admin_feature_rss_flow_hash_function flow_hash_func;
 
-		/* words 2 : rss flow hash input */
 		struct ena_admin_feature_rss_flow_hash_input flow_hash_input;
 
-		/* words 2:3 : rss indirection table */
 		struct ena_admin_feature_rss_ind_table ind_table;
 
-		/* words 2 : interrupt moderation configuration */
 		struct ena_admin_feature_intr_moder_desc intr_moderation;
 	} u;
 };
 
-/* ENA Set Feature command */
 struct ena_admin_set_feat_cmd {
-	/* words 0 :  */
 	struct ena_admin_aq_common_desc aq_common_descriptor;
 
-	/* words 1:3 : points to control buffer (direct or indirect,
-	 * chained if needed)
-	 */
 	struct ena_admin_ctrl_buff_info control_buffer;
 
-	/* words 4 :  */
 	struct ena_admin_get_set_feature_common_desc feat_common;
 
-	/* words 5:15 :  */
 	union {
-		/* raw words */
 		u32 raw[11];
 
-		/* words 5 : mtu size */
+		/* mtu size */
 		struct ena_admin_set_feature_mtu_desc mtu;
 
-		/* words 5:7 : host attributes */
+		/* host attributes */
 		struct ena_admin_set_feature_host_attr_desc host_attr;
 
-		/* words 5:6 : AENQ configuration */
+		/* AENQ configuration */
 		struct ena_admin_feature_aenq_desc aenq;
 
-		/* words 5:7 : rss flow hash function */
+		/* rss flow hash function */
 		struct ena_admin_feature_rss_flow_hash_function flow_hash_func;
 
-		/* words 5 : rss flow hash input */
+		/* rss flow hash input */
 		struct ena_admin_feature_rss_flow_hash_input flow_hash_input;
 
-		/* words 5:6 : rss indirection table */
+		/* rss indirection table */
 		struct ena_admin_feature_rss_ind_table ind_table;
 	} u;
 };
 
-/* ENA Set Feature command response */
 struct ena_admin_set_feat_resp {
-	/* words 0:1 :  */
 	struct ena_admin_acq_common_desc acq_common_desc;
 
-	/* words 2:15 :  */
 	union {
-		/* raw words */
 		u32 raw[14];
 	} u;
 };
 
-/* ENA Asynchronous Event Notification Queue descriptor.  */
 struct ena_admin_aenq_common_desc {
-	/* word 0 : */
 	u16 group;
 
 	u16 syndrom;
 
-	/* word 1 : */
 	/* 0 : phase */
 	u8 flags;
 
 	u8 reserved1[3];
 
-	/* word 2 : Timestamp LSB */
 	u32 timestamp_low;
 
-	/* word 3 : Timestamp MSB */
 	u32 timestamp_high;
 };
 
 /* asynchronous event notification groups */
 enum ena_admin_aenq_group {
-	/* Link State Change */
-	ENA_ADMIN_LINK_CHANGE = 0,
+	ENA_ADMIN_LINK_CHANGE		= 0,
 
-	ENA_ADMIN_FATAL_ERROR = 1,
+	ENA_ADMIN_FATAL_ERROR		= 1,
 
-	ENA_ADMIN_WARNING = 2,
+	ENA_ADMIN_WARNING		= 2,
 
-	ENA_ADMIN_NOTIFICATION = 3,
+	ENA_ADMIN_NOTIFICATION		= 3,
 
-	ENA_ADMIN_KEEP_ALIVE = 4,
+	ENA_ADMIN_KEEP_ALIVE		= 4,
 
-	ENA_ADMIN_AENQ_GROUPS_NUM = 5,
+	ENA_ADMIN_AENQ_GROUPS_NUM	= 5,
 };
 
-/* syndorm of AENQ notification group */
 enum ena_admin_aenq_notification_syndrom {
-	ENA_ADMIN_SUSPEND = 0,
+	ENA_ADMIN_SUSPEND	= 0,
 
-	ENA_ADMIN_RESUME = 1,
+	ENA_ADMIN_RESUME	= 1,
 };
 
-/* ENA Asynchronous Event Notification generic descriptor.  */
 struct ena_admin_aenq_entry {
-	/* words 0:3 :  */
 	struct ena_admin_aenq_common_desc aenq_common_desc;
 
 	/* command specific inline data */
 	u32 inline_data_w4[12];
 };
 
-/* ENA Asynchronous Event Notification Queue Link Change descriptor.  */
 struct ena_admin_aenq_link_change_desc {
-	/* words 0:3 :  */
 	struct ena_admin_aenq_common_desc aenq_common_desc;
 
-	/* word 4 : */
 	/* 0 : link_status */
 	u32 flags;
 };
 
-/* ENA MMIO Readless response interface */
 struct ena_admin_ena_mmio_req_read_less_resp {
-	/* word 0 : */
-	/* request id */
 	u16 req_id;
 
-	/* register offset */
 	u16 reg_off;
 
-	/* word 1 : value is valid when poll is cleared */
+	/* value is valid when poll is cleared */
 	u32 reg_val;
 };
 
@@ -1249,9 +947,6 @@ struct ena_admin_ena_mmio_req_read_less_resp {
 #define ENA_ADMIN_FEATURE_RSS_FLOW_HASH_FUNCTION_FUNCS_MASK GENMASK(7, 0)
 #define ENA_ADMIN_FEATURE_RSS_FLOW_HASH_FUNCTION_SELECTED_FUNC_MASK GENMASK(7, 0)
 
-/* proto_input */
-#define ENA_ADMIN_PROTO_INPUT_INNER_MASK BIT(0)
-
 /* feature_rss_flow_hash_input */
 #define ENA_ADMIN_FEATURE_RSS_FLOW_HASH_INPUT_L3_SORT_SHIFT 1
 #define ENA_ADMIN_FEATURE_RSS_FLOW_HASH_INPUT_L3_SORT_MASK BIT(1)
diff --git a/drivers/amazon/net/ena/ena_com.c b/drivers/amazon/net/ena/ena_com.c
index 1c79b14..b0b37c1 100644
--- a/drivers/amazon/net/ena/ena_com.c
+++ b/drivers/amazon/net/ena/ena_com.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -83,59 +83,63 @@ struct ena_comp_ctx {
 	bool occupied;
 };
 
+struct ena_com_stats_ctx {
+	struct ena_admin_aq_get_stats_cmd get_cmd;
+	struct ena_admin_acq_get_stats_resp get_resp;
+};
+
 static inline int ena_com_mem_addr_set(struct ena_com_dev *ena_dev,
 				       struct ena_common_mem_addr *ena_addr,
 				       dma_addr_t addr)
 {
 	if ((addr & GENMASK_ULL(ena_dev->dma_addr_bits - 1, 0)) != addr) {
-		ena_trc_err("dma address has more bits that the device supports\n");
+		pr_err("dma address has more bits that the device supports\n");
 		return -EINVAL;
 	}
 
 	ena_addr->mem_addr_low = (u32)addr;
-	ena_addr->mem_addr_high =
-		((addr & GENMASK_ULL(ena_dev->dma_addr_bits - 1, 32)) >> 32);
+	ena_addr->mem_addr_high = (u64)addr >> 32;
 
 	return 0;
 }
 
 static int ena_com_admin_init_sq(struct ena_com_admin_queue *queue)
 {
-	queue->sq.entries =
-		dma_alloc_coherent(queue->q_dmadev,
-				   ADMIN_SQ_SIZE(queue->q_depth),
-				   &queue->sq.dma_addr,
-				   GFP_KERNEL | __GFP_ZERO);
+	struct ena_com_admin_sq *sq = &queue->sq;
+	u16 size = ADMIN_SQ_SIZE(queue->q_depth);
+
+	sq->entries = dma_zalloc_coherent(queue->q_dmadev, size, &sq->dma_addr,
+					  GFP_KERNEL);
 
-	if (!queue->sq.entries) {
-		ena_trc_err("memory allocation failed");
+	if (!sq->entries) {
+		pr_err("memory allocation failed");
 		return -ENOMEM;
 	}
 
-	queue->sq.head = 0;
-	queue->sq.tail = 0;
-	queue->sq.phase = 1;
+	sq->head = 0;
+	sq->tail = 0;
+	sq->phase = 1;
 
-	queue->sq.db_addr = NULL;
+	sq->db_addr = NULL;
 
 	return 0;
 }
 
 static int ena_com_admin_init_cq(struct ena_com_admin_queue *queue)
 {
-	queue->cq.entries =
-		dma_alloc_coherent(queue->q_dmadev,
-				   ADMIN_CQ_SIZE(queue->q_depth),
-				   &queue->cq.dma_addr,
-				   GFP_KERNEL | __GFP_ZERO);
+	struct ena_com_admin_cq *cq = &queue->cq;
+	u16 size = ADMIN_CQ_SIZE(queue->q_depth);
+
+	cq->entries = dma_zalloc_coherent(queue->q_dmadev, size, &cq->dma_addr,
+					  GFP_KERNEL);
 
-	if (!queue->cq.entries)  {
-		ena_trc_err("memory allocation failed");
+	if (!cq->entries) {
+		pr_err("memory allocation failed");
 		return -ENOMEM;
 	}
 
-	queue->cq.head = 0;
-	queue->cq.phase = 1;
+	cq->head = 0;
+	cq->phase = 1;
 
 	return 0;
 }
@@ -143,42 +147,42 @@ static int ena_com_admin_init_cq(struct ena_com_admin_queue *queue)
 static int ena_com_admin_init_aenq(struct ena_com_dev *dev,
 				   struct ena_aenq_handlers *aenq_handlers)
 {
+	struct ena_com_aenq *aenq = &dev->aenq;
 	u32 addr_low, addr_high, aenq_caps;
+	u16 size;
 
 	dev->aenq.q_depth = ENA_ASYNC_QUEUE_DEPTH;
-	dev->aenq.entries =
-		dma_alloc_coherent(dev->dmadev,
-				   ADMIN_AENQ_SIZE(dev->aenq.q_depth),
-				   &dev->aenq.dma_addr,
-				   GFP_KERNEL | __GFP_ZERO);
-
-	if (!dev->aenq.entries) {
-		ena_trc_err("memory allocation failed");
+	size = ADMIN_AENQ_SIZE(ENA_ASYNC_QUEUE_DEPTH);
+	aenq->entries = dma_zalloc_coherent(dev->dmadev, size, &aenq->dma_addr,
+					    GFP_KERNEL);
+
+	if (!aenq->entries) {
+		pr_err("memory allocation failed");
 		return -ENOMEM;
 	}
 
-	dev->aenq.head = dev->aenq.q_depth;
-	dev->aenq.phase = 1;
+	aenq->head = aenq->q_depth;
+	aenq->phase = 1;
 
-	addr_low = ENA_DMA_ADDR_TO_UINT32_LOW(dev->aenq.dma_addr);
-	addr_high = ENA_DMA_ADDR_TO_UINT32_HIGH(dev->aenq.dma_addr);
+	addr_low = ENA_DMA_ADDR_TO_UINT32_LOW(aenq->dma_addr);
+	addr_high = ENA_DMA_ADDR_TO_UINT32_HIGH(aenq->dma_addr);
 
 	writel(addr_low, dev->reg_bar + ENA_REGS_AENQ_BASE_LO_OFF);
 	writel(addr_high, dev->reg_bar + ENA_REGS_AENQ_BASE_HI_OFF);
 
 	aenq_caps = 0;
 	aenq_caps |= dev->aenq.q_depth & ENA_REGS_AENQ_CAPS_AENQ_DEPTH_MASK;
-	aenq_caps |= (sizeof(struct ena_admin_aenq_entry) <<
-		ENA_REGS_AENQ_CAPS_AENQ_ENTRY_SIZE_SHIFT) &
-		ENA_REGS_AENQ_CAPS_AENQ_ENTRY_SIZE_MASK;
+	aenq_caps |= (sizeof(struct ena_admin_aenq_entry)
+		      << ENA_REGS_AENQ_CAPS_AENQ_ENTRY_SIZE_SHIFT) &
+		     ENA_REGS_AENQ_CAPS_AENQ_ENTRY_SIZE_MASK;
 	writel(aenq_caps, dev->reg_bar + ENA_REGS_AENQ_CAPS_OFF);
 
 	if (unlikely(!aenq_handlers)) {
-		ena_trc_err("aenq handlers pointer is NULL\n");
+		pr_err("aenq handlers pointer is NULL\n");
 		return -EINVAL;
 	}
 
-	dev->aenq.aenq_handlers = aenq_handlers;
+	aenq->aenq_handlers = aenq_handlers;
 
 	return 0;
 }
@@ -194,13 +198,13 @@ static struct ena_comp_ctx *get_comp_ctxt(struct ena_com_admin_queue *queue,
 					  u16 command_id, bool capture)
 {
 	if (unlikely(command_id >= queue->q_depth)) {
-		ena_trc_err("command id is larger than the queue size. cmd_id: %u queue size %d\n",
-			    command_id, queue->q_depth);
+		pr_err("command id is larger than the queue size. cmd_id: %u queue size %d\n",
+		       command_id, queue->q_depth);
 		return NULL;
 	}
 
 	if (unlikely(queue->comp_ctx[command_id].occupied && capture)) {
-		ena_trc_err("Completion context is occupied\n");
+		pr_err("Completion context is occupied\n");
 		return NULL;
 	}
 
@@ -230,10 +234,9 @@ static struct ena_comp_ctx *__ena_com_submit_admin_cmd(struct ena_com_admin_queu
 	/* In case of queue FULL */
 	cnt = admin_queue->sq.tail - admin_queue->sq.head;
 	if (cnt >= admin_queue->q_depth) {
-		ena_trc_dbg("admin queue is FULL (tail %d head %d depth: %d)\n",
-			    admin_queue->sq.tail,
-			    admin_queue->sq.head,
-			    admin_queue->q_depth);
+		pr_debug("admin queue is FULL (tail %d head %d depth: %d)\n",
+			 admin_queue->sq.tail, admin_queue->sq.head,
+			 admin_queue->q_depth);
 		admin_queue->stats.out_of_space++;
 		return ERR_PTR(-ENOSPC);
 	}
@@ -281,7 +284,7 @@ static inline int ena_com_init_comp_ctxt(struct ena_com_admin_queue *queue)
 
 	queue->comp_ctx = devm_kzalloc(queue->q_dmadev, size, GFP_KERNEL);
 	if (unlikely(!queue->comp_ctx)) {
-		ena_trc_err("memory allocation failed");
+		pr_err("memory allocation failed");
 		return -ENOMEM;
 	}
 
@@ -324,7 +327,7 @@ static int ena_com_init_io_sq(struct ena_com_dev *ena_dev,
 			      struct ena_com_io_sq *io_sq)
 {
 	size_t size;
-	int dev_node;
+	int dev_node = 0;
 
 	memset(&io_sq->desc_addr, 0x0, sizeof(struct ena_com_io_desc_addr));
 
@@ -339,30 +342,30 @@ static int ena_com_init_io_sq(struct ena_com_dev *ena_dev,
 		dev_node = dev_to_node(ena_dev->dmadev);
 		set_dev_node(ena_dev->dmadev, ctx->numa_node);
 		io_sq->desc_addr.virt_addr =
-			dma_alloc_coherent(ena_dev->dmadev,
-					   size,
-					   &io_sq->desc_addr.phys_addr,
-					   GFP_KERNEL | __GFP_ZERO);
+			dma_zalloc_coherent(ena_dev->dmadev, size,
+					    &io_sq->desc_addr.phys_addr,
+					    GFP_KERNEL);
 		set_dev_node(ena_dev->dmadev, dev_node);
-		if (!io_sq->desc_addr.virt_addr)
+		if (!io_sq->desc_addr.virt_addr) {
 			io_sq->desc_addr.virt_addr =
-				dma_alloc_coherent(ena_dev->dmadev,
-						   size,
-						   &io_sq->desc_addr.phys_addr,
-						   GFP_KERNEL | __GFP_ZERO);
+				dma_zalloc_coherent(ena_dev->dmadev, size,
+						    &io_sq->desc_addr.phys_addr,
+						    GFP_KERNEL);
+		}
 	} else {
 		dev_node = dev_to_node(ena_dev->dmadev);
-		set_dev_node(ena_dev->dmadev, dev_node);
+		set_dev_node(ena_dev->dmadev, ctx->numa_node);
 		io_sq->desc_addr.virt_addr =
 			devm_kzalloc(ena_dev->dmadev, size, GFP_KERNEL);
 		set_dev_node(ena_dev->dmadev, dev_node);
-		if (!io_sq->desc_addr.virt_addr)
+		if (!io_sq->desc_addr.virt_addr) {
 			io_sq->desc_addr.virt_addr =
 				devm_kzalloc(ena_dev->dmadev, size, GFP_KERNEL);
+		}
 	}
 
 	if (!io_sq->desc_addr.virt_addr) {
-		ena_trc_err("memory allocation failed");
+		pr_err("memory allocation failed");
 		return -ENOMEM;
 	}
 
@@ -378,7 +381,7 @@ static int ena_com_init_io_cq(struct ena_com_dev *ena_dev,
 			      struct ena_com_io_cq *io_cq)
 {
 	size_t size;
-	int prev_node;
+	int prev_node = 0;
 
 	memset(&io_cq->cdesc_addr, 0x0, sizeof(struct ena_com_io_desc_addr));
 
@@ -393,20 +396,18 @@ static int ena_com_init_io_cq(struct ena_com_dev *ena_dev,
 	prev_node = dev_to_node(ena_dev->dmadev);
 	set_dev_node(ena_dev->dmadev, ctx->numa_node);
 	io_cq->cdesc_addr.virt_addr =
-		dma_alloc_coherent(ena_dev->dmadev,
-				   size,
-				   &io_cq->cdesc_addr.phys_addr,
-				   GFP_KERNEL | __GFP_ZERO);
+		dma_zalloc_coherent(ena_dev->dmadev, size,
+				    &io_cq->cdesc_addr.phys_addr, GFP_KERNEL);
 	set_dev_node(ena_dev->dmadev, prev_node);
-	if (!io_cq->cdesc_addr.virt_addr)
+	if (!io_cq->cdesc_addr.virt_addr) {
 		io_cq->cdesc_addr.virt_addr =
-			dma_alloc_coherent(ena_dev->dmadev,
-					   size,
-					   &io_cq->cdesc_addr.phys_addr,
-					   GFP_KERNEL | __GFP_ZERO);
+			dma_zalloc_coherent(ena_dev->dmadev, size,
+					    &io_cq->cdesc_addr.phys_addr,
+					    GFP_KERNEL);
+	}
 
 	if (!io_cq->cdesc_addr.virt_addr) {
-		ena_trc_err("memory allocation failed");
+		pr_err("memory allocation failed");
 		return -ENOMEM;
 	}
 
@@ -427,7 +428,7 @@ static void ena_com_handle_single_admin_completion(struct ena_com_admin_queue *a
 
 	comp_ctx = get_comp_ctxt(admin_queue, cmd_id, false);
 	if (unlikely(!comp_ctx)) {
-		ena_trc_err("comp_ctx is NULL. Changing the admin queue running state\n");
+		pr_err("comp_ctx is NULL. Changing the admin queue running state\n");
 		admin_queue->running_state = false;
 		return;
 	}
@@ -482,7 +483,7 @@ static void ena_com_handle_admin_completion(struct ena_com_admin_queue *admin_qu
 static int ena_com_comp_status_to_errno(u8 comp_status)
 {
 	if (unlikely(comp_status != 0))
-		ena_trc_err("admin command failed[%u]\n", comp_status);
+		pr_err("admin command failed[%u]\n", comp_status);
 
 	if (unlikely(comp_status > ENA_ADMIN_UNKNOWN_ERROR))
 		return -EINVAL;
@@ -511,11 +512,12 @@ static int ena_com_wait_and_process_admin_cq_polling(struct ena_comp_ctx *comp_c
 	u32 start_time;
 	int ret;
 
-	start_time = ((uint32_t)jiffies_to_usecs(jiffies));
+	start_time = ((u32)jiffies_to_usecs(jiffies));
 
 	while (comp_ctx->status == ENA_CMD_SUBMITTED) {
-		if ((((uint32_t)jiffies_to_usecs(jiffies)) - start_time) > ADMIN_CMD_TIMEOUT_US) {
-			ena_trc_err("Wait for completion (polling) timeout\n");
+		if ((((u32)jiffies_to_usecs(jiffies)) - start_time) >
+		    ADMIN_CMD_TIMEOUT_US) {
+			pr_err("Wait for completion (polling) timeout\n");
 			/* ENA didn't have any completion */
 			spin_lock_irqsave(&admin_queue->q_lock, flags);
 			admin_queue->stats.no_completion++;
@@ -534,7 +536,7 @@ static int ena_com_wait_and_process_admin_cq_polling(struct ena_comp_ctx *comp_c
 	}
 
 	if (unlikely(comp_ctx->status == ENA_CMD_ABORTED)) {
-		ena_trc_err("Command was aborted\n");
+		pr_err("Command was aborted\n");
 		spin_lock_irqsave(&admin_queue->q_lock, flags);
 		admin_queue->stats.aborted_cmd++;
 		spin_unlock_irqrestore(&admin_queue->q_lock, flags);
@@ -542,8 +544,8 @@ static int ena_com_wait_and_process_admin_cq_polling(struct ena_comp_ctx *comp_c
 		goto err;
 	}
 
-	ENA_ASSERT(comp_ctx->status == ENA_CMD_COMPLETED,
-		   "Invalid comp status %d\n", comp_ctx->status);
+	WARN(comp_ctx->status != ENA_CMD_COMPLETED, "Invalid comp status %d\n",
+	     comp_ctx->status);
 
 	ret = ena_com_comp_status_to_errno(comp_ctx->comp_status);
 err:
@@ -555,7 +557,7 @@ static int ena_com_wait_and_process_admin_cq_interrupts(struct ena_comp_ctx *com
 							struct ena_com_admin_queue *admin_queue)
 {
 	unsigned long flags;
-	int ret = 0;
+	int ret;
 
 	wait_for_completion_timeout(&comp_ctx->wait_event,
 				    usecs_to_jiffies(ADMIN_CMD_TIMEOUT_US));
@@ -572,11 +574,11 @@ static int ena_com_wait_and_process_admin_cq_interrupts(struct ena_comp_ctx *com
 		spin_unlock_irqrestore(&admin_queue->q_lock, flags);
 
 		if (comp_ctx->status == ENA_CMD_COMPLETED)
-			ena_trc_err("The ena device have completion but the driver didn't receive any MSI-X interrupt (cmd %d)\n",
-				    comp_ctx->cmd_opcode);
+			pr_err("The ena device have completion but the driver didn't receive any MSI-X interrupt (cmd %d)\n",
+			       comp_ctx->cmd_opcode);
 		else
-			ena_trc_err("The ena device doesn't send any completion for the admin cmd %d status %d\n",
-				    comp_ctx->cmd_opcode, comp_ctx->status);
+			pr_err("The ena device doesn't send any completion for the admin cmd %d status %d\n",
+			       comp_ctx->cmd_opcode, comp_ctx->status);
 
 		admin_queue->running_state = false;
 		ret = -ETIME;
@@ -632,17 +634,15 @@ static u32 ena_com_reg_bar_read32(struct ena_com_dev *ena_dev, u16 offset)
 	}
 
 	if (unlikely(i == ENA_REG_READ_TIMEOUT)) {
-		ena_trc_err("reading reg failed for timeout. expected: req id[%hu] offset[%hu] actual: req id[%hu] offset[%hu]\n",
-			    mmio_read->seq_num,
-			    offset,
-			    read_resp->req_id,
-			    read_resp->reg_off);
+		pr_err("reading reg failed for timeout. expected: req id[%hu] offset[%hu] actual: req id[%hu] offset[%hu]\n",
+		       mmio_read->seq_num, offset, read_resp->req_id,
+		       read_resp->reg_off);
 		ret = ENA_MMIO_READ_TIMEOUT;
 		goto err;
 	}
 
 	if (read_resp->reg_off != offset) {
-		ena_trc_err("reading failed for wrong offset value");
+		pr_err("Read failure: wrong offset provided");
 		ret = ENA_MMIO_READ_TIMEOUT;
 	} else {
 		ret = read_resp->reg_val;
@@ -701,7 +701,7 @@ static int ena_com_destroy_io_sq(struct ena_com_dev *ena_dev,
 					    sizeof(destroy_resp));
 
 	if (unlikely(ret && (ret != -ENODEV)))
-		ena_trc_err("failed to destroy io sq error: %d\n", ret);
+		pr_err("failed to destroy io sq error: %d\n", ret);
 
 	return ret;
 }
@@ -715,8 +715,7 @@ static void ena_com_io_queue_free(struct ena_com_dev *ena_dev,
 	if (io_cq->cdesc_addr.virt_addr) {
 		size = io_cq->cdesc_entry_size_in_bytes * io_cq->q_depth;
 
-		dma_free_coherent(ena_dev->dmadev,
-				  size,
+		dma_free_coherent(ena_dev->dmadev, size,
 				  io_cq->cdesc_addr.virt_addr,
 				  io_cq->cdesc_addr.phys_addr);
 
@@ -727,8 +726,7 @@ static void ena_com_io_queue_free(struct ena_com_dev *ena_dev,
 		size = io_sq->desc_entry_size * io_sq->q_depth;
 
 		if (io_sq->mem_queue_type == ENA_ADMIN_PLACEMENT_POLICY_HOST)
-			dma_free_coherent(ena_dev->dmadev,
-					  size,
+			dma_free_coherent(ena_dev->dmadev, size,
 					  io_sq->desc_addr.virt_addr,
 					  io_sq->desc_addr.phys_addr);
 		else
@@ -747,7 +745,7 @@ static int wait_for_reset_state(struct ena_com_dev *ena_dev, u32 timeout,
 		val = ena_com_reg_bar_read32(ena_dev, ENA_REGS_DEV_STS_OFF);
 
 		if (unlikely(val == ENA_MMIO_READ_TIMEOUT)) {
-			ena_trc_err("Reg read timeout occurred\n");
+			pr_err("Reg read timeout occurred\n");
 			return -ETIME;
 		}
 
@@ -785,13 +783,8 @@ static int ena_com_get_feature_ex(struct ena_com_dev *ena_dev,
 	struct ena_admin_get_feat_cmd get_cmd;
 	int ret;
 
-	if (!ena_dev) {
-		ena_trc_err("%s : ena_dev is NULL\n", __func__);
-		return -ENODEV;
-	}
-
 	if (!ena_com_check_supported_feature_id(ena_dev, feature_id)) {
-		ena_trc_info("Feature %d isn't supported\n", feature_id);
+		pr_info("Feature %d isn't supported\n", feature_id);
 		return -EPERM;
 	}
 
@@ -810,7 +803,7 @@ static int ena_com_get_feature_ex(struct ena_com_dev *ena_dev,
 				   &get_cmd.control_buffer.address,
 				   control_buf_dma_addr);
 	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
+		pr_err("memory address set failed\n");
 		return ret;
 	}
 
@@ -827,8 +820,8 @@ static int ena_com_get_feature_ex(struct ena_com_dev *ena_dev,
 					    sizeof(*get_resp));
 
 	if (unlikely(ret))
-		ena_trc_err("Failed to submit get_feature command %d error: %d\n",
-			    feature_id, ret);
+		pr_err("Failed to submit get_feature command %d error: %d\n",
+		       feature_id, ret);
 
 	return ret;
 }
@@ -848,10 +841,9 @@ static int ena_com_hash_key_allocate(struct ena_com_dev *ena_dev)
 {
 	struct ena_rss *rss = &ena_dev->rss;
 
-	rss->hash_key = dma_alloc_coherent(ena_dev->dmadev,
-					   sizeof(*rss->hash_key),
-					   &rss->hash_key_dma_addr,
-					   GFP_KERNEL | __GFP_ZERO);
+	rss->hash_key =
+		dma_zalloc_coherent(ena_dev->dmadev, sizeof(*rss->hash_key),
+				    &rss->hash_key_dma_addr, GFP_KERNEL);
 
 	if (unlikely(!rss->hash_key))
 		return -ENOMEM;
@@ -864,10 +856,8 @@ static void ena_com_hash_key_destroy(struct ena_com_dev *ena_dev)
 	struct ena_rss *rss = &ena_dev->rss;
 
 	if (rss->hash_key)
-		dma_free_coherent(ena_dev->dmadev,
-				  sizeof(*rss->hash_key),
-				  rss->hash_key,
-				  rss->hash_key_dma_addr);
+		dma_free_coherent(ena_dev->dmadev, sizeof(*rss->hash_key),
+				  rss->hash_key, rss->hash_key_dma_addr);
 	rss->hash_key = NULL;
 }
 
@@ -875,10 +865,9 @@ static int ena_com_hash_ctrl_init(struct ena_com_dev *ena_dev)
 {
 	struct ena_rss *rss = &ena_dev->rss;
 
-	rss->hash_ctrl = dma_alloc_coherent(ena_dev->dmadev,
-					    sizeof(*rss->hash_ctrl),
-					    &rss->hash_ctrl_dma_addr,
-					    GFP_KERNEL | __GFP_ZERO);
+	rss->hash_ctrl =
+		dma_zalloc_coherent(ena_dev->dmadev, sizeof(*rss->hash_ctrl),
+				    &rss->hash_ctrl_dma_addr, GFP_KERNEL);
 
 	if (unlikely(!rss->hash_ctrl))
 		return -ENOMEM;
@@ -891,10 +880,8 @@ static void ena_com_hash_ctrl_destroy(struct ena_com_dev *ena_dev)
 	struct ena_rss *rss = &ena_dev->rss;
 
 	if (rss->hash_ctrl)
-		dma_free_coherent(ena_dev->dmadev,
-				  sizeof(*rss->hash_ctrl),
-				  rss->hash_ctrl,
-				  rss->hash_ctrl_dma_addr);
+		dma_free_coherent(ena_dev->dmadev, sizeof(*rss->hash_ctrl),
+				  rss->hash_ctrl, rss->hash_ctrl_dma_addr);
 	rss->hash_ctrl = NULL;
 }
 
@@ -913,10 +900,9 @@ static int ena_com_indirect_table_allocate(struct ena_com_dev *ena_dev,
 
 	if ((get_resp.u.ind_table.min_size > log_size) ||
 	    (get_resp.u.ind_table.max_size < log_size)) {
-		ena_trc_err("indirect table size doesn't fit. requested size: %d while min is:%d and max %d\n",
-			    1 << log_size,
-			    1 << get_resp.u.ind_table.min_size,
-			    1 << get_resp.u.ind_table.max_size);
+		pr_err("indirect table size doesn't fit. requested size: %d while min is:%d and max %d\n",
+		       1 << log_size, 1 << get_resp.u.ind_table.min_size,
+		       1 << get_resp.u.ind_table.max_size);
 		return -EINVAL;
 	}
 
@@ -924,10 +910,8 @@ static int ena_com_indirect_table_allocate(struct ena_com_dev *ena_dev,
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
 	rss->rss_ind_tbl =
-		dma_alloc_coherent(ena_dev->dmadev,
-				   tbl_size,
-				   &rss->rss_ind_tbl_dma_addr,
-				   GFP_KERNEL | __GFP_ZERO);
+		dma_zalloc_coherent(ena_dev->dmadev, tbl_size,
+				    &rss->rss_ind_tbl_dma_addr, GFP_KERNEL);
 	if (unlikely(!rss->rss_ind_tbl))
 		goto mem_err1;
 
@@ -945,9 +929,7 @@ mem_err2:
 	tbl_size = (1ULL << log_size) *
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
-	dma_free_coherent(ena_dev->dmadev,
-			  tbl_size,
-			  rss->rss_ind_tbl,
+	dma_free_coherent(ena_dev->dmadev, tbl_size, rss->rss_ind_tbl,
 			  rss->rss_ind_tbl_dma_addr);
 	rss->rss_ind_tbl = NULL;
 mem_err1:
@@ -962,9 +944,7 @@ static void ena_com_indirect_table_destroy(struct ena_com_dev *ena_dev)
 		sizeof(struct ena_admin_rss_ind_table_entry);
 
 	if (rss->rss_ind_tbl)
-		dma_free_coherent(ena_dev->dmadev,
-				  tbl_size,
-				  rss->rss_ind_tbl,
+		dma_free_coherent(ena_dev->dmadev, tbl_size, rss->rss_ind_tbl,
 				  rss->rss_ind_tbl_dma_addr);
 	rss->rss_ind_tbl = NULL;
 
@@ -1013,7 +993,7 @@ static int ena_com_create_io_sq(struct ena_com_dev *ena_dev,
 					   &create_cmd.sq_ba,
 					   io_sq->desc_addr.phys_addr);
 		if (unlikely(ret)) {
-			ena_trc_err("memory address set failed\n");
+			pr_err("memory address set failed\n");
 			return ret;
 		}
 	}
@@ -1024,7 +1004,7 @@ static int ena_com_create_io_sq(struct ena_com_dev *ena_dev,
 					    (struct ena_admin_acq_entry *)&cmd_completion,
 					    sizeof(cmd_completion));
 	if (unlikely(ret)) {
-		ena_trc_err("Failed to create IO SQ. error: %d\n", ret);
+		pr_err("Failed to create IO SQ. error: %d\n", ret);
 		return ret;
 	}
 
@@ -1042,7 +1022,7 @@ static int ena_com_create_io_sq(struct ena_com_dev *ena_dev,
 			cmd_completion.llq_descriptors_offset);
 	}
 
-	ena_trc_dbg("created sq[%u], depth[%u]\n", io_sq->idx, io_sq->q_depth);
+	pr_debug("created sq[%u], depth[%u]\n", io_sq->idx, io_sq->q_depth);
 
 	return ret;
 }
@@ -1100,7 +1080,8 @@ static int ena_com_init_interrupt_moderation_table(struct ena_com_dev *ena_dev)
 
 	size = sizeof(struct ena_intr_moder_entry) * ENA_INTR_MAX_NUM_OF_LEVELS;
 
-	ena_dev->intr_moder_tbl = devm_kzalloc(ena_dev->dmadev, size, GFP_KERNEL);
+	ena_dev->intr_moder_tbl =
+		devm_kzalloc(ena_dev->dmadev, size, GFP_KERNEL);
 	if (!ena_dev->intr_moder_tbl)
 		return -ENOMEM;
 
@@ -1116,7 +1097,7 @@ static void ena_com_update_intr_delay_resolution(struct ena_com_dev *ena_dev,
 	unsigned int i;
 
 	if (!intr_delay_resolution) {
-		ena_trc_err("Illegal intr_delay_resolution provided. Going to use default 1 usec resolution\n");
+		pr_err("Illegal intr_delay_resolution provided. Going to use default 1 usec resolution\n");
 		intr_delay_resolution = 1;
 	}
 	ena_dev->intr_delay_resolution = intr_delay_resolution;
@@ -1140,24 +1121,21 @@ int ena_com_execute_admin_command(struct ena_com_admin_queue *admin_queue,
 				  size_t comp_size)
 {
 	struct ena_comp_ctx *comp_ctx;
-	int ret = 0;
+	int ret;
 
 	comp_ctx = ena_com_submit_admin_cmd(admin_queue, cmd, cmd_size,
 					    comp, comp_size);
 	if (unlikely(IS_ERR(comp_ctx))) {
-		ena_trc_err("Failed to submit command [%ld]\n",
-			    PTR_ERR(comp_ctx));
+		pr_err("Failed to submit command [%ld]\n", PTR_ERR(comp_ctx));
 		return PTR_ERR(comp_ctx);
 	}
 
 	ret = ena_com_wait_and_process_admin_cq(comp_ctx, admin_queue);
 	if (unlikely(ret)) {
 		if (admin_queue->running_state)
-			ena_trc_err("Failed to process command. ret = %d\n",
-				    ret);
+			pr_err("Failed to process command. ret = %d\n", ret);
 		else
-			ena_trc_dbg("Failed to process command. ret = %d\n",
-				    ret);
+			pr_debug("Failed to process command. ret = %d\n", ret);
 	}
 	return ret;
 }
@@ -1186,7 +1164,7 @@ int ena_com_create_io_cq(struct ena_com_dev *ena_dev,
 				   &create_cmd.cq_ba,
 				   io_cq->cdesc_addr.phys_addr);
 	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
+		pr_err("memory address set failed\n");
 		return ret;
 	}
 
@@ -1196,7 +1174,7 @@ int ena_com_create_io_cq(struct ena_com_dev *ena_dev,
 					    (struct ena_admin_acq_entry *)&cmd_completion,
 					    sizeof(cmd_completion));
 	if (unlikely(ret)) {
-		ena_trc_err("Failed to create IO CQ. error: %d\n", ret);
+		pr_err("Failed to create IO CQ. error: %d\n", ret);
 		return ret;
 	}
 
@@ -1215,7 +1193,7 @@ int ena_com_create_io_cq(struct ena_com_dev *ena_dev,
 			(u32 __iomem *)((uintptr_t)ena_dev->reg_bar +
 			cmd_completion.numa_node_register_offset);
 
-	ena_trc_dbg("created cq[%u], depth[%u]\n", io_cq->idx, io_cq->q_depth);
+	pr_debug("created cq[%u], depth[%u]\n", io_cq->idx, io_cq->q_depth);
 
 	return ret;
 }
@@ -1225,8 +1203,8 @@ int ena_com_get_io_handlers(struct ena_com_dev *ena_dev, u16 qid,
 			    struct ena_com_io_cq **io_cq)
 {
 	if (qid >= ENA_TOTAL_NUM_QUEUES) {
-		ena_trc_err("Invalid queue number %d but the max is %d\n",
-			    qid, ENA_TOTAL_NUM_QUEUES);
+		pr_err("Invalid queue number %d but the max is %d\n", qid,
+		       ENA_TOTAL_NUM_QUEUES);
 		return -EINVAL;
 	}
 
@@ -1290,7 +1268,7 @@ int ena_com_destroy_io_cq(struct ena_com_dev *ena_dev,
 					    sizeof(destroy_resp));
 
 	if (unlikely(ret && (ret != -ENODEV)))
-		ena_trc_err("Failed to destroy IO CQ. error: %d\n", ret);
+		pr_err("Failed to destroy IO CQ. error: %d\n", ret);
 
 	return ret;
 }
@@ -1314,7 +1292,7 @@ void ena_com_admin_aenq_enable(struct ena_com_dev *ena_dev)
 {
 	u16 depth = ena_dev->aenq.q_depth;
 
-	ENA_ASSERT(ena_dev->aenq.head == depth, "Invalid AENQ state\n");
+	WARN(ena_dev->aenq.head != depth, "Invalid AENQ state\n");
 
 	/* Init head_db to mark that all entries in the queue
 	 * are initially available
@@ -1328,23 +1306,17 @@ int ena_com_set_aenq_config(struct ena_com_dev *ena_dev, u32 groups_flag)
 	struct ena_admin_set_feat_cmd cmd;
 	struct ena_admin_set_feat_resp resp;
 	struct ena_admin_get_feat_resp get_resp;
-	int ret = 0;
-
-	if (unlikely(!ena_dev)) {
-		ena_trc_err("%s : ena_dev is NULL\n", __func__);
-		return -ENODEV;
-	}
+	int ret;
 
 	ret = ena_com_get_feature(ena_dev, &get_resp, ENA_ADMIN_AENQ_CONFIG);
 	if (ret) {
-		ena_trc_info("Can't get aenq configuration\n");
+		pr_info("Can't get aenq configuration\n");
 		return ret;
 	}
 
 	if ((get_resp.u.aenq.supported_groups & groups_flag) != groups_flag) {
-		ena_trc_warn("Trying to set unsupported aenq events. supported flag: %x asked flag: %x\n",
-			     get_resp.u.aenq.supported_groups,
-			     groups_flag);
+		pr_warn("Trying to set unsupported aenq events. supported flag: %x asked flag: %x\n",
+			get_resp.u.aenq.supported_groups, groups_flag);
 		return -EPERM;
 	}
 
@@ -1363,7 +1335,7 @@ int ena_com_set_aenq_config(struct ena_com_dev *ena_dev, u32 groups_flag)
 					    sizeof(resp));
 
 	if (unlikely(ret))
-		ena_trc_err("Failed to config AENQ ret: %d\n", ret);
+		pr_err("Failed to config AENQ ret: %d\n", ret);
 
 	return ret;
 }
@@ -1374,17 +1346,17 @@ int ena_com_get_dma_width(struct ena_com_dev *ena_dev)
 	int width;
 
 	if (unlikely(caps == ENA_MMIO_READ_TIMEOUT)) {
-		ena_trc_err("Reg read timeout occurred\n");
+		pr_err("Reg read timeout occurred\n");
 		return -ETIME;
 	}
 
 	width = (caps & ENA_REGS_CAPS_DMA_ADDR_WIDTH_MASK) >>
 		ENA_REGS_CAPS_DMA_ADDR_WIDTH_SHIFT;
 
-	ena_trc_dbg("ENA dma width: %d\n", width);
+	pr_debug("ENA dma width: %d\n", width);
 
 	if ((width < 32) || width > ENA_MAX_PHYS_ADDR_SIZE_BITS) {
-		ena_trc_err("DMA width illegal value: %d\n", width);
+		pr_err("DMA width illegal value: %d\n", width);
 		return -EINVAL;
 	}
 
@@ -1408,28 +1380,28 @@ int ena_com_validate_version(struct ena_com_dev *ena_dev)
 
 	if (unlikely((ver == ENA_MMIO_READ_TIMEOUT) ||
 		     (ctrl_ver == ENA_MMIO_READ_TIMEOUT))) {
-		ena_trc_err("Reg read timeout occurred\n");
+		pr_err("Reg read timeout occurred\n");
 		return -ETIME;
 	}
 
-	ena_trc_info("ena device version: %d.%d\n",
-		     (ver & ENA_REGS_VERSION_MAJOR_VERSION_MASK) >>
-		     ENA_REGS_VERSION_MAJOR_VERSION_SHIFT,
-		     ver & ENA_REGS_VERSION_MINOR_VERSION_MASK);
+	pr_info("ena device version: %d.%d\n",
+		(ver & ENA_REGS_VERSION_MAJOR_VERSION_MASK) >>
+			ENA_REGS_VERSION_MAJOR_VERSION_SHIFT,
+		ver & ENA_REGS_VERSION_MINOR_VERSION_MASK);
 
 	if (ver < MIN_ENA_VER) {
-		ena_trc_err("ENA version is lower than the minimal version the driver supports\n");
+		pr_err("ENA version is lower than the minimal version the driver supports\n");
 		return -1;
 	}
 
-	ena_trc_info("ena controller version: %d.%d.%d implementation version %d\n",
-		     (ctrl_ver & ENA_REGS_CONTROLLER_VERSION_MAJOR_VERSION_MASK)
-		     >> ENA_REGS_CONTROLLER_VERSION_MAJOR_VERSION_SHIFT,
-		     (ctrl_ver & ENA_REGS_CONTROLLER_VERSION_MINOR_VERSION_MASK)
-		     >> ENA_REGS_CONTROLLER_VERSION_MINOR_VERSION_SHIFT,
-		     (ctrl_ver & ENA_REGS_CONTROLLER_VERSION_SUBMINOR_VERSION_MASK),
-		     (ctrl_ver & ENA_REGS_CONTROLLER_VERSION_IMPL_ID_MASK) >>
-		     ENA_REGS_CONTROLLER_VERSION_IMPL_ID_SHIFT);
+	pr_info("ena controller version: %d.%d.%d implementation version %d\n",
+		(ctrl_ver & ENA_REGS_CONTROLLER_VERSION_MAJOR_VERSION_MASK) >>
+			ENA_REGS_CONTROLLER_VERSION_MAJOR_VERSION_SHIFT,
+		(ctrl_ver & ENA_REGS_CONTROLLER_VERSION_MINOR_VERSION_MASK) >>
+			ENA_REGS_CONTROLLER_VERSION_MINOR_VERSION_SHIFT,
+		(ctrl_ver & ENA_REGS_CONTROLLER_VERSION_SUBMINOR_VERSION_MASK),
+		(ctrl_ver & ENA_REGS_CONTROLLER_VERSION_IMPL_ID_MASK) >>
+			ENA_REGS_CONTROLLER_VERSION_IMPL_ID_SHIFT);
 
 	ctrl_ver_masked =
 		(ctrl_ver & ENA_REGS_CONTROLLER_VERSION_MAJOR_VERSION_MASK) |
@@ -1438,7 +1410,7 @@ int ena_com_validate_version(struct ena_com_dev *ena_dev)
 
 	/* Validate the ctrl version without the implementation ID */
 	if (ctrl_ver_masked < MIN_ENA_CTRL_VER) {
-		ena_trc_err("ENA ctrl version is lower than the minimal ctrl version the driver supports\n");
+		pr_err("ENA ctrl version is lower than the minimal ctrl version the driver supports\n");
 		return -1;
 	}
 
@@ -1448,34 +1420,31 @@ int ena_com_validate_version(struct ena_com_dev *ena_dev)
 void ena_com_admin_destroy(struct ena_com_dev *ena_dev)
 {
 	struct ena_com_admin_queue *admin_queue = &ena_dev->admin_queue;
-
-	if (!admin_queue)
-		return;
+	struct ena_com_admin_cq *cq = &admin_queue->cq;
+	struct ena_com_admin_sq *sq = &admin_queue->sq;
+	struct ena_com_aenq *aenq = &ena_dev->aenq;
+	u16 size;
 
 	if (admin_queue->comp_ctx)
 		devm_kfree(ena_dev->dmadev, admin_queue->comp_ctx);
 	admin_queue->comp_ctx = NULL;
-
-	if (admin_queue->sq.entries)
-		dma_free_coherent(ena_dev->dmadev,
-				  ADMIN_SQ_SIZE(admin_queue->q_depth),
-				  admin_queue->sq.entries,
-				  admin_queue->sq.dma_addr);
-	admin_queue->sq.entries = NULL;
-
-	if (admin_queue->cq.entries)
-		dma_free_coherent(ena_dev->dmadev,
-				  ADMIN_CQ_SIZE(admin_queue->q_depth),
-				  admin_queue->cq.entries,
-				  admin_queue->cq.dma_addr);
-	admin_queue->cq.entries = NULL;
-
+	size = ADMIN_SQ_SIZE(admin_queue->q_depth);
+	if (sq->entries)
+		dma_free_coherent(ena_dev->dmadev, size, sq->entries,
+				  sq->dma_addr);
+	sq->entries = NULL;
+
+	size = ADMIN_CQ_SIZE(admin_queue->q_depth);
+	if (cq->entries)
+		dma_free_coherent(ena_dev->dmadev, size, cq->entries,
+				  cq->dma_addr);
+	cq->entries = NULL;
+
+	size = ADMIN_AENQ_SIZE(aenq->q_depth);
 	if (ena_dev->aenq.entries)
-		dma_free_coherent(ena_dev->dmadev,
-				  ADMIN_AENQ_SIZE(ena_dev->aenq.q_depth),
-				  ena_dev->aenq.entries,
-				  ena_dev->aenq.dma_addr);
-	ena_dev->aenq.entries = NULL;
+		dma_free_coherent(ena_dev->dmadev, size, aenq->entries,
+				  aenq->dma_addr);
+	aenq->entries = NULL;
 }
 
 void ena_com_set_admin_polling_mode(struct ena_com_dev *ena_dev, bool polling)
@@ -1489,10 +1458,9 @@ int ena_com_mmio_reg_read_request_init(struct ena_com_dev *ena_dev)
 
 	spin_lock_init(&mmio_read->lock);
 	mmio_read->read_resp =
-		dma_alloc_coherent(ena_dev->dmadev,
-				   sizeof(*mmio_read->read_resp),
-				   &mmio_read->read_resp_dma_addr,
-				   GFP_KERNEL | __GFP_ZERO);
+		dma_zalloc_coherent(ena_dev->dmadev,
+				    sizeof(*mmio_read->read_resp),
+				    &mmio_read->read_resp_dma_addr, GFP_KERNEL);
 	if (unlikely(!mmio_read->read_resp))
 		return -ENOMEM;
 
@@ -1519,10 +1487,8 @@ void ena_com_mmio_reg_read_request_destroy(struct ena_com_dev *ena_dev)
 	writel(0x0, ena_dev->reg_bar + ENA_REGS_MMIO_RESP_LO_OFF);
 	writel(0x0, ena_dev->reg_bar + ENA_REGS_MMIO_RESP_HI_OFF);
 
-	dma_free_coherent(ena_dev->dmadev,
-			  sizeof(*mmio_read->read_resp),
-			  mmio_read->read_resp,
-			  mmio_read->read_resp_dma_addr);
+	dma_free_coherent(ena_dev->dmadev, sizeof(*mmio_read->read_resp),
+			  mmio_read->read_resp, mmio_read->read_resp_dma_addr);
 
 	mmio_read->read_resp = NULL;
 }
@@ -1550,12 +1516,12 @@ int ena_com_admin_init(struct ena_com_dev *ena_dev,
 	dev_sts = ena_com_reg_bar_read32(ena_dev, ENA_REGS_DEV_STS_OFF);
 
 	if (unlikely(dev_sts == ENA_MMIO_READ_TIMEOUT)) {
-		ena_trc_err("Reg read timeout occurred\n");
+		pr_err("Reg read timeout occurred\n");
 		return -ETIME;
 	}
 
 	if (!(dev_sts & ENA_REGS_DEV_STS_READY_MASK)) {
-		ena_trc_err("Device isn't ready, abort com init\n");
+		pr_err("Device isn't ready, abort com init\n");
 		return -ENODEV;
 	}
 
@@ -1629,11 +1595,11 @@ int ena_com_create_io_queue(struct ena_com_dev *ena_dev,
 {
 	struct ena_com_io_sq *io_sq;
 	struct ena_com_io_cq *io_cq;
-	int ret = 0;
+	int ret;
 
 	if (ctx->qid >= ENA_TOTAL_NUM_QUEUES) {
-		ena_trc_err("Qid (%d) is bigger than max num of queues (%d)\n",
-			    ctx->qid, ENA_TOTAL_NUM_QUEUES);
+		pr_err("Qid (%d) is bigger than max num of queues (%d)\n",
+		       ctx->qid, ENA_TOTAL_NUM_QUEUES);
 		return -EINVAL;
 	}
 
@@ -1691,8 +1657,8 @@ void ena_com_destroy_io_queue(struct ena_com_dev *ena_dev, u16 qid)
 	struct ena_com_io_cq *io_cq;
 
 	if (qid >= ENA_TOTAL_NUM_QUEUES) {
-		ena_trc_err("Qid (%d) is bigger than max num of queues (%d)\n",
-			    qid, ENA_TOTAL_NUM_QUEUES);
+		pr_err("Qid (%d) is bigger than max num of queues (%d)\n", qid,
+		       ENA_TOTAL_NUM_QUEUES);
 		return;
 	}
 
@@ -1793,12 +1759,11 @@ void ena_com_aenq_intr_handler(struct ena_com_dev *dev, void *data)
 
 	/* Go over all the events */
 	while ((aenq_common->flags & ENA_ADMIN_AENQ_COMMON_DESC_PHASE_MASK) ==
-		phase) {
-		ena_trc_dbg("AENQ! Group[%x] Syndrom[%x] timestamp: [%llus]\n",
-			    aenq_common->group,
-			    aenq_common->syndrom,
-			    (u64)aenq_common->timestamp_low +
-			    ((u64)aenq_common->timestamp_high << 32));
+	       phase) {
+		pr_debug("AENQ! Group[%x] Syndrom[%x] timestamp: [%llus]\n",
+			 aenq_common->group, aenq_common->syndrom,
+			 (u64)aenq_common->timestamp_low +
+				 ((u64)aenq_common->timestamp_high << 32));
 
 		/* Handle specific event*/
 		handler_cb = ena_com_get_specific_aenq_cb(dev,
@@ -1839,19 +1804,19 @@ int ena_com_dev_reset(struct ena_com_dev *ena_dev)
 
 	if (unlikely((stat == ENA_MMIO_READ_TIMEOUT) ||
 		     (cap == ENA_MMIO_READ_TIMEOUT))) {
-		ena_trc_err("Reg read32 timeout occurred\n");
+		pr_err("Reg read32 timeout occurred\n");
 		return -ETIME;
 	}
 
 	if ((stat & ENA_REGS_DEV_STS_READY_MASK) == 0) {
-		ena_trc_err("Device isn't ready, can't reset device\n");
+		pr_err("Device isn't ready, can't reset device\n");
 		return -EINVAL;
 	}
 
 	timeout = (cap & ENA_REGS_CAPS_RESET_TIMEOUT_MASK) >>
 			ENA_REGS_CAPS_RESET_TIMEOUT_SHIFT;
 	if (timeout == 0) {
-		ena_trc_err("Invalid timeout value\n");
+		pr_err("Invalid timeout value\n");
 		return -EINVAL;
 	}
 
@@ -1865,7 +1830,7 @@ int ena_com_dev_reset(struct ena_com_dev *ena_dev)
 	rc = wait_for_reset_state(ena_dev, timeout,
 				  ENA_REGS_DEV_STS_RESET_IN_PROGRESS_MASK);
 	if (rc != 0) {
-		ena_trc_err("Reset indication didn't turn on\n");
+		pr_err("Reset indication didn't turn on\n");
 		return rc;
 	}
 
@@ -1873,7 +1838,7 @@ int ena_com_dev_reset(struct ena_com_dev *ena_dev)
 	writel(0, ena_dev->reg_bar + ENA_REGS_DEV_CTL_OFF);
 	rc = wait_for_reset_state(ena_dev, timeout, 0);
 	if (rc != 0) {
-		ena_trc_err("Reset indication didn't turn off\n");
+		pr_err("Reset indication didn't turn off\n");
 		return rc;
 	}
 
@@ -1881,17 +1846,13 @@ int ena_com_dev_reset(struct ena_com_dev *ena_dev)
 }
 
 static int ena_get_dev_stats(struct ena_com_dev *ena_dev,
-			     struct ena_admin_aq_get_stats_cmd *get_cmd,
-			     struct ena_admin_acq_get_stats_resp *get_resp,
+			     struct ena_com_stats_ctx *ctx,
 			     enum ena_admin_get_stats_type type)
 {
+	struct ena_admin_aq_get_stats_cmd *get_cmd = &ctx->get_cmd;
+	struct ena_admin_acq_get_stats_resp *get_resp = &ctx->get_resp;
 	struct ena_com_admin_queue *admin_queue;
-	int ret = 0;
-
-	if (!ena_dev) {
-		ena_trc_err("%s : ena_dev is NULL\n", __func__);
-		return -ENODEV;
-	}
+	int ret;
 
 	admin_queue = &ena_dev->admin_queue;
 
@@ -1906,7 +1867,7 @@ static int ena_get_dev_stats(struct ena_com_dev *ena_dev,
 					     sizeof(*get_resp));
 
 	if (unlikely(ret))
-		ena_trc_err("Failed to get stats. error: %d\n", ret);
+		pr_err("Failed to get stats. error: %d\n", ret);
 
 	return ret;
 }
@@ -1914,77 +1875,27 @@ static int ena_get_dev_stats(struct ena_com_dev *ena_dev,
 int ena_com_get_dev_basic_stats(struct ena_com_dev *ena_dev,
 				struct ena_admin_basic_stats *stats)
 {
-	int ret = 0;
-	struct ena_admin_aq_get_stats_cmd get_cmd;
-	struct ena_admin_acq_get_stats_resp get_resp;
+	struct ena_com_stats_ctx ctx;
+	int ret;
 
-	memset(&get_cmd, 0x0, sizeof(get_cmd));
-	ret = ena_get_dev_stats(ena_dev, &get_cmd, &get_resp,
-				ENA_ADMIN_GET_STATS_TYPE_BASIC);
+	memset(&ctx, 0x0, sizeof(ctx));
+	ret = ena_get_dev_stats(ena_dev, &ctx, ENA_ADMIN_GET_STATS_TYPE_BASIC);
 	if (likely(ret == 0))
-		memcpy(stats, &get_resp.basic_stats,
-		       sizeof(get_resp.basic_stats));
+		memcpy(stats, &ctx.get_resp.basic_stats,
+		       sizeof(ctx.get_resp.basic_stats));
 
 	return ret;
 }
 
-int ena_com_get_dev_extended_stats(struct ena_com_dev *ena_dev, char *buff,
-				   u32 len)
-{
-	int ret = 0;
-	struct ena_admin_aq_get_stats_cmd get_cmd;
-	struct ena_admin_acq_get_stats_resp get_resp;
-	void *virt_addr;
-	dma_addr_t phys_addr;
-
-	virt_addr = dma_alloc_coherent(ena_dev->dmadev,
-				       len,
-				       &phys_addr,
-				       GFP_KERNEL | __GFP_ZERO);
-	if (!virt_addr) {
-		ret = -ENOMEM;
-		goto done;
-	}
-	memset(&get_cmd, 0x0, sizeof(get_cmd));
-	ret = ena_com_mem_addr_set(ena_dev,
-				   &get_cmd.u.control_buffer.address,
-				   phys_addr);
-	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
-		return ret;
-	}
-	get_cmd.u.control_buffer.length = len;
-
-	get_cmd.device_id = ena_dev->stats_func;
-	get_cmd.queue_idx = ena_dev->stats_queue;
-
-	ret = ena_get_dev_stats(ena_dev, &get_cmd, &get_resp,
-				ENA_ADMIN_GET_STATS_TYPE_EXTENDED);
-	if (ret < 0)
-		goto free_ext_stats_mem;
-
-	ret = snprintf(buff, len, "%s", (char *)virt_addr);
-
-free_ext_stats_mem:
-	dma_free_coherent(ena_dev->dmadev, len, virt_addr, phys_addr);
-done:
-	return ret;
-}
-
 int ena_com_set_dev_mtu(struct ena_com_dev *ena_dev, int mtu)
 {
 	struct ena_com_admin_queue *admin_queue;
 	struct ena_admin_set_feat_cmd cmd;
 	struct ena_admin_set_feat_resp resp;
-	int ret = 0;
-
-	if (unlikely(!ena_dev)) {
-		ena_trc_err("%s : ena_dev is NULL\n", __func__);
-		return -ENODEV;
-	}
+	int ret;
 
 	if (!ena_com_check_supported_feature_id(ena_dev, ENA_ADMIN_MTU)) {
-		ena_trc_info("Feature %d isn't supported\n", ENA_ADMIN_MTU);
+		pr_info("Feature %d isn't supported\n", ENA_ADMIN_MTU);
 		return -EPERM;
 	}
 
@@ -2002,11 +1913,10 @@ int ena_com_set_dev_mtu(struct ena_com_dev *ena_dev, int mtu)
 					    (struct ena_admin_acq_entry *)&resp,
 					    sizeof(resp));
 
-	if (unlikely(ret)) {
-		ena_trc_err("Failed to set mtu %d. error: %d\n", mtu, ret);
-		return -EINVAL;
-	}
-	return 0;
+	if (unlikely(ret))
+		pr_err("Failed to set mtu %d. error: %d\n", mtu, ret);
+
+	return ret;
 }
 
 int ena_com_get_offload_settings(struct ena_com_dev *ena_dev,
@@ -2018,8 +1928,8 @@ int ena_com_get_offload_settings(struct ena_com_dev *ena_dev,
 	ret = ena_com_get_feature(ena_dev, &resp,
 				  ENA_ADMIN_STATELESS_OFFLOAD_CONFIG);
 	if (unlikely(ret)) {
-		ena_trc_err("Failed to get offload capabilities %d\n", ret);
-		return -EINVAL;
+		pr_err("Failed to get offload capabilities %d\n", ret);
+		return ret;
 	}
 
 	memcpy(offload, &resp.u.offload, sizeof(resp.u.offload));
@@ -2038,8 +1948,8 @@ int ena_com_set_hash_function(struct ena_com_dev *ena_dev)
 
 	if (!ena_com_check_supported_feature_id(ena_dev,
 						ENA_ADMIN_RSS_HASH_FUNCTION)) {
-		ena_trc_info("Feature %d isn't supported\n",
-			     ENA_ADMIN_RSS_HASH_FUNCTION);
+		pr_info("Feature %d isn't supported\n",
+			ENA_ADMIN_RSS_HASH_FUNCTION);
 		return -EPERM;
 	}
 
@@ -2050,8 +1960,8 @@ int ena_com_set_hash_function(struct ena_com_dev *ena_dev)
 		return ret;
 
 	if (get_resp.u.flow_hash_func.supported_func & (1 << rss->hash_func)) {
-		ena_trc_err("Func hash %d isn't supported by device, abort\n",
-			    rss->hash_func);
+		pr_err("Func hash %d isn't supported by device, abort\n",
+		       rss->hash_func);
 		return -EPERM;
 	}
 
@@ -2068,7 +1978,7 @@ int ena_com_set_hash_function(struct ena_com_dev *ena_dev)
 				   &cmd.control_buffer.address,
 				   rss->hash_key_dma_addr);
 	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
+		pr_err("memory address set failed\n");
 		return ret;
 	}
 
@@ -2080,8 +1990,8 @@ int ena_com_set_hash_function(struct ena_com_dev *ena_dev)
 					    (struct ena_admin_acq_entry *)&resp,
 					    sizeof(resp));
 	if (unlikely(ret)) {
-		ena_trc_err("Failed to set hash function %d. error: %d\n",
-			    rss->hash_func, ret);
+		pr_err("Failed to set hash function %d. error: %d\n",
+		       rss->hash_func, ret);
 		return -EINVAL;
 	}
 
@@ -2110,15 +2020,15 @@ int ena_com_fill_hash_function(struct ena_com_dev *ena_dev,
 		return rc;
 
 	if (!((1 << func) & get_resp.u.flow_hash_func.supported_func)) {
-		ena_trc_err("Flow hash function %d isn't supported\n", func);
+		pr_err("Flow hash function %d isn't supported\n", func);
 		return -EPERM;
 	}
 
 	switch (func) {
 	case ENA_ADMIN_TOEPLITZ:
 		if (key_len > sizeof(hash_key->key)) {
-			ena_trc_err("key len (%hu) is bigger than the max supported (%zu)\n",
-				    key_len, sizeof(hash_key->key));
+			pr_err("key len (%hu) is bigger than the max supported (%zu)\n",
+			       key_len, sizeof(hash_key->key));
 			return -EINVAL;
 		}
 
@@ -2130,7 +2040,7 @@ int ena_com_fill_hash_function(struct ena_com_dev *ena_dev,
 		rss->hash_init_val = init_val;
 		break;
 	default:
-		ena_trc_err("Invalid hash function (%d)\n", func);
+		pr_err("Invalid hash function (%d)\n", func);
 		return -EINVAL;
 	}
 
@@ -2202,8 +2112,7 @@ int ena_com_set_hash_ctrl(struct ena_com_dev *ena_dev)
 
 	if (!ena_com_check_supported_feature_id(ena_dev,
 						ENA_ADMIN_RSS_HASH_INPUT)) {
-		ena_trc_info("Feature %d isn't supported\n",
-			     ENA_ADMIN_RSS_HASH_INPUT);
+		pr_info("Feature %d isn't supported\n", ENA_ADMIN_RSS_HASH_INPUT);
 		return -EPERM;
 	}
 
@@ -2219,7 +2128,7 @@ int ena_com_set_hash_ctrl(struct ena_com_dev *ena_dev)
 				   &cmd.control_buffer.address,
 				   rss->hash_ctrl_dma_addr);
 	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
+		pr_err("memory address set failed\n");
 		return ret;
 	}
 	cmd.control_buffer.length = sizeof(*hash_ctrl);
@@ -2229,12 +2138,10 @@ int ena_com_set_hash_ctrl(struct ena_com_dev *ena_dev)
 					    sizeof(cmd),
 					    (struct ena_admin_acq_entry *)&resp,
 					    sizeof(resp));
-	if (unlikely(ret)) {
-		ena_trc_err("Failed to set hash input. error: %d\n", ret);
-		ret = -EINVAL;
-	}
+	if (unlikely(ret))
+		pr_err("Failed to set hash input. error: %d\n", ret);
 
-	return 0;
+	return ret;
 }
 
 int ena_com_set_default_hash_ctrl(struct ena_com_dev *ena_dev)
@@ -2282,9 +2189,9 @@ int ena_com_set_default_hash_ctrl(struct ena_com_dev *ena_dev)
 		available_fields = hash_ctrl->selected_fields[i].fields &
 				hash_ctrl->supported_fields[i].fields;
 		if (available_fields != hash_ctrl->selected_fields[i].fields) {
-			ena_trc_err("hash control doesn't support all the desire configuration. proto %x supported %x selected %x\n",
-				    i, hash_ctrl->supported_fields[i].fields,
-				    hash_ctrl->selected_fields[i].fields);
+			pr_err("hash control doesn't support all the desire configuration. proto %x supported %x selected %x\n",
+			       i, hash_ctrl->supported_fields[i].fields,
+			       hash_ctrl->selected_fields[i].fields);
 			return -EPERM;
 		}
 	}
@@ -2308,7 +2215,7 @@ int ena_com_fill_hash_ctrl(struct ena_com_dev *ena_dev,
 	int rc;
 
 	if (proto >= ENA_ADMIN_RSS_PROTO_NUM) {
-		ena_trc_err("Invalid proto num (%u)\n", proto);
+		pr_err("Invalid proto num (%u)\n", proto);
 		return -EINVAL;
 	}
 
@@ -2320,8 +2227,8 @@ int ena_com_fill_hash_ctrl(struct ena_com_dev *ena_dev,
 	/* Make sure all the fields are supported */
 	supported_fields = hash_ctrl->supported_fields[proto].fields;
 	if ((hash_fields & supported_fields) != hash_fields) {
-		ena_trc_err("proto %d doesn't support the required fields %x. supports only: %x\n",
-			    proto, hash_fields, supported_fields);
+		pr_err("proto %d doesn't support the required fields %x. supports only: %x\n",
+		       proto, hash_fields, supported_fields);
 	}
 
 	hash_ctrl->selected_fields[proto].fields = hash_fields;
@@ -2357,18 +2264,18 @@ int ena_com_indirect_table_set(struct ena_com_dev *ena_dev)
 	struct ena_rss *rss = &ena_dev->rss;
 	struct ena_admin_set_feat_cmd cmd;
 	struct ena_admin_set_feat_resp resp;
-	int ret = 0;
+	int ret;
 
-	if (!ena_com_check_supported_feature_id(ena_dev,
-						ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG)) {
-		ena_trc_info("Feature %d isn't supported\n",
-			     ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG);
+	if (!ena_com_check_supported_feature_id(
+		    ena_dev, ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG)) {
+		pr_info("Feature %d isn't supported\n",
+			ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG);
 		return -EPERM;
 	}
 
 	ret = ena_com_ind_tbl_convert_to_device(ena_dev);
 	if (ret) {
-		ena_trc_err("Failed to convert host indirection table to device table\n");
+		pr_err("Failed to convert host indirection table to device table\n");
 		return ret;
 	}
 
@@ -2385,7 +2292,7 @@ int ena_com_indirect_table_set(struct ena_com_dev *ena_dev)
 				   &cmd.control_buffer.address,
 				   rss->rss_ind_tbl_dma_addr);
 	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
+		pr_err("memory address set failed\n");
 		return ret;
 	}
 
@@ -2398,12 +2305,10 @@ int ena_com_indirect_table_set(struct ena_com_dev *ena_dev)
 					    (struct ena_admin_acq_entry *)&resp,
 					    sizeof(resp));
 
-	if (unlikely(ret)) {
-		ena_trc_err("Failed to set indirect table. error: %d\n", ret);
-		return -EINVAL;
-	}
+	if (unlikely(ret))
+		pr_err("Failed to set indirect table. error: %d\n", ret);
 
-	return 0;
+	return ret;
 }
 
 int ena_com_indirect_table_get(struct ena_com_dev *ena_dev, u32 *ind_tbl)
@@ -2479,10 +2384,8 @@ int ena_com_allocate_host_info(struct ena_com_dev *ena_dev)
 	struct ena_host_attribute *host_attr = &ena_dev->host_attr;
 
 	host_attr->host_info =
-		dma_alloc_coherent(ena_dev->dmadev,
-				   SZ_4K,
-				   &host_attr->host_info_dma_addr,
-				   GFP_KERNEL | __GFP_ZERO);
+		dma_zalloc_coherent(ena_dev->dmadev, SZ_4K,
+				    &host_attr->host_info_dma_addr, GFP_KERNEL);
 	if (unlikely(!host_attr->host_info))
 		return -ENOMEM;
 
@@ -2495,10 +2398,8 @@ int ena_com_allocate_debug_area(struct ena_com_dev *ena_dev,
 	struct ena_host_attribute *host_attr = &ena_dev->host_attr;
 
 	host_attr->debug_area_virt_addr =
-		dma_alloc_coherent(ena_dev->dmadev,
-				   debug_area_size,
-				   &host_attr->debug_area_dma_addr,
-				   GFP_KERNEL | __GFP_ZERO);
+		dma_zalloc_coherent(ena_dev->dmadev, debug_area_size,
+				    &host_attr->debug_area_dma_addr, GFP_KERNEL);
 	if (unlikely(!host_attr->debug_area_virt_addr)) {
 		host_attr->debug_area_size = 0;
 		return -ENOMEM;
@@ -2514,9 +2415,7 @@ void ena_com_delete_host_info(struct ena_com_dev *ena_dev)
 	struct ena_host_attribute *host_attr = &ena_dev->host_attr;
 
 	if (host_attr->host_info) {
-		dma_free_coherent(ena_dev->dmadev,
-				  SZ_4K,
-				  host_attr->host_info,
+		dma_free_coherent(ena_dev->dmadev, SZ_4K, host_attr->host_info,
 				  host_attr->host_info_dma_addr);
 		host_attr->host_info = NULL;
 	}
@@ -2527,8 +2426,7 @@ void ena_com_delete_debug_area(struct ena_com_dev *ena_dev)
 	struct ena_host_attribute *host_attr = &ena_dev->host_attr;
 
 	if (host_attr->debug_area_virt_addr) {
-		dma_free_coherent(ena_dev->dmadev,
-				  host_attr->debug_area_size,
+		dma_free_coherent(ena_dev->dmadev, host_attr->debug_area_size,
 				  host_attr->debug_area_virt_addr,
 				  host_attr->debug_area_dma_addr);
 		host_attr->debug_area_virt_addr = NULL;
@@ -2542,16 +2440,11 @@ int ena_com_set_host_attributes(struct ena_com_dev *ena_dev)
 	struct ena_admin_set_feat_cmd cmd;
 	struct ena_admin_set_feat_resp resp;
 
-	int ret = 0;
-
-	if (unlikely(!ena_dev)) {
-		ena_trc_err("%s : ena_dev is NULL\n", __func__);
-		return -ENODEV;
-	}
+	int ret;
 
 	if (!ena_com_check_supported_feature_id(ena_dev,
 						ENA_ADMIN_HOST_ATTR_CONFIG)) {
-		ena_trc_warn("Set host attribute isn't supported\n");
+		pr_warn("Set host attribute isn't supported\n");
 		return -EPERM;
 	}
 
@@ -2565,7 +2458,7 @@ int ena_com_set_host_attributes(struct ena_com_dev *ena_dev)
 				   &cmd.u.host_attr.debug_ba,
 				   host_attr->debug_area_dma_addr);
 	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
+		pr_err("memory address set failed\n");
 		return ret;
 	}
 
@@ -2573,7 +2466,7 @@ int ena_com_set_host_attributes(struct ena_com_dev *ena_dev)
 				   &cmd.u.host_attr.os_info_ba,
 				   host_attr->host_info_dma_addr);
 	if (unlikely(ret)) {
-		ena_trc_err("memory address set failed\n");
+		pr_err("memory address set failed\n");
 		return ret;
 	}
 
@@ -2586,7 +2479,7 @@ int ena_com_set_host_attributes(struct ena_com_dev *ena_dev)
 					    sizeof(resp));
 
 	if (unlikely(ret))
-		ena_trc_err("Failed to set host attributes: %d\n", ret);
+		pr_err("Failed to set host attributes: %d\n", ret);
 
 	return ret;
 }
@@ -2602,7 +2495,7 @@ int ena_com_update_nonadaptive_moderation_interval_tx(struct ena_com_dev *ena_de
 						      u32 tx_coalesce_usecs)
 {
 	if (!ena_dev->intr_delay_resolution) {
-		ena_trc_err("Illegal interrupt delay granularity value\n");
+		pr_err("Illegal interrupt delay granularity value\n");
 		return -EFAULT;
 	}
 
@@ -2616,7 +2509,7 @@ int ena_com_update_nonadaptive_moderation_interval_rx(struct ena_com_dev *ena_de
 						      u32 rx_coalesce_usecs)
 {
 	if (!ena_dev->intr_delay_resolution) {
-		ena_trc_err("Illegal interrupt delay granularity value\n");
+		pr_err("Illegal interrupt delay granularity value\n");
 		return -EFAULT;
 	}
 
@@ -2647,12 +2540,12 @@ int ena_com_init_interrupt_moderation(struct ena_com_dev *ena_dev)
 
 	if (rc) {
 		if (rc == -EPERM) {
-			ena_trc_info("Feature %d isn't supported\n",
-				     ENA_ADMIN_INTERRUPT_MODERATION);
+			pr_info("Feature %d isn't supported\n",
+				ENA_ADMIN_INTERRUPT_MODERATION);
 			rc = 0;
 		} else {
-			ena_trc_err("Failed to get interrupt moderation admin cmd. rc: %d\n",
-				    rc);
+			pr_err("Failed to get interrupt moderation admin cmd. rc: %d\n",
+			       rc);
 		}
 
 		/* no moderation supported, disable adaptive support */
diff --git a/drivers/amazon/net/ena/ena_com.h b/drivers/amazon/net/ena/ena_com.h
index e028d69..3505088 100644
--- a/drivers/amazon/net/ena/ena_com.h
+++ b/drivers/amazon/net/ena/ena_com.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -47,24 +47,8 @@
 #include "ena_eth_io_defs.h"
 #include "ena_regs_defs.h"
 
-#define ena_trc_dbg(format, arg...) \
-	pr_debug("[ENA_COM: %s] " format, __func__, ##arg)
-#define ena_trc_info(format, arg...) \
-	pr_info("[ENA_COM: %s] " format, __func__, ##arg)
-#define ena_trc_warn(format, arg...) \
-	pr_warn("[ENA_COM: %s] " format, __func__, ##arg)
-#define ena_trc_err(format, arg...) \
-	pr_err("[ENA_COM: %s] " format, __func__, ##arg)
-
-#define ENA_ASSERT(cond, format, arg...)				\
-	do {								\
-		if (unlikely(!(cond))) {				\
-			ena_trc_err(					\
-				"Assert failed on %s:%s:%d:" format,	\
-				__FILE__, __func__, __LINE__, ##arg);	\
-			WARN_ON(!(cond));				\
-		}							\
-	} while (0)
+#undef pr_fmt
+#define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
 
 #define ENA_MAX_NUM_IO_QUEUES		128U
 /* We need to queues for each IO (on for Tx and one for Rx) */
@@ -141,8 +125,8 @@ struct ena_com_rx_buf_info {
 };
 
 struct ena_com_io_desc_addr {
-	u8  __iomem *pbuf_dev_addr; /* LLQ address */
-	u8  *virt_addr;
+	u8 __iomem *pbuf_dev_addr; /* LLQ address */
+	u8 *virt_addr;
 	dma_addr_t phys_addr;
 };
 
@@ -150,8 +134,6 @@ struct ena_com_tx_meta {
 	u16 mss;
 	u16 l3_hdr_len;
 	u16 l3_hdr_offset;
-	u16 l3_outer_hdr_len; /* In words */
-	u16 l3_outer_hdr_offset;
 	u16 l4_hdr_len; /* In words */
 };
 
@@ -387,7 +369,7 @@ int ena_com_mmio_reg_read_request_init(struct ena_com_dev *ena_dev);
 
 /* ena_com_set_mmio_read_mode - Enable/disable the mmio reg read mechanism
  * @ena_dev: ENA communication layer struct
- * @realess_supported: readless mode (enable/disable)
+ * @readless_supported: readless mode (enable/disable)
  */
 void ena_com_set_mmio_read_mode(struct ena_com_dev *ena_dev,
 				bool readless_supported);
@@ -436,7 +418,7 @@ int ena_com_dev_reset(struct ena_com_dev *ena_dev);
 
 /* ena_com_create_io_queue - Create io queue.
  * @ena_dev: ENA communication layer struct
- * ena_com_create_io_ctx - create context structure
+ * @ctx - create context structure
  *
  * Create the submission and the completion queues.
  *
@@ -445,8 +427,9 @@ int ena_com_dev_reset(struct ena_com_dev *ena_dev);
 int ena_com_create_io_queue(struct ena_com_dev *ena_dev,
 			    struct ena_com_create_io_ctx *ctx);
 
-/* ena_com_admin_destroy - Destroy IO queue with the queue id - qid.
+/* ena_com_destroy_io_queue - Destroy IO queue with the queue id - qid.
  * @ena_dev: ENA communication layer struct
+ * @qid - the caller virtual queue id.
  */
 void ena_com_destroy_io_queue(struct ena_com_dev *ena_dev, u16 qid);
 
@@ -987,8 +970,8 @@ static inline void ena_com_calculate_interrupt_delay(struct ena_com_dev *ena_dev
 		return;
 
 	curr_moder_idx = (enum ena_intr_moder_level)(*moder_tbl_idx);
-	if (unlikely(curr_moder_idx >=  ENA_INTR_MAX_NUM_OF_LEVELS)) {
-		ena_trc_err("Wrong moderation index %u\n", curr_moder_idx);
+	if (unlikely(curr_moder_idx >= ENA_INTR_MAX_NUM_OF_LEVELS)) {
+		pr_err("Wrong moderation index %u\n", curr_moder_idx);
 		return;
 	}
 
@@ -1044,7 +1027,7 @@ static inline void ena_com_update_intr_reg(struct ena_eth_io_intr_reg *intr_reg,
 
 	intr_reg->intr_control |=
 		(tx_delay_interval << ENA_ETH_IO_INTR_REG_TX_INTR_DELAY_SHIFT)
-		& ENA_ETH_IO_INTR_REG_RX_INTR_DELAY_MASK;
+		& ENA_ETH_IO_INTR_REG_TX_INTR_DELAY_MASK;
 
 	if (unmask)
 		intr_reg->intr_control |= ENA_ETH_IO_INTR_REG_INTR_UNMASK_MASK;
diff --git a/drivers/amazon/net/ena/ena_common_defs.h b/drivers/amazon/net/ena/ena_common_defs.h
index 4a086f5..bb8d736 100644
--- a/drivers/amazon/net/ena/ena_common_defs.h
+++ b/drivers/amazon/net/ena/ena_common_defs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -32,17 +32,13 @@
 #ifndef _ENA_COMMON_H_
 #define _ENA_COMMON_H_
 
-/* spec version */
-#define ENA_COMMON_SPEC_VERSION_MAJOR	0 /* spec version major */
-#define ENA_COMMON_SPEC_VERSION_MINOR	10 /* spec version minor */
+#define ENA_COMMON_SPEC_VERSION_MAJOR	0 /*  */
+#define ENA_COMMON_SPEC_VERSION_MINOR	10 /*  */
 
 /* ENA operates with 48-bit memory addresses. ena_mem_addr_t */
 struct ena_common_mem_addr {
-	/* word 0 : low 32 bit of the memory address */
 	u32 mem_addr_low;
 
-	/* word 1 : */
-	/* high 16 bits of the memory address */
 	u16 mem_addr_high;
 
 	/* MBZ */
diff --git a/drivers/amazon/net/ena/ena_eth_com.c b/drivers/amazon/net/ena/ena_eth_com.c
index f31cfcf..539c536 100644
--- a/drivers/amazon/net/ena/ena_eth_com.c
+++ b/drivers/amazon/net/ena/ena_eth_com.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -60,7 +60,7 @@ static inline void ena_com_cq_inc_head(struct ena_com_io_cq *io_cq)
 
 	/* Switch phase bit in case of wrap around */
 	if (unlikely((io_cq->head & (io_cq->q_depth - 1)) == 0))
-		io_cq->phase = !io_cq->phase;
+		io_cq->phase ^= 1;
 }
 
 static inline void *get_sq_desc(struct ena_com_io_sq *io_sq)
@@ -95,7 +95,7 @@ static inline void ena_com_sq_update_tail(struct ena_com_io_sq *io_sq)
 
 	/* Switch phase bit in case of wrap around */
 	if (unlikely((io_sq->tail & (io_sq->q_depth - 1)) == 0))
-		io_sq->phase = !io_sq->phase;
+		io_sq->phase ^= 1;
 }
 
 static inline int ena_com_write_header(struct ena_com_io_sq *io_sq,
@@ -109,7 +109,7 @@ static inline int ena_com_write_header(struct ena_com_io_sq *io_sq,
 		return 0;
 
 	if (unlikely(!io_sq->header_addr)) {
-		ena_trc_err("Push buffer header ptr is NULL\n");
+		pr_err("Push buffer header ptr is NULL\n");
 		return -EINVAL;
 	}
 
@@ -127,7 +127,7 @@ static inline struct ena_eth_io_rx_cdesc_base *
 		idx * io_cq->cdesc_entry_size_in_bytes);
 }
 
-static inline int ena_com_cdesc_rx_pkt_get(struct ena_com_io_cq *io_cq,
+static inline u16 ena_com_cdesc_rx_pkt_get(struct ena_com_io_cq *io_cq,
 					   u16 *first_cdesc_idx)
 {
 	struct ena_eth_io_rx_cdesc_base *cdesc;
@@ -154,8 +154,8 @@ static inline int ena_com_cdesc_rx_pkt_get(struct ena_com_io_cq *io_cq,
 		io_cq->cur_rx_pkt_cdesc_count = 0;
 		io_cq->cur_rx_pkt_cdesc_start_idx = head_masked;
 
-		ena_trc_dbg("ena q_id: %d packets were completed. first desc idx %u descs# %d\n",
-			    io_cq->qid, *first_cdesc_idx, count);
+		pr_debug("ena q_id: %d packets were completed. first desc idx %u descs# %d\n",
+			 io_cq->qid, *first_cdesc_idx, count);
 	} else {
 		io_cq->cur_rx_pkt_cdesc_count += count;
 		count = 0;
@@ -200,8 +200,8 @@ static inline void ena_com_create_and_store_tx_meta_desc(struct ena_com_io_sq *i
 		ENA_ETH_IO_TX_META_DESC_MSS_LO_MASK;
 	/* bits 10-13 of the mss */
 	meta_desc->len_ctrl |= ((ena_meta->mss >> 10) <<
-		ENA_ETH_IO_TX_META_DESC_MSS_HI_PTP_SHIFT) &
-		ENA_ETH_IO_TX_META_DESC_MSS_HI_PTP_MASK;
+		ENA_ETH_IO_TX_META_DESC_MSS_HI_SHIFT) &
+		ENA_ETH_IO_TX_META_DESC_MSS_HI_MASK;
 
 	/* Extended meta desc */
 	meta_desc->len_ctrl |= ENA_ETH_IO_TX_META_DESC_ETH_META_TYPE_MASK;
@@ -250,14 +250,10 @@ static inline void ena_com_rx_set_flags(struct ena_com_rx_ctx *ena_rx_ctx,
 		(cdesc->status & ENA_ETH_IO_RX_CDESC_BASE_IPV4_FRAG_MASK) >>
 		ENA_ETH_IO_RX_CDESC_BASE_IPV4_FRAG_SHIFT;
 
-	ena_trc_dbg("ena_rx_ctx->l3_proto %d ena_rx_ctx->l4_proto %d\nena_rx_ctx->l3_csum_err %d ena_rx_ctx->l4_csum_err %d\nhash frag %d frag: %d cdesc_status: %x\n",
-		    ena_rx_ctx->l3_proto,
-		    ena_rx_ctx->l4_proto,
-		    ena_rx_ctx->l3_csum_err,
-		    ena_rx_ctx->l4_csum_err,
-		    ena_rx_ctx->hash,
-		    ena_rx_ctx->frag,
-		    cdesc->status);
+	pr_debug("ena_rx_ctx->l3_proto %d ena_rx_ctx->l4_proto %d\nena_rx_ctx->l3_csum_err %d ena_rx_ctx->l4_csum_err %d\nhash frag %d frag: %d cdesc_status: %x\n",
+		 ena_rx_ctx->l3_proto, ena_rx_ctx->l4_proto,
+		 ena_rx_ctx->l3_csum_err, ena_rx_ctx->l4_csum_err,
+		 ena_rx_ctx->hash, ena_rx_ctx->frag, cdesc->status);
 }
 
 /*****************************************************************************/
@@ -277,18 +273,17 @@ int ena_com_prepare_tx(struct ena_com_io_sq *io_sq,
 	bool have_meta;
 	u64 addr_hi;
 
-	ENA_ASSERT(io_sq->direction == ENA_COM_IO_QUEUE_DIRECTION_TX,
-		   "wrong Q type");
+	WARN(io_sq->direction != ENA_COM_IO_QUEUE_DIRECTION_TX, "wrong Q type");
 
 	/* num_bufs +1 for potential meta desc */
 	if (ena_com_sq_empty_space(io_sq) < (num_bufs + 1)) {
-		ena_trc_err("Not enough space in the tx queue\n");
+		pr_err("Not enough space in the tx queue\n");
 		return -ENOMEM;
 	}
 
 	if (unlikely(header_len > io_sq->tx_max_header_size)) {
-		ena_trc_err("header size is too large %d max header: %d\n",
-			    header_len, io_sq->tx_max_header_size);
+		pr_err("header size is too large %d max header: %d\n",
+		       header_len, io_sq->tx_max_header_size);
 		return -EINVAL;
 	}
 
@@ -407,8 +402,7 @@ int ena_com_rx_pkt(struct ena_com_io_cq *io_cq,
 	u16 nb_hw_desc;
 	u16 i;
 
-	ENA_ASSERT(io_cq->direction == ENA_COM_IO_QUEUE_DIRECTION_RX,
-		   "wrong Q type");
+	WARN(io_cq->direction != ENA_COM_IO_QUEUE_DIRECTION_RX, "wrong Q type");
 
 	nb_hw_desc = ena_com_cdesc_rx_pkt_get(io_cq, &cdesc_idx);
 	if (nb_hw_desc == 0) {
@@ -416,12 +410,12 @@ int ena_com_rx_pkt(struct ena_com_io_cq *io_cq,
 		return 0;
 	}
 
-	ena_trc_dbg("fetch rx packet: queue %d completed desc: %d\n",
-		    io_cq->qid, nb_hw_desc);
+	pr_debug("fetch rx packet: queue %d completed desc: %d\n", io_cq->qid,
+		 nb_hw_desc);
 
 	if (unlikely(nb_hw_desc > ena_rx_ctx->max_bufs)) {
-		ena_trc_err("Too many RX cdescs (%d) > MAX(%d)\n",
-			    nb_hw_desc, ena_rx_ctx->max_bufs);
+		pr_err("Too many RX cdescs (%d) > MAX(%d)\n", nb_hw_desc,
+		       ena_rx_ctx->max_bufs);
 		return -ENOSPC;
 	}
 
@@ -436,8 +430,8 @@ int ena_com_rx_pkt(struct ena_com_io_cq *io_cq,
 	/* Update SQ head ptr */
 	io_sq->next_to_comp += nb_hw_desc;
 
-	ena_trc_dbg("[%s][QID#%d] Updating SQ head to: %d\n", __func__,
-		    io_sq->qid, io_sq->next_to_comp);
+	pr_debug("[%s][QID#%d] Updating SQ head to: %d\n", __func__, io_sq->qid,
+		 io_sq->next_to_comp);
 
 	/* Get rx flags from the last pkt */
 	ena_com_rx_set_flags(ena_rx_ctx, cdesc);
@@ -452,8 +446,7 @@ int ena_com_add_single_rx_desc(struct ena_com_io_sq *io_sq,
 {
 	struct ena_eth_io_rx_desc *desc;
 
-	ENA_ASSERT(io_sq->direction == ENA_COM_IO_QUEUE_DIRECTION_RX,
-		   "wrong Q type");
+	WARN(io_sq->direction != ENA_COM_IO_QUEUE_DIRECTION_RX, "wrong Q type");
 
 	if (unlikely(ena_com_sq_empty_space(io_sq) == 0))
 		return -ENOSPC;
@@ -494,7 +487,8 @@ int ena_com_tx_comp_req_id_get(struct ena_com_io_cq *io_cq, u16 *req_id)
 
 	/* When the current completion descriptor phase isn't the same as the
 	 * expected, it mean that the device still didn't update
-	 * this completion. */
+	 * this completion.
+	 */
 	cdesc_phase = cdesc->flags & ENA_ETH_IO_TX_CDESC_PHASE_MASK;
 	if (cdesc_phase != expected_phase)
 		return -EAGAIN;
diff --git a/drivers/amazon/net/ena/ena_eth_com.h b/drivers/amazon/net/ena/ena_eth_com.h
index 571c827..bb53c3a 100644
--- a/drivers/amazon/net/ena/ena_eth_com.h
+++ b/drivers/amazon/net/ena/ena_eth_com.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -111,8 +111,8 @@ static inline int ena_com_write_sq_doorbell(struct ena_com_io_sq *io_sq)
 
 	tail = io_sq->tail;
 
-	ena_trc_dbg("write submission queue doorbell for queue: %d tail: %d\n",
-		    io_sq->qid, tail);
+	pr_debug("write submission queue doorbell for queue: %d tail: %d\n",
+		 io_sq->qid, tail);
 
 	writel(tail, io_sq->db_addr);
 
@@ -129,8 +129,8 @@ static inline int ena_com_update_dev_comp_head(struct ena_com_io_cq *io_cq)
 	need_update = unreported_comp > (io_cq->q_depth / ENA_COMP_HEAD_THRESH);
 
 	if (io_cq->cq_head_db_reg && need_update) {
-		ena_trc_dbg("Write completion queue doorbell for queue %d: head: %d\n",
-			    io_cq->qid, head);
+		pr_debug("Write completion queue doorbell for queue %d: head: %d\n",
+			 io_cq->qid, head);
 		writel(head, io_cq->cq_head_db_reg);
 		io_cq->last_head_update = head;
 	}
diff --git a/drivers/amazon/net/ena/ena_eth_io_defs.h b/drivers/amazon/net/ena/ena_eth_io_defs.h
index 34fd33d..f320c58 100644
--- a/drivers/amazon/net/ena/ena_eth_io_defs.h
+++ b/drivers/amazon/net/ena/ena_eth_io_defs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -32,35 +32,30 @@
 #ifndef _ENA_ETH_IO_H_
 #define _ENA_ETH_IO_H_
 
-/* Layer 3 protocol index */
 enum ena_eth_io_l3_proto_index {
-	ENA_ETH_IO_L3_PROTO_UNKNOWN = 0,
+	ENA_ETH_IO_L3_PROTO_UNKNOWN	= 0,
 
-	ENA_ETH_IO_L3_PROTO_IPV4 = 8,
+	ENA_ETH_IO_L3_PROTO_IPV4	= 8,
 
-	ENA_ETH_IO_L3_PROTO_IPV6 = 11,
+	ENA_ETH_IO_L3_PROTO_IPV6	= 11,
 
-	ENA_ETH_IO_L3_PROTO_FCOE = 21,
+	ENA_ETH_IO_L3_PROTO_FCOE	= 21,
 
-	ENA_ETH_IO_L3_PROTO_ROCE = 22,
+	ENA_ETH_IO_L3_PROTO_ROCE	= 22,
 };
 
-/* Layer 4 protocol index */
 enum ena_eth_io_l4_proto_index {
-	ENA_ETH_IO_L4_PROTO_UNKNOWN = 0,
+	ENA_ETH_IO_L4_PROTO_UNKNOWN		= 0,
 
-	ENA_ETH_IO_L4_PROTO_TCP = 12,
+	ENA_ETH_IO_L4_PROTO_TCP			= 12,
 
-	ENA_ETH_IO_L4_PROTO_UDP = 13,
+	ENA_ETH_IO_L4_PROTO_UDP			= 13,
 
-	ENA_ETH_IO_L4_PROTO_ROUTEABLE_ROCE = 23,
+	ENA_ETH_IO_L4_PROTO_ROUTEABLE_ROCE	= 23,
 };
 
-/* ENA IO Queue Tx descriptor */
 struct ena_eth_io_tx_desc {
-	/* word 0 : */
-	/* length, request id and control flags
-	 * 15:0 : length - Buffer length in bytes, must
+	/* 15:0 : length - Buffer length in bytes, must
 	 *    include any packet trailers that the ENA supposed
 	 *    to update like End-to-End CRC, Authentication GMAC
 	 *    etc. This length must not include the
@@ -83,30 +78,17 @@ struct ena_eth_io_tx_desc {
 	 */
 	u32 len_ctrl;
 
-	/* word 1 : */
-	/* ethernet control
-	 * 3:0 : l3_proto_idx - L3 protocol, if
-	 *    tunnel_ctrl[0] is set, then this is the inner
-	 *    packet L3. This field required when
-	 *    l3_csum_en,l3_csum or tso_en are set.
+	/* 3:0 : l3_proto_idx - L3 protocol. This field
+	 *    required when l3_csum_en,l3_csum or tso_en are set.
 	 * 4 : DF - IPv4 DF, must be 0 if packet is IPv4 and
 	 *    DF flags of the IPv4 header is 0. Otherwise must
 	 *    be set to 1
 	 * 6:5 : reserved5
-	 * 7 : tso_en - Enable TSO, For TCP only. For packets
-	 *    with tunnel (tunnel_ctrl[0]=1), then the inner
-	 *    packet will be segmented while the outer tunnel is
-	 *    duplicated
-	 * 12:8 : l4_proto_idx - L4 protocol, if
-	 *    tunnel_ctrl[0] is set, then this is the inner
-	 *    packet L4. This field need to be set when
-	 *    l4_csum_en or tso_en are set.
-	 * 13 : l3_csum_en - enable IPv4 header checksum. if
-	 *    tunnel_ctrl[0] is set, then this will enable
-	 *    checksum for the inner packet IPv4
-	 * 14 : l4_csum_en - enable TCP/UDP checksum. if
-	 *    tunnel_ctrl[0] is set, then this will enable
-	 *    checksum on the inner packet TCP/UDP checksum
+	 * 7 : tso_en - Enable TSO, For TCP only.
+	 * 12:8 : l4_proto_idx - L4 protocol. This field need
+	 *    to be set when l4_csum_en or tso_en are set.
+	 * 13 : l3_csum_en - enable IPv4 header checksum.
+	 * 14 : l4_csum_en - enable TCP/UDP checksum.
 	 * 15 : ethernet_fcs_dis - when set, the controller
 	 *    will not append the 802.3 Ethernet Frame Check
 	 *    Sequence to the packet
@@ -122,19 +104,14 @@ struct ena_eth_io_tx_desc {
 	 *    must not include the tcp length field. L4 partial
 	 *    checksum should be used for IPv6 packet that
 	 *    contains Routing Headers.
-	 * 20:18 : tunnel_ctrl - Bit 0: tunneling exists, Bit
-	 *    1: tunnel packet actually uses UDP as L4, Bit 2:
-	 *    tunnel packet L3 protocol: 0: IPv4 1: IPv6
-	 * 21 : ts_req - Indicates that the packet is IEEE
-	 *    1588v2 packet requiring the timestamp
+	 * 20:18 : reserved18 - MBZ
+	 * 21 : reserved21 - MBZ
 	 * 31:22 : req_id_lo - Request ID[9:0]
 	 */
 	u32 meta_ctrl;
 
-	/* word 2 : Buffer address bits[31:0] */
 	u32 buff_addr_lo;
 
-	/* word 3 : */
 	/* address high and header size
 	 * 15:0 : addr_hi - Buffer Pointer[47:32]
 	 * 23:16 : reserved16_w2
@@ -153,22 +130,16 @@ struct ena_eth_io_tx_desc {
 	u32 buff_addr_hi_hdr_sz;
 };
 
-/* ENA IO Queue Tx Meta descriptor */
 struct ena_eth_io_tx_meta_desc {
-	/* word 0 : */
-	/* length, request id and control flags
-	 * 9:0 : req_id_lo - Request ID[9:0]
-	 * 11:10 : outr_l3_off_hi - valid if
-	 *    tunnel_ctrl[0]=1. bits[4:3] of outer packet L3
-	 *    offset
+	/* 9:0 : req_id_lo - Request ID[9:0]
+	 * 11:10 : reserved10 - MBZ
 	 * 12 : reserved12 - MBZ
 	 * 13 : reserved13 - MBZ
 	 * 14 : ext_valid - if set, offset fields in Word2
-	 *    are valid Also MSS High in Word 0 and Outer L3
-	 *    Offset High in WORD 0 and bits [31:24] in Word 3
-	 * 15 : word3_valid - If set Crypto Info[23:0] of
-	 *    Word 3 is valid
-	 * 19:16 : mss_hi_ptp
+	 *    are valid Also MSS High in Word 0 and bits [31:24]
+	 *    in Word 3
+	 * 15 : reserved15
+	 * 19:16 : mss_hi
 	 * 20 : eth_meta_type - 0: Tx Metadata Descriptor, 1:
 	 *    Extended Metadata Descriptor
 	 * 21 : meta_store - Store extended metadata in queue
@@ -189,50 +160,25 @@ struct ena_eth_io_tx_meta_desc {
 	 */
 	u32 len_ctrl;
 
-	/* word 1 : */
-	/* word 1
-	 * 5:0 : req_id_hi
+	/* 5:0 : req_id_hi
 	 * 31:6 : reserved6 - MBZ
 	 */
 	u32 word1;
 
-	/* word 2 : */
-	/* word 2
-	 * 7:0 : l3_hdr_len - the header length L3 IP header.
-	 *    if tunnel_ctrl[0]=1, this is the IP header length
-	 *    of the inner packet.  FIXME - check if includes IP
-	 *    options hdr_len
-	 * 15:8 : l3_hdr_off - the offset of the first byte
-	 *    in the L3 header from the beginning of the to-be
-	 *    transmitted packet. if tunnel_ctrl[0]=1, this is
-	 *    the offset the L3 header of the inner packet
+	/* 7:0 : l3_hdr_len
+	 * 15:8 : l3_hdr_off
 	 * 21:16 : l4_hdr_len_in_words - counts the L4 header
 	 *    length in words. there is an explicit assumption
 	 *    that L4 header appears right after L3 header and
-	 *    L4 offset is based on l3_hdr_off+l3_hdr_len FIXME
-	 *    - pls confirm
+	 *    L4 offset is based on l3_hdr_off+l3_hdr_len
 	 * 31:22 : mss_lo
 	 */
 	u32 word2;
 
-	/* word 3 : */
-	/* word 3
-	 * 23:0 : crypto_info
-	 * 28:24 : outr_l3_hdr_len_words - valid if
-	 *    tunnel_ctrl[0]=1.  Counts in words
-	 * 31:29 : outr_l3_off_lo - valid if
-	 *    tunnel_ctrl[0]=1. bits[2:0] of outer packet L3
-	 *    offset. Counts the offset of the tunnel IP header
-	 *    from beginning of the packet. NOTE: if the tunnel
-	 *    header requires CRC or checksum, it is expected to
-	 *    be done by the driver as it is not done by the HW
-	 */
-	u32 word3;
+	u32 reserved;
 };
 
-/* ENA IO Queue Tx completions descriptor */
 struct ena_eth_io_tx_cdesc {
-	/* word 0 : */
 	/* Request ID[15:0] */
 	u16 req_id;
 
@@ -244,24 +190,19 @@ struct ena_eth_io_tx_cdesc {
 	 */
 	u8 flags;
 
-	/* word 1 : */
 	u16 sub_qid;
 
-	/* indicates location of submission queue head */
 	u16 sq_head_idx;
 };
 
-/* ENA IO Queue Rx descriptor */
 struct ena_eth_io_rx_desc {
-	/* word 0 : */
 	/* In bytes. 0 means 64KB */
 	u16 length;
 
 	/* MBZ */
 	u8 reserved2;
 
-	/* control flags
-	 * 0 : phase
+	/* 0 : phase
 	 * 1 : reserved1 - MBZ
 	 * 2 : first - Indicates first descriptor in
 	 *    transaction
@@ -272,118 +213,90 @@ struct ena_eth_io_rx_desc {
 	 */
 	u8 ctrl;
 
-	/* word 1 : */
 	u16 req_id;
 
 	/* MBZ */
 	u16 reserved6;
 
-	/* word 2 : Buffer address bits[31:0] */
 	u32 buff_addr_lo;
 
-	/* word 3 : */
-	/* Buffer Address bits[47:16] */
 	u16 buff_addr_hi;
 
 	/* MBZ */
 	u16 reserved16_w3;
 };
 
-/* ENA IO Queue Rx Completion Base Descriptor (4-word format). Note: all
- * ethernet parsing information are valid only when last=1
+/* 4-word format Note: all ethernet parsing information are valid only when
+ * last=1
  */
 struct ena_eth_io_rx_cdesc_base {
-	/* word 0 : */
-	/* 4:0 : l3_proto_idx - L3 protocol index
-	 * 6:5 : src_vlan_cnt - Source VLAN count
-	 * 7 : tunnel - Tunnel exists
-	 * 12:8 : l4_proto_idx - L4 protocol index
+	/* 4:0 : l3_proto_idx
+	 * 6:5 : src_vlan_cnt
+	 * 7 : reserved7 - MBZ
+	 * 12:8 : l4_proto_idx
 	 * 13 : l3_csum_err - when set, either the L3
 	 *    checksum error detected, or, the controller didn't
-	 *    validate the checksum, If tunnel exists, this
-	 *    result is for the inner packet. This bit is valid
-	 *    only when l3_proto_idx indicates IPv4 packet
+	 *    validate the checksum. This bit is valid only when
+	 *    l3_proto_idx indicates IPv4 packet
 	 * 14 : l4_csum_err - when set, either the L4
 	 *    checksum error detected, or, the controller didn't
-	 *    validate the checksum. If tunnel exists, this
-	 *    result is for the inner packet. This bit is valid
-	 *    only when l4_proto_idx indicates TCP/UDP packet,
-	 *    and, ipv4_frag is not set
+	 *    validate the checksum. This bit is valid only when
+	 *    l4_proto_idx indicates TCP/UDP packet, and,
+	 *    ipv4_frag is not set
 	 * 15 : ipv4_frag - Indicates IPv4 fragmented packet
-	 * 17:16 : reserved16
-	 * 19:18 : reserved18
-	 * 20 : secured_pkt - Set if packet was handled by
-	 *    inline crypto engine
-	 * 22:21 : crypto_status -  bit 0 secured direction:
-	 *    0: decryption, 1: encryption. bit 1 reserved
-	 * 23 : reserved23
+	 * 23:16 : reserved16
 	 * 24 : phase
 	 * 25 : l3_csum2 - second checksum engine result
 	 * 26 : first - Indicates first descriptor in
 	 *    transaction
 	 * 27 : last - Indicates last descriptor in
 	 *    transaction
-	 * 28 : inr_l4_csum - TCP/UDP checksum results for
-	 *    inner packet
-	 * 29 : reserved29
+	 * 29:28 : reserved28
 	 * 30 : buffer - 0: Metadata descriptor. 1: Buffer
 	 *    Descriptor was used
 	 * 31 : reserved31
 	 */
 	u32 status;
 
-	/* word 1 : */
 	u16 length;
 
 	u16 req_id;
 
-	/* word 2 : 32-bit hash result */
+	/* 32-bit hash result */
 	u32 hash;
 
-	/* word 3 : */
-	/* submission queue number */
 	u16 sub_qid;
 
 	u16 reserved;
 };
 
-/* ENA IO Queue Rx Completion Descriptor (8-word format) */
+/* 8-word format */
 struct ena_eth_io_rx_cdesc_ext {
-	/* words 0:3 : Rx Completion Extended */
 	struct ena_eth_io_rx_cdesc_base base;
 
-	/* word 4 : Completed Buffer address bits[31:0] */
 	u32 buff_addr_lo;
 
-	/* word 5 : */
-	/* the buffer address used bits[47:32] */
 	u16 buff_addr_hi;
 
 	u16 reserved16;
 
-	/* word 6 : Reserved */
 	u32 reserved_w6;
 
-	/* word 7 : Reserved */
 	u32 reserved_w7;
 };
 
-/* ENA Interrupt Unmask Register */
 struct ena_eth_io_intr_reg {
-	/* word 0 : */
-	/* 14:0 : rx_intr_delay - rx interrupt delay value
-	 * 29:15 : tx_intr_delay - tx interrupt delay value
-	 * 30 : intr_unmask - if set, unmasks interrupt
+	/* 14:0 : rx_intr_delay
+	 * 29:15 : tx_intr_delay
+	 * 30 : intr_unmask
 	 * 31 : reserved
 	 */
 	u32 intr_control;
 };
 
-/* ENA NUMA Node configuration register */
 struct ena_eth_io_numa_node_cfg_reg {
-	/* word 0 : */
 	/* 7:0 : numa
-	 * 30:8 : resrved
+	 * 30:8 : reserved
 	 * 31 : enabled
 	 */
 	u32 numa_cfg;
@@ -418,10 +331,6 @@ struct ena_eth_io_numa_node_cfg_reg {
 #define ENA_ETH_IO_TX_DESC_ETHERNET_FCS_DIS_MASK BIT(15)
 #define ENA_ETH_IO_TX_DESC_L4_CSUM_PARTIAL_SHIFT 17
 #define ENA_ETH_IO_TX_DESC_L4_CSUM_PARTIAL_MASK BIT(17)
-#define ENA_ETH_IO_TX_DESC_TUNNEL_CTRL_SHIFT 18
-#define ENA_ETH_IO_TX_DESC_TUNNEL_CTRL_MASK GENMASK(20, 18)
-#define ENA_ETH_IO_TX_DESC_TS_REQ_SHIFT 21
-#define ENA_ETH_IO_TX_DESC_TS_REQ_MASK BIT(21)
 #define ENA_ETH_IO_TX_DESC_REQ_ID_LO_SHIFT 22
 #define ENA_ETH_IO_TX_DESC_REQ_ID_LO_MASK GENMASK(31, 22)
 #define ENA_ETH_IO_TX_DESC_ADDR_HI_MASK GENMASK(15, 0)
@@ -430,14 +339,10 @@ struct ena_eth_io_numa_node_cfg_reg {
 
 /* tx_meta_desc */
 #define ENA_ETH_IO_TX_META_DESC_REQ_ID_LO_MASK GENMASK(9, 0)
-#define ENA_ETH_IO_TX_META_DESC_OUTR_L3_OFF_HI_SHIFT 10
-#define ENA_ETH_IO_TX_META_DESC_OUTR_L3_OFF_HI_MASK GENMASK(11, 10)
 #define ENA_ETH_IO_TX_META_DESC_EXT_VALID_SHIFT 14
 #define ENA_ETH_IO_TX_META_DESC_EXT_VALID_MASK BIT(14)
-#define ENA_ETH_IO_TX_META_DESC_WORD3_VALID_SHIFT 15
-#define ENA_ETH_IO_TX_META_DESC_WORD3_VALID_MASK BIT(15)
-#define ENA_ETH_IO_TX_META_DESC_MSS_HI_PTP_SHIFT 16
-#define ENA_ETH_IO_TX_META_DESC_MSS_HI_PTP_MASK GENMASK(19, 16)
+#define ENA_ETH_IO_TX_META_DESC_MSS_HI_SHIFT 16
+#define ENA_ETH_IO_TX_META_DESC_MSS_HI_MASK GENMASK(19, 16)
 #define ENA_ETH_IO_TX_META_DESC_ETH_META_TYPE_SHIFT 20
 #define ENA_ETH_IO_TX_META_DESC_ETH_META_TYPE_MASK BIT(20)
 #define ENA_ETH_IO_TX_META_DESC_META_STORE_SHIFT 21
@@ -460,11 +365,6 @@ struct ena_eth_io_numa_node_cfg_reg {
 #define ENA_ETH_IO_TX_META_DESC_L4_HDR_LEN_IN_WORDS_MASK GENMASK(21, 16)
 #define ENA_ETH_IO_TX_META_DESC_MSS_LO_SHIFT 22
 #define ENA_ETH_IO_TX_META_DESC_MSS_LO_MASK GENMASK(31, 22)
-#define ENA_ETH_IO_TX_META_DESC_CRYPTO_INFO_MASK GENMASK(23, 0)
-#define ENA_ETH_IO_TX_META_DESC_OUTR_L3_HDR_LEN_WORDS_SHIFT 24
-#define ENA_ETH_IO_TX_META_DESC_OUTR_L3_HDR_LEN_WORDS_MASK GENMASK(28, 24)
-#define ENA_ETH_IO_TX_META_DESC_OUTR_L3_OFF_LO_SHIFT 29
-#define ENA_ETH_IO_TX_META_DESC_OUTR_L3_OFF_LO_MASK GENMASK(31, 29)
 
 /* tx_cdesc */
 #define ENA_ETH_IO_TX_CDESC_PHASE_MASK BIT(0)
@@ -482,8 +382,6 @@ struct ena_eth_io_numa_node_cfg_reg {
 #define ENA_ETH_IO_RX_CDESC_BASE_L3_PROTO_IDX_MASK GENMASK(4, 0)
 #define ENA_ETH_IO_RX_CDESC_BASE_SRC_VLAN_CNT_SHIFT 5
 #define ENA_ETH_IO_RX_CDESC_BASE_SRC_VLAN_CNT_MASK GENMASK(6, 5)
-#define ENA_ETH_IO_RX_CDESC_BASE_TUNNEL_SHIFT 7
-#define ENA_ETH_IO_RX_CDESC_BASE_TUNNEL_MASK BIT(7)
 #define ENA_ETH_IO_RX_CDESC_BASE_L4_PROTO_IDX_SHIFT 8
 #define ENA_ETH_IO_RX_CDESC_BASE_L4_PROTO_IDX_MASK GENMASK(12, 8)
 #define ENA_ETH_IO_RX_CDESC_BASE_L3_CSUM_ERR_SHIFT 13
@@ -492,10 +390,6 @@ struct ena_eth_io_numa_node_cfg_reg {
 #define ENA_ETH_IO_RX_CDESC_BASE_L4_CSUM_ERR_MASK BIT(14)
 #define ENA_ETH_IO_RX_CDESC_BASE_IPV4_FRAG_SHIFT 15
 #define ENA_ETH_IO_RX_CDESC_BASE_IPV4_FRAG_MASK BIT(15)
-#define ENA_ETH_IO_RX_CDESC_BASE_SECURED_PKT_SHIFT 20
-#define ENA_ETH_IO_RX_CDESC_BASE_SECURED_PKT_MASK BIT(20)
-#define ENA_ETH_IO_RX_CDESC_BASE_CRYPTO_STATUS_SHIFT 21
-#define ENA_ETH_IO_RX_CDESC_BASE_CRYPTO_STATUS_MASK GENMASK(22, 21)
 #define ENA_ETH_IO_RX_CDESC_BASE_PHASE_SHIFT 24
 #define ENA_ETH_IO_RX_CDESC_BASE_PHASE_MASK BIT(24)
 #define ENA_ETH_IO_RX_CDESC_BASE_L3_CSUM2_SHIFT 25
@@ -504,8 +398,6 @@ struct ena_eth_io_numa_node_cfg_reg {
 #define ENA_ETH_IO_RX_CDESC_BASE_FIRST_MASK BIT(26)
 #define ENA_ETH_IO_RX_CDESC_BASE_LAST_SHIFT 27
 #define ENA_ETH_IO_RX_CDESC_BASE_LAST_MASK BIT(27)
-#define ENA_ETH_IO_RX_CDESC_BASE_INR_L4_CSUM_SHIFT 28
-#define ENA_ETH_IO_RX_CDESC_BASE_INR_L4_CSUM_MASK BIT(28)
 #define ENA_ETH_IO_RX_CDESC_BASE_BUFFER_SHIFT 30
 #define ENA_ETH_IO_RX_CDESC_BASE_BUFFER_MASK BIT(30)
 
@@ -518,8 +410,6 @@ struct ena_eth_io_numa_node_cfg_reg {
 
 /* numa_node_cfg_reg */
 #define ENA_ETH_IO_NUMA_NODE_CFG_REG_NUMA_MASK GENMASK(7, 0)
-#define ENA_ETH_IO_NUMA_NODE_CFG_REG_RESRVED_SHIFT 8
-#define ENA_ETH_IO_NUMA_NODE_CFG_REG_RESRVED_MASK GENMASK(30, 8)
 #define ENA_ETH_IO_NUMA_NODE_CFG_REG_ENABLED_SHIFT 31
 #define ENA_ETH_IO_NUMA_NODE_CFG_REG_ENABLED_MASK BIT(31)
 
diff --git a/drivers/amazon/net/ena/ena_ethtool.c b/drivers/amazon/net/ena/ena_ethtool.c
index fc2d845..16a46d7 100644
--- a/drivers/amazon/net/ena/ena_ethtool.c
+++ b/drivers/amazon/net/ena/ena_ethtool.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -31,6 +31,7 @@
  */
 
 #include <linux/pci.h>
+#include <linux/version.h>
 
 #include "ena_netdev.h"
 
@@ -93,7 +94,7 @@ static const struct ena_stats ena_stats_rx_strings[] = {
 	ENA_STAT_RX_ENTRY(skb_alloc_fail),
 	ENA_STAT_RX_ENTRY(dma_mapping_err),
 	ENA_STAT_RX_ENTRY(bad_desc_num),
-	ENA_STAT_RX_ENTRY(small_copy_len_pkt),
+	ENA_STAT_RX_ENTRY(rx_copybreak_pkt),
 };
 
 static const struct ena_stats ena_stats_ena_com_strings[] = {
@@ -195,12 +196,13 @@ static void ena_get_ethtool_stats(struct net_device *netdev,
 
 int ena_get_sset_count(struct net_device *netdev, int sset)
 {
+	struct ena_adapter *adapter = netdev_priv(netdev);
+
 	if (sset != ETH_SS_STATS)
 		return -EOPNOTSUPP;
 
-	return  netdev->num_tx_queues *
-		(ENA_STATS_ARRAY_TX + ENA_STATS_ARRAY_RX) +
-		ENA_STATS_ARRAY_GLOBAL + ENA_STATS_ARRAY_ENA_COM;
+	return  adapter->num_queues * (ENA_STATS_ARRAY_TX + ENA_STATS_ARRAY_RX)
+		+ ENA_STATS_ARRAY_GLOBAL + ENA_STATS_ARRAY_ENA_COM;
 }
 
 static void ena_queue_strings(struct ena_adapter *adapter, u8 **data)
@@ -263,32 +265,8 @@ static void ena_get_strings(struct net_device *netdev, u32 sset, u8 *data)
 }
 
 static int ena_get_settings(struct net_device *netdev,
-			    struct ethtool_cmd *ecmd)
+							struct ethtool_cmd *ecmd)
 {
-	struct ena_adapter *adapter = netdev_priv(netdev);
-	struct ena_com_dev *ena_dev = adapter->ena_dev;
-	struct ena_admin_get_feature_link_desc *link;
-	struct ena_admin_get_feat_resp feat_resp;
-	int rc;
-
-	rc = ena_com_get_link_params(ena_dev, &feat_resp);
-	if (rc)
-		return rc;
-
-	link = &feat_resp.u.link;
-
-	ethtool_cmd_speed_set(ecmd, link->speed);
-
-	if (link->flags & ENA_ADMIN_GET_FEATURE_LINK_DESC_DUPLEX_MASK)
-		ecmd->duplex = DUPLEX_FULL;
-	else
-		ecmd->duplex = DUPLEX_HALF;
-
-	if (link->flags & ENA_ADMIN_GET_FEATURE_LINK_DESC_AUTONEG_MASK)
-		ecmd->autoneg = AUTONEG_ENABLE;
-	else
-		ecmd->autoneg = AUTONEG_DISABLE;
-
 	return 0;
 }
 
@@ -396,11 +374,6 @@ err:
 	return rc;
 }
 
-static int ena_nway_reset(struct net_device *netdev)
-{
-	return -ENODEV;
-}
-
 static u32 ena_get_msglevel(struct net_device *netdev)
 {
 	struct ena_adapter *adapter = netdev_priv(netdev);
@@ -595,7 +568,7 @@ static int ena_set_rxnfc(struct net_device *netdev, struct ethtool_rxnfc *info)
 	case ETHTOOL_SRXCLSRLINS:
 	default:
 		netif_err(adapter, drv, netdev,
-			  "Command parameters %d doesn't support\n", info->cmd);
+			  "Command parameter %d is not supported\n", info->cmd);
 		rc = -EOPNOTSUPP;
 	}
 
@@ -621,7 +594,7 @@ static int ena_get_rxnfc(struct net_device *netdev, struct ethtool_rxnfc *info,
 	case ETHTOOL_GRXCLSRLALL:
 	default:
 		netif_err(adapter, drv, netdev,
-			  "Command parameters %x doesn't support\n", info->cmd);
+			  "Command parameter %d is not supported\n", info->cmd);
 		rc = -EOPNOTSUPP;
 	}
 
@@ -657,11 +630,13 @@ static int ena_get_rxfh(struct net_device *netdev, u32 *indir, u8 *key,
 	switch (ena_func) {
 	case ENA_ADMIN_TOEPLITZ:
 		func = ETH_RSS_HASH_TOP;
+		break;
 	case ENA_ADMIN_CRC32:
 		func = ETH_RSS_HASH_XOR;
+		break;
 	default:
 		netif_err(adapter, drv, netdev,
-			  "Command parameters doesn't support\n");
+			  "Command parameter is not supported\n");
 		return -EOPNOTSUPP;
 	}
 
@@ -740,12 +715,54 @@ static void ena_get_channels(struct net_device *netdev,
 	channels->combined_count = 0;
 }
 
+static int ena_get_tunable(struct net_device *netdev,
+			   const struct ethtool_tunable *tuna, void *data)
+{
+	struct ena_adapter *adapter = netdev_priv(netdev);
+	int ret = 0;
+
+	switch (tuna->id) {
+	case ETHTOOL_RX_COPYBREAK:
+		*(u32 *)data = adapter->rx_copybreak;
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
+static int ena_set_tunable(struct net_device *netdev,
+			   const struct ethtool_tunable *tuna,
+			   const void *data)
+{
+	struct ena_adapter *adapter = netdev_priv(netdev);
+	int ret = 0;
+	u32 len;
+
+	switch (tuna->id) {
+	case ETHTOOL_RX_COPYBREAK:
+		len = *(u32 *)data;
+		if (len > adapter->netdev->mtu) {
+			ret = -EINVAL;
+			break;
+		}
+		adapter->rx_copybreak = len;
+		break;
+	default:
+		ret = -EINVAL;
+		break;
+	}
+
+	return ret;
+}
+
 static const struct ethtool_ops ena_ethtool_ops = {
 	.get_settings		= ena_get_settings,
 	.get_drvinfo		= ena_get_drvinfo,
 	.get_msglevel		= ena_get_msglevel,
 	.set_msglevel		= ena_set_msglevel,
-	.nway_reset		= ena_nway_reset,
 	.get_link		= ethtool_op_get_link,
 	.get_coalesce		= ena_get_coalesce,
 	.set_coalesce		= ena_set_coalesce,
@@ -760,6 +777,8 @@ static const struct ethtool_ops ena_ethtool_ops = {
 	.get_rxfh		= ena_get_rxfh,
 	.set_rxfh		= ena_set_rxfh,
 	.get_channels		= ena_get_channels,
+	.get_tunable		= ena_get_tunable,
+	.set_tunable		= ena_set_tunable,
 };
 
 void ena_set_ethtool_ops(struct net_device *netdev)
diff --git a/drivers/amazon/net/ena/ena_gen_info.h b/drivers/amazon/net/ena/ena_gen_info.h
deleted file mode 100644
index cacfa40..0000000
--- a/drivers/amazon/net/ena/ena_gen_info.h
+++ /dev/null
@@ -1,37 +0,0 @@
-/******************************************************************************
-Copyright (C) 2015 Annapurna Labs Ltd.
-
-This file may be licensed under the terms of the Annapurna Labs Commercial
-License Agreement.
-
-Alternatively, this file can be distributed under the terms of the GNU General
-Public License V2 as published by the Free Software Foundation and can be
-found at http://www.gnu.org/licenses/gpl-2.0.html
-
-Alternatively, redistribution and use in source and binary forms, with or
-without modification, are permitted provided that the following conditions are
-met:
-
-    *  Redistributions of source code must retain the above copyright notice,
-this list of conditions and the following disclaimer.
-
-    *  Redistributions in binary form must reproduce the above copyright
-notice, this list of conditions and the following disclaimer in
-the documentation and/or other materials provided with the
-distribution.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
-ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
-WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
-DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
-ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
-(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
-LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
-ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
-(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
-SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
-******************************************************************************/
-
-#define	ENA_GEN_DATE	"Thu Nov 19 17:16:56 IST 2015"
-#define	ENA_GEN_COMMIT	"de30f60"
diff --git a/drivers/amazon/net/ena/ena_includes.h b/drivers/amazon/net/ena/ena_includes.h
deleted file mode 100644
index 5ea312f..0000000
--- a/drivers/amazon/net/ena/ena_includes.h
+++ /dev/null
@@ -1,4 +0,0 @@
-#include "ena_common_defs.h"
-#include "ena_regs_defs.h"
-#include "ena_admin_defs.h"
-#include "ena_eth_io_defs.h"
diff --git a/drivers/amazon/net/ena/ena_netdev.c b/drivers/amazon/net/ena/ena_netdev.c
index 6ef418e..ffd5c5d 100644
--- a/drivers/amazon/net/ena/ena_netdev.c
+++ b/drivers/amazon/net/ena/ena_netdev.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -86,8 +86,7 @@ static int enable_missing_tx_detection = 1;
 module_param(enable_missing_tx_detection, int, 0);
 MODULE_PARM_DESC(enable_missing_tx_detection, "Enable missing Tx completions. (default=1)");
 
-
-static int numa_node_override_array[NR_CPUS] = {[0 ... (NR_CPUS -1)] = NUMA_NO_NODE };
+static int numa_node_override_array[NR_CPUS] = {[0 ... (NR_CPUS - 1)] = NUMA_NO_NODE };
 module_param_array(numa_node_override_array, int, NULL, 0);
 MODULE_PARM_DESC(numa_node_override_array, "Numa node override map\n");
 
@@ -111,7 +110,7 @@ static void ena_tx_timeout(struct net_device *dev)
 	adapter->dev_stats.tx_timeout++;
 	u64_stats_update_end(&adapter->syncp);
 
-	netif_err(adapter, tx_err, dev, "Transmit timed out\n");
+	netif_err(adapter, tx_err, dev, "Transmit time out\n");
 
 	/* Change the state of the device to trigger reset */
 	set_bit(ENA_FLAG_TRIGGER_RESET, &adapter->flags);
@@ -179,7 +178,7 @@ static inline int ena_cpu_to_node(int cpu)
 	if (!numa_node_override)
 		return cpu_to_node(cpu);
 
-	if (cpu < NR_CPUS)
+	if (likely(cpu < NR_CPUS))
 		return numa_node_override_array[cpu];
 
 	return NUMA_NO_NODE;
@@ -227,7 +226,7 @@ static void ena_init_io_rings(struct ena_adapter *adapter)
 
 		/* RX specific ring state */
 		rxr->ring_size = adapter->rx_ring_size;
-		rxr->rx_small_copy_len = adapter->small_copy_len;
+		rxr->rx_copybreak = adapter->rx_copybreak;
 		rxr->sgl_size = adapter->max_rx_sgl_size;
 		rxr->smoothed_interval =
 			ena_com_get_nonadaptive_moderation_interval_rx(ena_dev);
@@ -253,7 +252,7 @@ static int ena_setup_tx_resources(struct ena_adapter *adapter, int qid)
 	}
 
 	size = sizeof(struct ena_tx_buffer) * tx_ring->ring_size;
-	node = ena_cpu_to_node(ena_irq->cpu);
+	node = cpu_to_node(ena_irq->cpu);
 
 	tx_ring->tx_buffer_info = vzalloc_node(size, node);
 	if (!tx_ring->tx_buffer_info) {
@@ -322,7 +321,7 @@ static int ena_setup_all_tx_resources(struct ena_adapter *adapter)
 err_setup_tx:
 
 	netif_err(adapter, ifup, adapter->netdev,
-		  "Allocation for TX queue %u failed\n", i);
+		  "Tx queue %d: allocation failed\n", i);
 
 	/* rewind the index freeing the rings as we go */
 	while (i--)
@@ -366,7 +365,7 @@ static int ena_setup_rx_resources(struct ena_adapter *adapter,
 	 * we can always prefetch rx_info + 1
 	 */
 	size = sizeof(struct ena_rx_buffer) * (rx_ring->ring_size + 1);
-	node = ena_cpu_to_node(ena_irq->cpu);
+	node = cpu_to_node(ena_irq->cpu);
 
 	rx_ring->rx_buffer_info = vzalloc_node(size, node);
 	if (!rx_ring->rx_buffer_info) {
@@ -420,7 +419,7 @@ static int ena_setup_all_rx_resources(struct ena_adapter *adapter)
 err_setup_rx:
 
 	netif_err(adapter, ifup, adapter->netdev,
-		  "Allocation for RX queue %u failed\n", i);
+		  "Rx queue %d: allocation failed\n", i);
 
 	/* rewind the index freeing the rings as we go */
 	while (i--)
@@ -840,9 +839,9 @@ static struct sk_buff *ena_rx_skb(struct ena_ring *rx_ring,
 	va = page_address(rx_info->page) + rx_info->page_offset;
 	prefetch(va + NET_IP_ALIGN);
 
-	if (len <= rx_ring->rx_small_copy_len) {
+	if (len <= rx_ring->rx_copybreak) {
 		skb = netdev_alloc_skb_ip_align(rx_ring->netdev,
-						rx_ring->rx_small_copy_len);
+						rx_ring->rx_copybreak);
 		if (unlikely(!skb)) {
 			u64_stats_update_begin(&rx_ring->syncp);
 			rx_ring->rx_stats.skb_alloc_fail++;
@@ -1003,7 +1002,7 @@ static int ena_clean_rx_irq(struct ena_ring *rx_ring, struct napi_struct *napi,
 	int refill_threshold;
 	int rc = 0;
 	int total_len = 0;
-	int small_copy_pkt = 0;
+	int rx_copybreak_pkt = 0;
 
 	netif_dbg(rx_ring->adapter, rx_status, rx_ring->netdev,
 		  "%s qid %d\n", __func__, rx_ring->qid);
@@ -1045,9 +1044,9 @@ static int ena_clean_rx_irq(struct ena_ring *rx_ring, struct napi_struct *napi,
 
 		skb_record_rx_queue(skb, rx_ring->qid);
 
-		if (rx_ring->ena_bufs[0].len <= rx_ring->rx_small_copy_len) {
+		if (rx_ring->ena_bufs[0].len <= rx_ring->rx_copybreak) {
 			total_len += rx_ring->ena_bufs[0].len;
-			small_copy_pkt++;
+			rx_copybreak_pkt++;
 			napi_gro_receive(napi, skb);
 		} else {
 			total_len += skb->len;
@@ -1063,7 +1062,7 @@ static int ena_clean_rx_irq(struct ena_ring *rx_ring, struct napi_struct *napi,
 	u64_stats_update_begin(&rx_ring->syncp);
 	rx_ring->rx_stats.bytes += total_len;
 	rx_ring->rx_stats.cnt += work_done;
-	rx_ring->rx_stats.small_copy_len_pkt += small_copy_pkt;
+	rx_ring->rx_stats.rx_copybreak_pkt += rx_copybreak_pkt;
 	u64_stats_update_end(&rx_ring->syncp);
 
 	rx_ring->next_to_clean = next_to_clean;
@@ -1562,7 +1561,7 @@ static int ena_create_io_tx_queue(struct ena_adapter *adapter, int qid)
 	ctx.mem_queue_type = ena_dev->tx_mem_queue_type;
 	ctx.msix_vector = msix_vector;
 	ctx.queue_size = adapter->tx_ring_size;
-	ctx.numa_node = ena_cpu_to_node(tx_ring->cpu);
+	ctx.numa_node = cpu_to_node(tx_ring->cpu);
 
 	rc = ena_com_create_io_queue(ena_dev, &ctx);
 	if (rc) {
@@ -1582,7 +1581,8 @@ static int ena_create_io_tx_queue(struct ena_adapter *adapter, int qid)
 		ena_com_destroy_io_queue(ena_dev, ena_qid);
 	}
 
-	ena_com_update_numa_node(tx_ring->ena_com_io_cq, ctx.numa_node);
+	ena_com_update_numa_node(tx_ring->ena_com_io_cq,
+				 ena_cpu_to_node(tx_ring->cpu));
 
 	return rc;
 }
@@ -1627,7 +1627,7 @@ static int ena_create_io_rx_queue(struct ena_adapter *adapter, int qid)
 	ctx.mem_queue_type = ENA_ADMIN_PLACEMENT_POLICY_HOST;
 	ctx.msix_vector = msix_vector;
 	ctx.queue_size = adapter->rx_ring_size;
-	ctx.numa_node = ena_cpu_to_node(rx_ring->cpu);
+	ctx.numa_node = cpu_to_node(rx_ring->cpu);
 
 	rc = ena_com_create_io_queue(ena_dev, &ctx);
 	if (rc) {
@@ -1647,7 +1647,8 @@ static int ena_create_io_rx_queue(struct ena_adapter *adapter, int qid)
 		ena_com_destroy_io_queue(ena_dev, ena_qid);
 	}
 
-	ena_com_update_numa_node(rx_ring->ena_com_io_cq, ctx.numa_node);
+	ena_com_update_numa_node(rx_ring->ena_com_io_cq,
+				 ena_cpu_to_node(rx_ring->cpu));
 
 	return rc;
 }
@@ -1838,7 +1839,7 @@ static void ena_tx_csum(struct ena_com_tx_ctx *ena_tx_ctx, struct sk_buff *skb)
 			ena_tx_ctx->l4_csum_partial = 1;
 		}
 
-		switch(ip_hdr(skb)->version) {
+		switch (ip_hdr(skb)->version) {
 		case IPVERSION:
 			ena_tx_ctx->l3_proto = ENA_ETH_IO_L3_PROTO_IPV4;
 			if (ip_hdr(skb)->frag_off & htons(IP_DF))
@@ -1916,7 +1917,7 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	u16 header_len;
 	dma_addr_t dma;
 	int qid, rc, nb_hw_desc;
-	int i = 0;
+	int i = -1;
 
 	netif_dbg(adapter, tx_queued, dev, "%s skb %p\n", __func__, skb);
 	/*  Determine which tx ring we will be placed on */
@@ -1926,7 +1927,7 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
 	rc = ena_check_and_linearize_skb(tx_ring, skb);
 	if (unlikely(rc))
-		return NETDEV_TX_BUSY;
+		goto error_drop_packet;
 
 	skb_tx_timestamp(skb);
 	len = skb_headlen(skb);
@@ -1936,7 +1937,7 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	tx_info = &tx_ring->tx_buffer_info[req_id];
 	tx_info->num_of_bufs = 0;
 
-	ENA_ASSERT(!tx_info->skb, "SKB isn't NULL req_id %d\n", req_id);
+	WARN(tx_info->skb, "SKB isn't NULL req_id %d\n", req_id);
 	ena_buf = tx_info->bufs;
 	tx_info->skb = skb;
 
@@ -1958,13 +1959,9 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 	if (len > push_len) {
 		dma = dma_map_single(tx_ring->dev, skb->data + push_len,
 				     len - push_len, DMA_TO_DEVICE);
-		if (dma_mapping_error(tx_ring->dev, dma)) {
-			u64_stats_update_begin(&tx_ring->syncp);
-			tx_ring->tx_stats.dma_mapping_err++;
-			u64_stats_update_end(&tx_ring->syncp);
-			netdev_warn(adapter->netdev, "failed to map skb\n");
-			return NETDEV_TX_BUSY;
-		}
+		if (dma_mapping_error(tx_ring->dev, dma))
+			goto error_report_dma_error;
+
 		ena_buf->paddr = dma;
 		ena_buf->len = len - push_len;
 
@@ -1980,12 +1977,9 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 		len = skb_frag_size(frag);
 		dma = skb_frag_dma_map(tx_ring->dev, frag, 0, len,
 				       DMA_TO_DEVICE);
-		if (dma_mapping_error(tx_ring->dev, dma)) {
-			u64_stats_update_begin(&tx_ring->syncp);
-			tx_ring->tx_stats.dma_mapping_err++;
-			u64_stats_update_end(&tx_ring->syncp);
-			goto dma_error;
-		}
+		if (dma_mapping_error(tx_ring->dev, dma))
+			goto error_report_dma_error;
+
 		ena_buf->paddr = dma;
 		ena_buf->len = len;
 		ena_buf++;
@@ -2015,7 +2009,7 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 		tx_ring->tx_stats.prepare_ctx_err++;
 		u64_stats_update_end(&tx_ring->syncp);
 		netif_tx_stop_queue(txq);
-		goto dma_error;
+		goto error_unmap_dma;
 	}
 
 	netdev_tx_sent_queue(txq, skb->len);
@@ -2079,23 +2073,35 @@ static netdev_tx_t ena_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
 	return NETDEV_TX_OK;
 
-dma_error:
-	/* save value of frag that failed */
-	last_frag = i;
+error_report_dma_error:
+	u64_stats_update_begin(&tx_ring->syncp);
+	tx_ring->tx_stats.dma_mapping_err++;
+	u64_stats_update_end(&tx_ring->syncp);
+	netdev_warn(adapter->netdev, "failed to map skb\n");
 
-	/* start back at beginning and unmap skb */
 	tx_info->skb = NULL;
-	ena_buf = tx_info->bufs;
-	dma_unmap_single(tx_ring->dev, dma_unmap_addr(ena_buf, paddr),
-			 dma_unmap_len(ena_buf, len), DMA_TO_DEVICE);
 
-	/* unmap remaining mapped pages */
-	for (i = 0; i < last_frag; i++) {
-		ena_buf++;
-		dma_unmap_page(tx_ring->dev, dma_unmap_addr(ena_buf, paddr),
-			       dma_unmap_len(ena_buf, len), DMA_TO_DEVICE);
+error_unmap_dma:
+	if (i >= 0) {
+		/* save value of frag that failed */
+		last_frag = i;
+
+		/* start back at beginning and unmap skb */
+		tx_info->skb = NULL;
+		ena_buf = tx_info->bufs;
+		dma_unmap_single(tx_ring->dev, dma_unmap_addr(ena_buf, paddr),
+				 dma_unmap_len(ena_buf, len), DMA_TO_DEVICE);
+
+		/* unmap remaining mapped pages */
+		for (i = 0; i < last_frag; i++) {
+			ena_buf++;
+			dma_unmap_page(tx_ring->dev, dma_unmap_addr(ena_buf, paddr),
+				       dma_unmap_len(ena_buf, len), DMA_TO_DEVICE);
+		}
 	}
 
+error_drop_packet:
+
 	dev_kfree_skb(skb);
 	return NETDEV_TX_OK;
 }
@@ -3044,7 +3050,7 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	adapter->num_queues = io_queue_num;
 	adapter->last_monitored_tx_qid = 0;
 
-	adapter->small_copy_len = ENA_DEFAULT_SMALL_PACKET_LEN;
+	adapter->rx_copybreak = ENA_DEFAULT_RX_COPYBREAK;
 
 	snprintf(adapter->name, ENA_NAME_MAX_LEN, "ena_%d", adapters_found);
 
@@ -3062,17 +3068,6 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 
 	netdev->priv_flags |= IFF_UNICAST_FLT;
 
-	INIT_WORK(&adapter->suspend_io_task, ena_device_io_suspend);
-	INIT_WORK(&adapter->resume_io_task, ena_device_io_resume);
-	INIT_WORK(&adapter->reset_task, ena_fw_reset_device);
-
-	init_timer(&adapter->timer_service);
-	adapter->timer_service.expires = round_jiffies(jiffies + HZ);
-	adapter->timer_service.function = ena_timer_service;
-	adapter->timer_service.data = (unsigned long)adapter;
-
-	add_timer(&adapter->timer_service);
-
 	u64_stats_init(&adapter->syncp);
 
 	rc = ena_enable_msix_and_set_admin_interrupts(adapter, io_queue_num);
@@ -3106,6 +3101,19 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 		goto err_rss;
 	}
 
+	INIT_WORK(&adapter->suspend_io_task, ena_device_io_suspend);
+	INIT_WORK(&adapter->resume_io_task, ena_device_io_resume);
+	INIT_WORK(&adapter->reset_task, ena_fw_reset_device);
+
+	adapter->last_keep_alive_jiffies = jiffies;
+
+	init_timer(&adapter->timer_service);
+	adapter->timer_service.expires = round_jiffies(jiffies + HZ);
+	adapter->timer_service.function = ena_timer_service;
+	adapter->timer_service.data = (unsigned long)adapter;
+
+	add_timer(&adapter->timer_service);
+
 	dev_info(&pdev->dev, "%s found at mem %lx, mac addr %pM Queues %d\n",
 		 DEVICE_NAME, (long)pci_resource_start(pdev, 0),
 		 netdev->dev_addr, io_queue_num);
@@ -3315,10 +3323,10 @@ static void ena_notification(void *adapter_data,
 {
 	struct ena_adapter *adapter = (struct ena_adapter *)adapter_data;
 
-	ENA_ASSERT(aenq_e->aenq_common_desc.group == ENA_ADMIN_NOTIFICATION,
-		   "Invalid group(%x) expected %x\n",
-		   aenq_e->aenq_common_desc.group,
-		   ENA_ADMIN_NOTIFICATION);
+	WARN(aenq_e->aenq_common_desc.group != ENA_ADMIN_NOTIFICATION,
+	     "Invalid group(%x) expected %x\n",
+	     aenq_e->aenq_common_desc.group,
+	     ENA_ADMIN_NOTIFICATION);
 
 	switch (aenq_e->aenq_common_desc.syndrom) {
 	case ENA_ADMIN_SUSPEND:
diff --git a/drivers/amazon/net/ena/ena_netdev.h b/drivers/amazon/net/ena/ena_netdev.h
index fa9bab4..1507715 100644
--- a/drivers/amazon/net/ena/ena_netdev.h
+++ b/drivers/amazon/net/ena/ena_netdev.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -43,9 +43,9 @@
 #include "ena_com.h"
 #include "ena_eth_com.h"
 
-#define DRV_MODULE_VER_MAJOR	0
-#define DRV_MODULE_VER_MINOR	6
-#define DRV_MODULE_VER_SUBMINOR 6
+#define DRV_MODULE_VER_MAJOR	1
+#define DRV_MODULE_VER_MINOR	0
+#define DRV_MODULE_VER_SUBMINOR 2
 
 #define DRV_MODULE_NAME		"ena"
 #ifndef DRV_MODULE_VERSION
@@ -54,7 +54,7 @@
 	__stringify(DRV_MODULE_VER_MINOR) "."	\
 	__stringify(DRV_MODULE_VER_SUBMINOR)
 #endif
-#define DRV_MODULE_RELDATE      "31-MAY-2016"
+#define DRV_MODULE_RELDATE      "13-JULY-2016"
 
 #define DEVICE_NAME	"Elastic Network Adapter (ENA)"
 
@@ -68,7 +68,7 @@
 #define ENA_DEFAULT_RING_SIZE	(1024)
 
 #define ENA_TX_WAKEUP_THRESH		(MAX_SKB_FRAGS + 2)
-#define ENA_DEFAULT_SMALL_PACKET_LEN		(128 - NET_IP_ALIGN)
+#define ENA_DEFAULT_RX_COPYBREAK	(128 - NET_IP_ALIGN)
 
 /* limit the buffer size to 600 bytes to handle MTU changes from very
  * small to very large, in which case the number of buffers per packet
@@ -136,9 +136,6 @@ struct ena_napi {
 	struct napi_struct napi ____cacheline_aligned;
 	struct ena_ring *tx_ring;
 	struct ena_ring *rx_ring;
-#ifndef HAVE_NETDEV_NAPI_LIST
-	struct net_device poll_dev;
-#endif /* HAVE_NETDEV_NAPI_LIST */
 	u32 qid;
 };
 
@@ -187,7 +184,7 @@ struct ena_stats_rx {
 	u64 skb_alloc_fail;
 	u64 dma_mapping_err;
 	u64 bad_desc_num;
-	u64 small_copy_len_pkt;
+	u64 rx_copybreak_pkt;
 };
 
 struct ena_ring {
@@ -210,7 +207,7 @@ struct ena_ring {
 
 	u16 next_to_use;
 	u16 next_to_clean;
-	u16 rx_small_copy_len;
+	u16 rx_copybreak;
 	u16 qid;
 	u16 mtu;
 	u16 sgl_size;
@@ -265,7 +262,7 @@ struct ena_adapter {
 	/* rx packets that shorter that this len will be copied to the skb
 	 * header
 	 */
-	u32 small_copy_len;
+	u32 rx_copybreak;
 	u32 max_mtu;
 
 	int num_queues;
diff --git a/drivers/amazon/net/ena/ena_pci_id_tbl.h b/drivers/amazon/net/ena/ena_pci_id_tbl.h
index 4f0aae1..f80d2a4 100644
--- a/drivers/amazon/net/ena/ena_pci_id_tbl.h
+++ b/drivers/amazon/net/ena/ena_pci_id_tbl.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -54,7 +54,7 @@
 #endif
 
 #define ENA_PCI_ID_TABLE_ENTRY(devid) \
-	{ PCI_DEVICE(PCI_VENDOR_ID_AMAZON, devid)},
+	{PCI_DEVICE(PCI_VENDOR_ID_AMAZON, devid)},
 
 static const struct pci_device_id ena_pci_tbl[] = {
 	ENA_PCI_ID_TABLE_ENTRY(PCI_DEV_ID_ENA_PF)
diff --git a/drivers/amazon/net/ena/ena_regs_defs.h b/drivers/amazon/net/ena/ena_regs_defs.h
index c8c9f89..26097a2 100644
--- a/drivers/amazon/net/ena/ena_regs_defs.h
+++ b/drivers/amazon/net/ena/ena_regs_defs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
diff --git a/drivers/amazon/net/ena/ena_sysfs.c b/drivers/amazon/net/ena/ena_sysfs.c
index d567164..d3e64d0 100644
--- a/drivers/amazon/net/ena/ena_sysfs.c
+++ b/drivers/amazon/net/ena/ena_sysfs.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -40,57 +40,6 @@
 #include "ena_sysfs.h"
 
 #define to_ext_attr(x) container_of(x, struct dev_ext_attribute, attr)
-static int ena_validate_small_copy_len(struct ena_adapter *adapter,
-				       unsigned long len)
-{
-	if (len > adapter->netdev->mtu)
-		return -EINVAL;
-
-	return 0;
-}
-
-static ssize_t ena_store_small_copy_len(struct device *dev,
-					struct device_attribute *attr,
-					const char *buf, size_t len)
-{
-	struct ena_adapter *adapter = dev_get_drvdata(dev);
-	unsigned long small_copy_len;
-	struct ena_ring *rx_ring;
-	int err, i;
-
-	err = kstrtoul(buf, 10, &small_copy_len);
-	if (err < 0)
-		return err;
-
-	err = ena_validate_small_copy_len(adapter, small_copy_len);
-	if (err)
-		return err;
-
-	rtnl_lock();
-	adapter->small_copy_len = small_copy_len;
-
-	for (i = 0; i < adapter->num_queues; i++) {
-		rx_ring = &adapter->rx_ring[i];
-		rx_ring->rx_small_copy_len = small_copy_len;
-	}
-	rtnl_unlock();
-
-	return len;
-}
-
-static ssize_t ena_show_small_copy_len(struct device *dev,
-				       struct device_attribute *attr, char *buf)
-{
-	struct ena_adapter *adapter = dev_get_drvdata(dev);
-
-	return sprintf(buf, "%d\n", adapter->small_copy_len);
-}
-
-static struct device_attribute dev_attr_small_copy_len = {
-	.attr = {.name = "small_copy_len", .mode = (S_IRUGO | S_IWUSR)},
-	.show = ena_show_small_copy_len,
-	.store = ena_store_small_copy_len,
-};
 
 /* adaptive interrupt moderation */
 static ssize_t ena_show_intr_moderation(struct device *dev,
@@ -190,17 +139,12 @@ static ssize_t ena_show_enable_adaptive_intr_moderation(struct device *dev,
 		       ena_com_get_adaptive_moderation_enabled(adapter->ena_dev));
 }
 
-static struct device_attribute dev_attr_enable_adaptive_intr_moderation = {
-	.attr = {.name = "enable_adaptive_intr_moderation", .mode = (S_IRUGO | S_IWUSR)},
-	.show = ena_show_enable_adaptive_intr_moderation,
-	.store = ena_store_enable_adaptive_intr_moderation,
-};
+static DEVICE_ATTR(enable_adaptive_intr_moderation, S_IRUGO | S_IWUSR,
+		ena_show_enable_adaptive_intr_moderation,
+		ena_store_enable_adaptive_intr_moderation);
 
-static struct device_attribute dev_attr_intr_moderation_restore_default = {
-	.attr = {.name = "intr_moderation_restore_default", .mode = (S_IWUSR | S_IWGRP)},
-	.show = NULL,
-	.store = ena_store_intr_moderation_restore_default,
-};
+static DEVICE_ATTR(intr_moderation_restore_default, S_IWUSR | S_IWGRP,
+		NULL, ena_store_intr_moderation_restore_default);
 
 #define INTR_MODERATION_PREPARE_ATTR(_name, _type) {			\
 	__ATTR(intr_moderation_##_name, (S_IRUGO | S_IWUSR | S_IWGRP),	\
@@ -223,9 +167,6 @@ int ena_sysfs_init(struct device *dev)
 	int i, rc;
 	struct ena_adapter *adapter = dev_get_drvdata(dev);
 
-	if (device_create_file(dev, &dev_attr_small_copy_len))
-		dev_err(dev, "failed to create small_copy_len sysfs entry");
-
 	if (ena_com_interrupt_moderation_supported(adapter->ena_dev)) {
 		if (device_create_file(dev,
 				       &dev_attr_intr_moderation_restore_default))
@@ -259,7 +200,6 @@ void ena_sysfs_terminate(struct device *dev)
 	struct ena_adapter *adapter = dev_get_drvdata(dev);
 	int i;
 
-	device_remove_file(dev, &dev_attr_small_copy_len);
 	if (ena_com_interrupt_moderation_supported(adapter->ena_dev)) {
 		for (i = 0; i < ARRAY_SIZE(dev_attr_intr_moderation); i++)
 			sysfs_remove_file(&dev->kobj,
diff --git a/drivers/amazon/net/ena/ena_sysfs.h b/drivers/amazon/net/ena/ena_sysfs.h
index 9e60770..dc0d4c9 100644
--- a/drivers/amazon/net/ena/ena_sysfs.h
+++ b/drivers/amazon/net/ena/ena_sysfs.h
@@ -1,5 +1,5 @@
 /*
- * Copyright 2015 - 2016 Amazon.com, Inc. or its affiliates.
+ * Copyright 2015 Amazon.com, Inc. or its affiliates.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
-- 
2.7.4

