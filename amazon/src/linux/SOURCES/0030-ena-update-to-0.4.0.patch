From d7472d406ec670cd4c3282263e3c4d87afdab925 Mon Sep 17 00:00:00 2001
From: Munehisa Kamata <kamatam@amazon.com>
Date: Fri, 19 Feb 2016 23:32:49 +0000
Subject: ena: update to 0.4.0

Signed-off-by: Munehisa Kamata <kamatam@amazon.com>
Reviewed-by: Netanel Belgazal <netanel@annapurnalabs.com>
Reviewed-by: Rashika Kheria <rashika@amazon.de>
Reviewed-by: Matt Nierzwicki <nierzwic@amazon.com>

CR: https://cr.amazon.com/r/5132188/
---
 Documentation/networking/ena.txt     |  27 ++-
 drivers/amazon/ena/ena_admin_defs.h  | 119 ++++++----
 drivers/amazon/ena/ena_com.c         | 430 +++++++++++++++++++++++++++++------
 drivers/amazon/ena/ena_com.h         | 297 ++++++++++++++++++++++--
 drivers/amazon/ena/ena_eth_com.c     |   4 +
 drivers/amazon/ena/ena_eth_com.h     |  40 +++-
 drivers/amazon/ena/ena_eth_io_defs.h |  18 ++
 drivers/amazon/ena/ena_ethtool.c     | 165 ++++++++------
 drivers/amazon/ena/ena_netdev.c      | 393 +++++++++++++++++++++++---------
 drivers/amazon/ena/ena_netdev.h      |  27 ++-
 drivers/amazon/ena/ena_sysfs.c       | 165 +++++++++++++-
 11 files changed, 1357 insertions(+), 328 deletions(-)

diff --git a/Documentation/networking/ena.txt b/Documentation/networking/ena.txt
index 29754c9..ea7e13b 100644
--- a/Documentation/networking/ena.txt
+++ b/Documentation/networking/ena.txt
@@ -173,12 +173,27 @@ modes. That is, once MSI-X is delivered to the host, its Cause bit is
 automatically cleared and the interrupt is masked. The interrupt is
 unmasked by the driver after NAPI processing is complete.
 
-The driver can operate in conventional interrupt coalescing mode
-(parameters are configured through ethtool(8)) or adaptive interrupt
-coalescing mode (parameters are configured through sysfs).
-
-Interrupt mode is set through SetFeature AQ command
-(ENA_ADMIN_INTERRUPT_MODERATION property)
+Interrupt Moderation:
+=====================
+ENA driver and device can operate in conventional or adaptive interrupt 
+moderation mode. 
+In conventional mode the driver instructs device to postpone interrupt posting
+according to static interrupt delay value. The interrupt delay value can be 
+configured through ethtool(8). The following ethtool parameters are supported
+by the driver: tx-usecs, rx-usecs
+In adaptive interrupt moderation mode the interrupt delay value is updated by 
+the driver dynamically and adjusted every NAPI cycle according to the traffic
+nature.
+By default ENA driver applies adaptive coalescing on Rx traffic and conventional
+coalescing on Tx traffic.
+Adaptive coalescing can be switched on/off through ethtool(8) adaptive_rx on|off
+parameter.
+The driver chooses interrupt delay value according to the number of bytes and
+packets received between interrupt unmasking and interrupt posting. The driver
+uses interrupt delay table that subdivides the range of received bytes/packets
+into 5 levels and assignes interrupt delay value to each level.
+The user can enable/disable adaptive moderation, modify the interrupt delay table
+and restore its default values through sysfs.      
 
 Memory Allocations:
 ===================
diff --git a/drivers/amazon/ena/ena_admin_defs.h b/drivers/amazon/ena/ena_admin_defs.h
index 36c4ec0..d834156 100644
--- a/drivers/amazon/ena/ena_admin_defs.h
+++ b/drivers/amazon/ena/ena_admin_defs.h
@@ -151,7 +151,7 @@ enum ena_admin_aq_feature_id {
 	/* overlay tunnels configuration */
 	ENA_ADMIN_TUNNEL_CONFIG = 19,
 
-	/* interrupt moderation: count,interval,adaptive */
+	/* interrupt moderation parameters */
 	ENA_ADMIN_INTERRUPT_MODERATION = 20,
 
 	/* 1588v2 and Timing configuration */
@@ -530,14 +530,6 @@ struct ena_admin_acq_create_cq_resp_desc {
 	 * PCIe MMIO REG BAR
 	 */
 	u32 cq_interrupt_unmask_register;
-
-	/* word 6 : value to be written into interrupt unmask register */
-	u32 cq_interrupt_unmask_value;
-
-	/* word 7 : interrupt moderation register address as an offset into
-	 * PCIe MMIO REG BAR. 1 usec granularity
-	 */
-	u32 cq_interrupt_moderation_register;
 };
 
 /* ENA AQ Destroy Completion Queue command. Placed in control buffer
@@ -736,17 +728,27 @@ struct ena_admin_set_feature_mtu_desc {
 
 /* ENA host attributes Set Feature descriptor. */
 struct ena_admin_set_feature_host_attr_desc {
-	/* word 0 : driver version */
-	u32 driver_version;
+	/* words 0:1 : host OS info base address in OS memory. host info is
+	 * 4KB of physically contiguous
+	 */
+	struct ena_common_mem_addr os_info_ba;
+
+	/* words 2:3 : host debug area base address in OS memory. debug
+	 * area must be physically contiguous
+	 */
+	struct ena_common_mem_addr debug_ba;
+
+	/* word 4 : debug area size */
+	u32 debug_area_size;
 };
 
-/* ENA Interrupt Moderation metrics. */
-struct ena_admin_intr_moder_metrics_desc {
+/* ENA Interrupt Moderation Get Feature descriptor. */
+struct ena_admin_feature_intr_moder_desc {
 	/* word 0 : */
-	u16 count;
+	/* interrupt delay granularity in usec */
+	u16 intr_delay_resolution;
 
-	/* interval in us */
-	u16 interval;
+	u16 reserved;
 };
 
 /* ENA Link Get Feature descriptor. */
@@ -767,27 +769,6 @@ struct ena_admin_get_feature_link_desc {
 	u32 flags;
 };
 
-/* ENA Interrupt Moderation Set Feature descriptor. */
-struct ena_admin_set_feature_intr_moder_desc {
-	/* word 0 : */
-	/* associated queue id. */
-	u16 cq_idx;
-
-	/* 2:0 : sq_direction - 0x1 - Tx; 0x2 - Rx */
-	u8 queue_identity;
-
-	u8 reserved1;
-
-	/* word 1 : */
-	/* 0 : enable
-	 * 31:1 : reserved1
-	 */
-	u32 flags;
-
-	/* words 2 :  */
-	struct ena_admin_intr_moder_metrics_desc intr_moder_metrics;
-};
-
 /* ENA AENQ Feature descriptor. */
 struct ena_admin_feature_aenq_desc {
 	/* word 0 : bitmask for AENQ groups the device can report */
@@ -971,6 +952,53 @@ struct ena_admin_feature_rss_flow_hash_input {
 	u16 enabled_input_sort;
 };
 
+/* Operating system type */
+enum ena_admin_os_type {
+	/* Linux OS */
+	ENA_ADMIN_OS_LINUX = 1,
+
+	/* Windows OS */
+	ENA_ADMIN_OS_WIN = 2,
+
+	/* DPDK OS */
+	ENA_ADMIN_OS_DPDK = 3,
+
+	/* FreeBSD OS */
+	ENA_ADMIN_OS_FREE_BSD = 4,
+
+	/* PXE OS */
+	ENA_ADMIN_OS_PXE = 5,
+};
+
+/* host info */
+struct ena_admin_host_info {
+	/* word 0 : OS type defined in enum ena_os_type */
+	u32 os_type;
+
+	/* os distribution string format */
+	u8 os_dist_str[128];
+
+	/* word 33 : OS distribution numeric format */
+	u32 os_dist;
+
+	/* kernel version string format */
+	u8 kernel_ver_str[32];
+
+	/* word 42 : Kernel version numeric format */
+	u32 kernel_ver;
+
+	/* word 43 : */
+	/* driver version
+	 * 7:0 : major - major
+	 * 15:8 : minor - minor
+	 * 23:16 : sub_minor - sub minor
+	 */
+	u32 driver_version;
+
+	/* features bitmap */
+	u32 supported_network_features[4];
+};
+
 /* ENA RSS indirection table entry */
 struct ena_admin_rss_ind_table_entry {
 	/* word 0 : */
@@ -1057,6 +1085,9 @@ struct ena_admin_get_feat_resp {
 
 		/* words 2:3 : rss indirection table */
 		struct ena_admin_feature_rss_ind_table ind_table;
+
+		/* words 2 : interrupt moderation configuration */
+		struct ena_admin_feature_intr_moder_desc intr_moderation;
 	} u;
 };
 
@@ -1084,9 +1115,6 @@ struct ena_admin_set_feat_cmd {
 		/* words 5:7 : host attributes */
 		struct ena_admin_set_feature_host_attr_desc host_attr;
 
-		/* words 5:7 : interrupt moderation */
-		struct ena_admin_set_feature_intr_moder_desc intr_moder;
-
 		/* words 5:6 : AENQ configuration */
 		struct ena_admin_feature_aenq_desc aenq;
 
@@ -1225,10 +1253,6 @@ struct ena_admin_ena_mmio_req_read_less_resp {
 #define ENA_ADMIN_GET_FEATURE_LINK_DESC_DUPLEX_SHIFT 1
 #define ENA_ADMIN_GET_FEATURE_LINK_DESC_DUPLEX_MASK BIT(1)
 
-/* set_feature_intr_moder_desc */
-#define ENA_ADMIN_SET_FEATURE_INTR_MODER_DESC_SQ_DIRECTION_MASK GENMASK(2, 0)
-#define ENA_ADMIN_SET_FEATURE_INTR_MODER_DESC_ENABLE_MASK BIT(0)
-
 /* feature_offload_desc */
 #define ENA_ADMIN_FEATURE_OFFLOAD_DESC_TX_L3_CSUM_IPV4_MASK BIT(0)
 #define ENA_ADMIN_FEATURE_OFFLOAD_DESC_TX_L4_IPV4_CSUM_PART_SHIFT 1
@@ -1270,6 +1294,13 @@ struct ena_admin_ena_mmio_req_read_less_resp {
 #define ENA_ADMIN_FEATURE_RSS_FLOW_HASH_INPUT_ENABLE_L4_SORT_SHIFT 2
 #define ENA_ADMIN_FEATURE_RSS_FLOW_HASH_INPUT_ENABLE_L4_SORT_MASK BIT(2)
 
+/* host_info */
+#define ENA_ADMIN_HOST_INFO_MAJOR_MASK GENMASK(7, 0)
+#define ENA_ADMIN_HOST_INFO_MINOR_SHIFT 8
+#define ENA_ADMIN_HOST_INFO_MINOR_MASK GENMASK(15, 8)
+#define ENA_ADMIN_HOST_INFO_SUB_MINOR_SHIFT 16
+#define ENA_ADMIN_HOST_INFO_SUB_MINOR_MASK GENMASK(23, 16)
+
 /* aenq_common_desc */
 #define ENA_ADMIN_AENQ_COMMON_DESC_PHASE_MASK BIT(0)
 
diff --git a/drivers/amazon/ena/ena_com.c b/drivers/amazon/ena/ena_com.c
index 8213aeb..14ad890 100644
--- a/drivers/amazon/ena/ena_com.c
+++ b/drivers/amazon/ena/ena_com.c
@@ -399,8 +399,7 @@ static void ena_com_handle_single_admin_completion(struct ena_com_admin_queue *a
 		complete(&comp_ctx->wait_event);
 }
 
-static void ena_com_handle_admin_completion(
-		struct ena_com_admin_queue *admin_queue)
+static void ena_com_handle_admin_completion(struct ena_com_admin_queue *admin_queue)
 {
 	struct ena_admin_acq_entry *cqe = NULL;
 	u16 comp_num = 0;
@@ -410,12 +409,14 @@ static void ena_com_handle_admin_completion(
 	head_masked = admin_queue->cq.head & (admin_queue->q_depth - 1);
 	phase = admin_queue->cq.phase;
 
-	rmb();
 	cqe = &admin_queue->cq.entries[head_masked];
 
 	/* Go over all the completions */
 	while ((cqe->acq_common_descriptor.flags &
 			ENA_ADMIN_ACQ_COMMON_DESC_PHASE_MASK) == phase) {
+		/* Do not read the rest of the completion entry before the
+		 * phase bit was validated */
+		rmb();
 		ena_com_handle_single_admin_completion(admin_queue, cqe);
 
 		head_masked++;
@@ -425,7 +426,6 @@ static void ena_com_handle_admin_completion(
 			phase = !phase;
 		}
 
-		rmb();
 		cqe = &admin_queue->cq.entries[head_masked];
 	}
 
@@ -567,6 +567,12 @@ static u32 ena_com_reg_bar_read32(struct ena_com_dev *ena_dev, u16 offset)
 
 	might_sleep();
 
+	/* If readless is disabled, perform regular read */
+	if (!mmio_read->readless_supported) {
+		u8 *addr = (u8 *)((uintptr_t)ena_dev->reg_bar + offset);
+		return readl(addr);
+	}
+
 	spin_lock_irqsave(&mmio_read->lock, flags);
 	mmio_read->seq_num++;
 
@@ -657,8 +663,8 @@ static int ena_com_destroy_io_sq(struct ena_com_dev *ena_dev,
 					    (struct ena_admin_acq_entry *)&destroy_resp,
 					    sizeof(destroy_resp));
 
-	if (unlikely(ret))
-		ena_trc_err("failed to create io cq error: %d\n", ret);
+	if (unlikely(ret && (ret != -ENODEV)))
+		ena_trc_err("failed to destroy io sq error: %d\n", ret);
 
 	return ret;
 }
@@ -748,7 +754,7 @@ static int ena_com_get_feature_ex(struct ena_com_dev *ena_dev,
 	}
 
 	if (!ena_com_check_supported_feature_id(ena_dev, feature_id)) {
-		ena_trc_err("Feature %d isn't supported\n", feature_id);
+		ena_trc_info("Feature %d isn't supported\n", feature_id);
 		return -EPERM;
 	}
 
@@ -1048,6 +1054,41 @@ static int ena_com_ind_tbl_convert_from_device(struct ena_com_dev *ena_dev)
 	return 0;
 }
 
+static int ena_com_init_intrrupt_moderation_table(struct ena_com_dev *ena_dev)
+{
+	size_t size;
+
+	size = sizeof(struct ena_intr_moder_entry) * ENA_INTR_MAX_NUM_OF_LEVELS;
+
+	ena_dev->intr_moder_tbl = devm_kzalloc(ena_dev->dmadev, size, GFP_KERNEL);
+	if (!ena_dev->intr_moder_tbl)
+		return -ENOMEM;
+
+	ena_com_config_default_interrupt_moderation_table(ena_dev);
+
+	return 0;
+}
+
+static void ena_com_update_intr_delay_resolution(struct ena_com_dev *ena_dev,
+						 unsigned int intr_delay_resolution)
+{
+	struct ena_intr_moder_entry *intr_moder_tbl = ena_dev->intr_moder_tbl;
+	unsigned int i;
+
+	if (!intr_delay_resolution) {
+		ena_trc_err("Illegal intr_delay_resolution provided. Going to use default 1 usec resolution\n");
+		intr_delay_resolution = 1;
+	}
+	ena_dev->intr_delay_resolution = intr_delay_resolution;
+
+	/* update Rx */
+	for (i = 0; i < ENA_INTR_MAX_NUM_OF_LEVELS; i++)
+		intr_moder_tbl[i].intr_moder_interval /= intr_delay_resolution;
+
+	/* update Tx */
+	ena_dev->intr_moder_tx_interval /= intr_delay_resolution;
+}
+
 /*****************************************************************************/
 /*******************************      API       ******************************/
 /*****************************************************************************/
@@ -1127,7 +1168,10 @@ int ena_com_create_io_cq(struct ena_com_dev *ena_dev,
 
 	io_cq->unmask_reg = (u32 __iomem *)((uintptr_t)ena_dev->reg_bar +
 		cmd_completion.cq_interrupt_unmask_register);
-	io_cq->unmask_val = cmd_completion.cq_interrupt_unmask_value;
+
+	if (cmd_completion.cq_head_db_offset)
+		io_cq->cq_head_db_reg = (u32 *)((u8 *)ena_dev->reg_bar +
+			cmd_completion.cq_head_db_offset);
 
 	ena_trc_dbg("created cq[%u], depth[%u]\n", io_cq->idx, io_cq->q_depth);
 
@@ -1200,7 +1244,8 @@ int ena_com_destroy_io_cq(struct ena_com_dev *ena_dev,
 					    (struct ena_admin_acq_entry *)&destroy_resp,
 					    sizeof(destroy_resp));
 
-	if (unlikely(ret))
+
+	if (unlikely(ret && (ret != -ENODEV)))
 		ena_trc_err("Failed to destroy IO CQ. error: %d\n", ret);
 
 	return ret;
@@ -1252,7 +1297,7 @@ int ena_com_set_aenq_config(struct ena_com_dev *ena_dev, u32 groups_flag)
 	}
 
 	if ((get_resp.u.aenq.supported_groups & groups_flag) != groups_flag) {
-		ena_trc_info("Trying to set unsupported aenq events. supported flag: %x asked flag: %x\n",
+		ena_trc_warn("Trying to set unsupported aenq events. supported flag: %x asked flag: %x\n",
 			     get_resp.u.aenq.supported_groups,
 			     groups_flag);
 		return -EPERM;
@@ -1410,10 +1455,18 @@ int ena_com_mmio_reg_read_request_init(struct ena_com_dev *ena_dev)
 
 	mmio_read->read_resp->req_id = 0x0;
 	mmio_read->seq_num = 0x0;
+	mmio_read->readless_supported = true;
 
 	return 0;
 }
 
+void ena_com_set_mmio_read_mode(struct ena_com_dev *ena_dev, bool readless_supported)
+{
+	struct ena_com_mmio_read *mmio_read = &ena_dev->mmio_read;
+
+	mmio_read->readless_supported = readless_supported;
+}
+
 void ena_com_mmio_reg_read_request_destroy(struct ena_com_dev *ena_dev)
 {
 	struct ena_com_mmio_read *mmio_read = &ena_dev->mmio_read;
@@ -1906,64 +1959,6 @@ int ena_com_set_dev_mtu(struct ena_com_dev *ena_dev, int mtu)
 	return 0;
 }
 
-int ena_com_set_interrupt_moderation(struct ena_com_dev *ena_dev, int qid,
-				     bool enable, u16 count, u16 interval)
-{
-	struct ena_com_io_cq *io_cq = &ena_dev->io_cq_queues[qid];
-
-	struct ena_com_admin_queue *admin_queue;
-	struct ena_admin_set_feat_cmd cmd;
-	struct ena_admin_set_feat_resp resp;
-	u8 direction;
-	int ret = 0;
-
-	if (unlikely(!ena_dev)) {
-		ena_trc_err("%s : ena_dev is NULL\n", __func__);
-		return -ENODEV;
-	}
-
-	if (!ena_com_check_supported_feature_id(ena_dev,
-						ENA_ADMIN_INTERRUPT_MODERATION)) {
-		ena_trc_err("Feature %d isn't supported\n",
-			    ENA_ADMIN_INTERRUPT_MODERATION);
-		return -EPERM;
-	}
-
-	memset(&cmd, 0x0, sizeof(cmd));
-	admin_queue = &ena_dev->admin_queue;
-
-	cmd.aq_common_descriptor.opcode = ENA_ADMIN_SET_FEATURE;
-	cmd.aq_common_descriptor.flags = 0;
-	cmd.feat_common.feature_id = ENA_ADMIN_INTERRUPT_MODERATION;
-	cmd.u.intr_moder.cq_idx = io_cq->idx;
-	if (io_cq->direction == ENA_COM_IO_QUEUE_DIRECTION_TX)
-		direction = ENA_ADMIN_SQ_DIRECTION_TX;
-	else
-		direction = ENA_ADMIN_SQ_DIRECTION_RX;
-
-	cmd.u.intr_moder.queue_identity |= direction &
-		ENA_ADMIN_SET_FEATURE_INTR_MODER_DESC_SQ_DIRECTION_MASK;
-
-	if (enable) {
-		cmd.u.intr_moder.flags |=
-			ENA_ADMIN_SET_FEATURE_INTR_MODER_DESC_ENABLE_MASK;
-		cmd.u.intr_moder.intr_moder_metrics.count = count;
-		cmd.u.intr_moder.intr_moder_metrics.interval = interval;
-	}
-
-	ret = ena_com_execute_admin_command(admin_queue,
-					    (struct ena_admin_aq_entry *)&cmd,
-					    sizeof(cmd),
-					    (struct ena_admin_acq_entry *)&resp,
-					    sizeof(resp));
-
-	if (unlikely(ret)) {
-		ena_trc_err("Failed to set interrupt moderation %d\n", ret);
-		return -EINVAL;
-	}
-	return 0;
-}
-
 int ena_com_get_offload_settings(struct ena_com_dev *ena_dev,
 				 struct ena_admin_feature_offload_desc *offload)
 {
@@ -1993,8 +1988,8 @@ int ena_com_set_hash_function(struct ena_com_dev *ena_dev)
 
 	if (!ena_com_check_supported_feature_id(ena_dev,
 						ENA_ADMIN_RSS_HASH_FUNCTION)) {
-		ena_trc_err("Feature %d isn't supported\n",
-			    ENA_ADMIN_RSS_HASH_FUNCTION);
+		ena_trc_info("Feature %d isn't supported\n",
+			     ENA_ADMIN_RSS_HASH_FUNCTION);
 		return -EPERM;
 	}
 
@@ -2157,8 +2152,8 @@ int ena_com_set_hash_ctrl(struct ena_com_dev *ena_dev)
 
 	if (!ena_com_check_supported_feature_id(ena_dev,
 						ENA_ADMIN_RSS_HASH_INPUT)) {
-		ena_trc_err("Feature %d isn't supported\n",
-			    ENA_ADMIN_RSS_HASH_INPUT);
+		ena_trc_info("Feature %d isn't supported\n",
+			     ENA_ADMIN_RSS_HASH_INPUT);
 		return -EPERM;
 	}
 
@@ -2316,8 +2311,8 @@ int ena_com_indirect_table_set(struct ena_com_dev *ena_dev)
 
 	if (!ena_com_check_supported_feature_id(ena_dev,
 						ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG)) {
-		ena_trc_err("Feature %d isn't supported\n",
-			    ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG);
+		ena_trc_info("Feature %d isn't supported\n",
+			     ENA_ADMIN_RSS_REDIRECTION_TABLE_CONFIG);
 		return -EPERM;
 	}
 
@@ -2430,3 +2425,290 @@ int ena_com_rss_destroy(struct ena_com_dev *ena_dev)
 
 	return 0;
 }
+
+int ena_com_allocate_host_attribute(struct ena_com_dev *ena_dev,
+				    u32 debug_area_size)
+{
+	struct ena_host_attribute *host_attr = &ena_dev->host_attr;
+	int rc;
+
+	host_attr->host_info =
+		dma_alloc_coherent(ena_dev->dmadev,
+				   SZ_4K,
+				   &host_attr->host_info_dma_addr,
+				   GFP_KERNEL | __GFP_ZERO);
+	if (unlikely(!host_attr->host_info))
+			return -ENOMEM;
+
+	if (debug_area_size) {
+		host_attr->debug_area_virt_addr =
+			dma_alloc_coherent(ena_dev->dmadev,
+					   debug_area_size,
+					   &host_attr->debug_area_dma_addr,
+					   GFP_KERNEL | __GFP_ZERO);
+		if (unlikely(!host_attr->debug_area_virt_addr)) {
+			rc = -ENOMEM;
+			goto err;
+		}
+	}
+
+	host_attr->debug_area_size = debug_area_size;
+
+	return 0;
+err:
+
+	dma_free_coherent(ena_dev->dmadev,
+			  SZ_4K,
+			  host_attr->host_info,
+			  host_attr->host_info_dma_addr);
+	return rc;
+}
+
+void ena_com_delete_host_attribute(struct ena_com_dev *ena_dev)
+{
+	struct ena_host_attribute *host_attr = &ena_dev->host_attr;
+
+	if (host_attr->host_info) {
+		dma_free_coherent(ena_dev->dmadev,
+				  SZ_4K,
+				  host_attr->host_info,
+				  host_attr->host_info_dma_addr);
+		host_attr->host_info = NULL;
+	}
+
+	if (host_attr->debug_area_virt_addr) {
+		dma_free_coherent(ena_dev->dmadev,
+				  host_attr->debug_area_size,
+				  host_attr->debug_area_virt_addr,
+				  host_attr->debug_area_dma_addr);
+		host_attr->debug_area_virt_addr = NULL;
+	}
+}
+
+int ena_com_set_host_attributes(struct ena_com_dev *ena_dev)
+{
+	struct ena_host_attribute *host_attr = &ena_dev->host_attr;
+	struct ena_com_admin_queue *admin_queue;
+	struct ena_admin_set_feat_cmd cmd;
+	struct ena_admin_set_feat_resp resp;
+
+	int ret = 0;
+
+	if (unlikely(!ena_dev)) {
+		ena_trc_err("%s : ena_dev is NULL\n", __func__);
+		return -ENODEV;
+	}
+
+	if (!ena_com_check_supported_feature_id(ena_dev,
+						ENA_ADMIN_HOST_ATTR_CONFIG)) {
+		ena_trc_warn("Set host attribute isn't supported\n");
+		return -EPERM;
+	}
+
+	memset(&cmd, 0x0, sizeof(cmd));
+	admin_queue = &ena_dev->admin_queue;
+
+	cmd.aq_common_descriptor.opcode = ENA_ADMIN_SET_FEATURE;
+	cmd.feat_common.feature_id = ENA_ADMIN_HOST_ATTR_CONFIG;
+
+	ret = ena_com_mem_addr_set(ena_dev,
+				   &cmd.u.host_attr.debug_ba,
+				   host_attr->debug_area_dma_addr);
+	if (unlikely(ret)) {
+		ena_trc_err("memory address set failed\n");
+		return ret;
+	}
+
+	ret = ena_com_mem_addr_set(ena_dev,
+				   &cmd.u.host_attr.os_info_ba,
+				   host_attr->host_info_dma_addr);
+	if (unlikely(ret)) {
+		ena_trc_err("memory address set failed\n");
+		return ret;
+	}
+
+	cmd.u.host_attr.debug_area_size = host_attr->debug_area_size;
+
+	ret = ena_com_execute_admin_command(admin_queue,
+					    (struct ena_admin_aq_entry *)&cmd,
+					    sizeof(cmd),
+					    (struct ena_admin_acq_entry *)&resp,
+					    sizeof(resp));
+
+	if (unlikely(ret))
+		ena_trc_err("Failed to set host attributes: %d\n", ret);
+
+	return ret;
+}
+
+/* Interrupt moderation */
+bool ena_com_interrupt_moderation_supported(struct ena_com_dev *ena_dev)
+{
+	return ena_com_check_supported_feature_id(ena_dev,
+						  ENA_ADMIN_INTERRUPT_MODERATION);
+}
+
+int ena_com_update_nonadaptive_moderation_interval_tx(struct ena_com_dev *ena_dev,
+						      u32 tx_coalesce_usecs)
+{
+	if (!ena_dev->intr_delay_resolution) {
+		ena_trc_err("Illegal interrupt delay granularity value\n");
+		return -EFAULT;
+	}
+
+	ena_dev->intr_moder_tx_interval = tx_coalesce_usecs /
+		ena_dev->intr_delay_resolution;
+
+	return 0;
+}
+int ena_com_update_nonadaptive_moderation_interval_rx(struct ena_com_dev *ena_dev,
+						      u32 rx_coalesce_usecs)
+{
+	if (!ena_dev->intr_delay_resolution) {
+		ena_trc_err("Illegal interrupt delay granularity value\n");
+		return -EFAULT;
+	}
+
+	/* We use LOWEST entry of moderation table for storing
+	nonadaptive interrupt coalescing values */
+	ena_dev->intr_moder_tbl[ENA_INTR_MODER_LOWEST].intr_moder_interval =
+		rx_coalesce_usecs/ena_dev->intr_delay_resolution;
+
+	return 0;
+}
+
+void ena_com_destroy_interrupt_moderation(struct ena_com_dev *ena_dev)
+{
+	devm_kfree(ena_dev->dmadev, ena_dev->intr_moder_tbl);
+}
+
+int ena_com_init_intrrupt_moderation(struct ena_com_dev *ena_dev)
+{
+	struct ena_admin_get_feat_resp get_resp;
+	u32 delay_resolution;
+	int rc;
+
+	rc = ena_com_get_feature(ena_dev, &get_resp,
+				 ENA_ADMIN_INTERRUPT_MODERATION);
+
+	if (rc) {
+		if (rc == -EPERM) {
+			ena_trc_info("Feature %d isn't supported\n",
+				     ENA_ADMIN_INTERRUPT_MODERATION);
+			rc = 0;
+		} else {
+			ena_trc_err("Failed to get interrupt moderation admin cmd. rc: %d\n",
+				    rc);
+		}
+
+		/* no moderation supported, disable adaptive support  */
+		ena_com_set_adaptive_moderation_state(ena_dev, false);
+		return rc;
+	}
+
+	rc = ena_com_init_intrrupt_moderation_table(ena_dev);
+	if (rc)
+		goto err;
+
+	/* if moderation is supported by device we set adaptive moderation */
+	delay_resolution = get_resp.u.intr_moderation.intr_delay_resolution;
+	ena_com_update_intr_delay_resolution(ena_dev, delay_resolution);
+	ena_com_set_adaptive_moderation_state(ena_dev, true);
+
+	return 0;
+err:
+	ena_com_destroy_interrupt_moderation(ena_dev);
+	return rc;
+}
+
+void ena_com_config_default_interrupt_moderation_table(struct ena_com_dev *ena_dev)
+{
+	struct ena_intr_moder_entry *intr_moder_tbl = ena_dev->intr_moder_tbl;
+
+	if (!intr_moder_tbl)
+		return;
+
+	intr_moder_tbl[ENA_INTR_MODER_LOWEST].intr_moder_interval =
+		ENA_INTR_LOWEST_USECS;
+	intr_moder_tbl[ENA_INTR_MODER_LOWEST].pkts_per_interval =
+		ENA_INTR_LOWEST_PKTS;
+	intr_moder_tbl[ENA_INTR_MODER_LOWEST].bytes_per_interval =
+		ENA_INTR_LOWEST_BYTES;
+
+	intr_moder_tbl[ENA_INTR_MODER_LOW].intr_moder_interval =
+		ENA_INTR_LOW_USECS;
+	intr_moder_tbl[ENA_INTR_MODER_LOW].pkts_per_interval =
+		ENA_INTR_LOW_PKTS;
+	intr_moder_tbl[ENA_INTR_MODER_LOW].bytes_per_interval =
+		ENA_INTR_LOW_BYTES;
+
+	intr_moder_tbl[ENA_INTR_MODER_MID].intr_moder_interval =
+		ENA_INTR_MID_USECS;
+	intr_moder_tbl[ENA_INTR_MODER_MID].pkts_per_interval =
+		ENA_INTR_MID_PKTS;
+	intr_moder_tbl[ENA_INTR_MODER_MID].bytes_per_interval =
+		ENA_INTR_MID_BYTES;
+
+	intr_moder_tbl[ENA_INTR_MODER_HIGH].intr_moder_interval =
+		ENA_INTR_HIGH_USECS;
+	intr_moder_tbl[ENA_INTR_MODER_HIGH].pkts_per_interval =
+		ENA_INTR_HIGH_PKTS;
+	intr_moder_tbl[ENA_INTR_MODER_HIGH].bytes_per_interval =
+		ENA_INTR_HIGH_BYTES;
+
+	intr_moder_tbl[ENA_INTR_MODER_HIGHEST].intr_moder_interval =
+		ENA_INTR_HIGHEST_USECS;
+	intr_moder_tbl[ENA_INTR_MODER_HIGHEST].pkts_per_interval =
+		ENA_INTR_HIGHEST_PKTS;
+	intr_moder_tbl[ENA_INTR_MODER_HIGHEST].bytes_per_interval =
+		ENA_INTR_HIGHEST_BYTES;
+}
+
+unsigned int ena_com_get_nonadaptive_moderation_interval_tx(struct ena_com_dev *ena_dev)
+{
+	return ena_dev->intr_moder_tx_interval;
+}
+
+unsigned int ena_com_get_nonadaptive_moderation_interval_rx(struct ena_com_dev *ena_dev)
+{
+	struct ena_intr_moder_entry *intr_moder_tbl = ena_dev->intr_moder_tbl;
+
+	if (intr_moder_tbl)
+		return intr_moder_tbl[ENA_INTR_MODER_LOWEST].intr_moder_interval;
+
+	return 0;
+}
+
+void ena_com_init_intr_moderation_entry(struct ena_com_dev *ena_dev,
+					enum ena_intr_moder_level level,
+					struct ena_intr_moder_entry *entry)
+{
+	struct ena_intr_moder_entry *intr_moder_tbl = ena_dev->intr_moder_tbl;
+
+	if (level >= ENA_INTR_MAX_NUM_OF_LEVELS)
+		return;
+
+	intr_moder_tbl[level].intr_moder_interval = entry->intr_moder_interval;
+	if (ena_dev->intr_delay_resolution)
+		intr_moder_tbl[level].intr_moder_interval /=
+			ena_dev->intr_delay_resolution;
+	intr_moder_tbl[level].pkts_per_interval = entry->pkts_per_interval;
+	intr_moder_tbl[level].bytes_per_interval = entry->bytes_per_interval;
+}
+
+void ena_com_get_intr_moderation_entry(struct ena_com_dev *ena_dev,
+				       enum ena_intr_moder_level level,
+				       struct ena_intr_moder_entry *entry)
+{
+	struct ena_intr_moder_entry *intr_moder_tbl = ena_dev->intr_moder_tbl;
+
+	if (level >= ENA_INTR_MAX_NUM_OF_LEVELS)
+		return;
+
+	entry->intr_moder_interval = intr_moder_tbl[level].intr_moder_interval;
+	if (ena_dev->intr_delay_resolution)
+		entry->intr_moder_interval *= ena_dev->intr_delay_resolution;
+	entry->pkts_per_interval =
+	intr_moder_tbl[level].pkts_per_interval;
+	entry->bytes_per_interval = intr_moder_tbl[level].bytes_per_interval;
+}
diff --git a/drivers/amazon/ena/ena_com.h b/drivers/amazon/ena/ena_com.h
index 08b1c8b..9b27173 100644
--- a/drivers/amazon/ena/ena_com.h
+++ b/drivers/amazon/ena/ena_com.h
@@ -82,6 +82,47 @@
 
 /*****************************************************************************/
 /*****************************************************************************/
+/* ENA adaptive interrupt moderation settings */
+
+#define ENA_INTR_LOWEST_USECS           (0)
+#define ENA_INTR_LOWEST_PKTS            (3)
+#define ENA_INTR_LOWEST_BYTES           (2 * 1524)
+
+#define ENA_INTR_LOW_USECS              (32)
+#define ENA_INTR_LOW_PKTS               (12)
+#define ENA_INTR_LOW_BYTES              (16 * 1024)
+
+#define ENA_INTR_MID_USECS              (80)
+#define ENA_INTR_MID_PKTS               (48)
+#define ENA_INTR_MID_BYTES              (64 * 1024)
+
+#define ENA_INTR_HIGH_USECS             (128)
+#define ENA_INTR_HIGH_PKTS              (96)
+#define ENA_INTR_HIGH_BYTES             (128 * 1024)
+
+#define ENA_INTR_HIGHEST_USECS          (192)
+#define ENA_INTR_HIGHEST_PKTS           (128)
+#define ENA_INTR_HIGHEST_BYTES          (192 * 1024)
+
+#define ENA_INTR_INITIAL_TX_INTERVAL_USECS		196
+#define ENA_INTR_INITIAL_RX_INTERVAL_USECS		4
+#define ENA_INTR_DELAY_OLD_VALUE_WEIGHT			6
+#define ENA_INTR_DELAY_NEW_VALUE_WEIGHT			4
+
+enum ena_intr_moder_level {
+	ENA_INTR_MODER_LOWEST = 0,
+	ENA_INTR_MODER_LOW,
+	ENA_INTR_MODER_MID,
+	ENA_INTR_MODER_HIGH,
+	ENA_INTR_MODER_HIGHEST,
+	ENA_INTR_MAX_NUM_OF_LEVELS,
+};
+
+struct ena_intr_moder_entry {
+	unsigned int intr_moder_interval;
+	unsigned int pkts_per_interval;
+	unsigned int bytes_per_interval;
+};
 
 enum queue_direction {
 	ENA_COM_IO_QUEUE_DIRECTION_TX,
@@ -118,13 +159,15 @@ struct ena_com_io_cq {
 
 	u32 __iomem *db_addr;
 
-	/* The offset of the interrupt unmask register */
+	/* Interrupt unmask register */
 	u32 __iomem *unmask_reg;
 
+	/* The completion queue head doorbell register */
+	u32 __iomem *cq_head_db_reg;
+
 	/* The value to write to the above register to unmask
 	 * the interrupt of this queue
 	 */
-	u32 unmask_val;
 	u32 msix_vector;
 
 	enum queue_direction direction;
@@ -141,6 +184,7 @@ struct ena_com_io_cq {
 	/* Device queue index */
 	u16 idx;
 	u16 head;
+	u16 last_head_update;
 	u8 phase;
 	u8 cdesc_entry_size_in_bytes;
 
@@ -236,6 +280,7 @@ struct ena_com_mmio_read {
 	struct ena_admin_ena_mmio_req_read_less_resp *read_resp;
 	dma_addr_t read_resp_dma_addr;
 	u16 seq_num;
+	bool readless_supported;
 	/* spin lock to ensure a single outstanding read */
 	spinlock_t lock;
 };
@@ -259,6 +304,17 @@ struct ena_rss {
 
 };
 
+struct ena_host_attribute {
+	/* Debug area */
+	u8 *debug_area_virt_addr;
+	dma_addr_t debug_area_dma_addr;
+	u32 debug_area_size;
+
+	/* Host information */
+	struct ena_admin_host_info *host_info;
+	dma_addr_t host_info_dma_addr;
+};
+
 /* Each ena_dev is a PCI function. */
 struct ena_com_dev {
 	struct ena_com_admin_queue admin_queue;
@@ -279,6 +335,12 @@ struct ena_com_dev {
 	struct ena_rss rss;
 	u32 supported_features;
 	u32 dma_addr_bits;
+
+	struct ena_host_attribute host_attr;
+	bool adaptive_coalescing;
+	u16 intr_delay_resolution;
+	u32 intr_moder_tx_interval;
+	struct ena_intr_moder_entry *intr_moder_tbl;
 };
 
 struct ena_com_dev_get_features_ctx {
@@ -311,6 +373,13 @@ struct ena_aenq_handlers {
  */
 int ena_com_mmio_reg_read_request_init(struct ena_com_dev *ena_dev);
 
+/* ena_com_set_mmio_read_mode - Enable/disable the mmio reg read mechanism
+ * @ena_dev: ENA communication layer struct
+ * @realess_supported: readless mode (enable/disable)
+ */
+void ena_com_set_mmio_read_mode(struct ena_com_dev *ena_dev,
+				bool readless_supported);
+
 /* ena_com_mmio_reg_read_request_write_dev_addr - Write the mmio reg read return
  * value physical address.
  * @ena_dev: ENA communication layer struct
@@ -500,18 +569,6 @@ int ena_com_get_link_params(struct ena_com_dev *ena_dev,
  */
 int ena_com_get_dma_width(struct ena_com_dev *ena_dev);
 
-/* ena_com_set_interrupt_moderation - Config interrupt moderation.
- * @ena_dev: ENA communication layer struct
- * @qid: the caller virtual queue id.
- * @enable: enable/disable interrupt moderation
- * @count:  maximum packets between interrupts
- * @internal: maximum time between interrupts (value in us)
- *
- * @return: 0 on Success and negative value otherwise.
- */
-int ena_com_set_interrupt_moderation(struct ena_com_dev *ena_dev, int qid,
-				     bool enable, u16 count, u16 interval);
-
 /* ena_com_set_aenq_config - Set aenq groups configurations
  * @ena_dev: ENA communication layer struct
  * @groups flag: bit fields flags of enum ena_admin_aenq_group.
@@ -719,6 +776,32 @@ int ena_com_indirect_table_set(struct ena_com_dev *ena_dev);
  */
 int ena_com_indirect_table_get(struct ena_com_dev *ena_dev, u32 *ind_tbl);
 
+/* ena_com_allocate_host_attribute - Allocate host attributes resources.
+ * @ena_dev: ENA communication layer struct
+ * @debug_area_size: Debug aread size
+ *
+ * Allocate host info and debug area.
+ *
+ * @return: 0 on Success and negative value otherwise.
+ */
+int ena_com_allocate_host_attribute(struct ena_com_dev *ena_dev,
+				    u32 debug_area_size);
+
+/* ena_com_allocate_host_attribute - Free the host attributes resources.
+ * @ena_dev: ENA communication layer struct
+ *
+ * Free the allocate host info and debug area.
+ */
+void ena_com_delete_host_attribute(struct ena_com_dev *ena_dev);
+
+/* ena_com_set_host_attributes - Update the device with the host
+ * attributes base address.
+ * @ena_dev: ENA communication layer struct
+ *
+ * @return: 0 on Success and negative value otherwise.
+ */
+int ena_com_set_host_attributes(struct ena_com_dev *ena_dev);
+
 /* ena_com_create_io_cq - Create io completion queue.
  * @ena_dev: ENA communication layer struct
  * @io_cq - io completion queue handler
@@ -760,4 +843,190 @@ int ena_com_execute_admin_command(struct ena_com_admin_queue *admin_queue,
 				  struct ena_admin_acq_entry *cmd_comp,
 				  size_t cmd_comp_size);
 
+/* ena_com_init_intrrupt_moderation - Init interrupt moderation
+ * @ena_dev: ENA communication layer struct
+ *
+ * @return - 0 on success, negative value on failure.
+ */
+int ena_com_init_intrrupt_moderation(struct ena_com_dev *ena_dev);
+
+/* ena_com_destroy_interrupt_moderation - Destroy interrupt moderation resources
+ * @ena_dev: ENA communication layer struct
+ */
+void ena_com_destroy_interrupt_moderation(struct ena_com_dev *ena_dev);
+
+/* ena_com_interrupt_moderation_supported - Return if interrupt moderation
+ * capability is supported by the device.
+ *
+ * @return - supported or not.
+ */
+bool ena_com_interrupt_moderation_supported(struct ena_com_dev *ena_dev);
+
+/* ena_com_config_default_interrupt_moderation_table - Restore the interrupt
+ * moderation table back to the default parameters.
+ * @ena_dev: ENA communication layer struct
+ */
+void ena_com_config_default_interrupt_moderation_table(struct ena_com_dev *ena_dev);
+
+/* ena_com_update_nonadaptive_moderation_interval_tx - Update the
+ * non-adaptive interval in Tx direction.
+ * @ena_dev: ENA communication layer struct
+ * @tx_coalesce_usecs: Interval in usec.
+ *
+ * @return - 0 on success, negative value on failure.
+ */
+int ena_com_update_nonadaptive_moderation_interval_tx(struct ena_com_dev *ena_dev,
+						      u32 tx_coalesce_usecs);
+
+/* ena_com_update_nonadaptive_moderation_interval_rx - Update the
+ * non-adaptive interval in Rx direction.
+ * @ena_dev: ENA communication layer struct
+ * @rx_coalesce_usecs: Interval in usec.
+ *
+ * @return - 0 on success, negative value on failure.
+ */
+int ena_com_update_nonadaptive_moderation_interval_rx(struct ena_com_dev *ena_dev,
+						      u32 rx_coalesce_usecs);
+
+/* ena_com_get_nonadaptive_moderation_interval_tx - Retrieve the
+ * non-adaptive interval in Tx direction.
+ * @ena_dev: ENA communication layer struct
+ *
+ * @return - interval in usec
+ */
+unsigned int ena_com_get_nonadaptive_moderation_interval_tx(struct ena_com_dev *ena_dev);
+
+/* ena_com_get_nonadaptive_moderation_interval_rx - Retrieve the
+ * non-adaptive interval in Rx direction.
+ * @ena_dev: ENA communication layer struct
+ *
+ * @return - interval in usec
+ */
+unsigned int ena_com_get_nonadaptive_moderation_interval_rx(struct ena_com_dev *ena_dev);
+
+/* ena_com_init_intr_moderation_entry - Update a single entry in the interrupt
+ * moderation table.
+ * @ena_dev: ENA communication layer struct
+ * @level: Interrupt moderation table level
+ * @entry: Entry value
+ *
+ * Update a single entry in the interrupt moderation table.
+ */
+void ena_com_init_intr_moderation_entry(struct ena_com_dev *ena_dev,
+					enum ena_intr_moder_level level,
+					struct ena_intr_moder_entry *entry);
+
+/* ena_com_get_intr_moderation_entry - Init ena_intr_moder_entry.
+ * @ena_dev: ENA communication layer struct
+ * @level: Interrupt moderation table level
+ * @entry: Entry to fill.
+ *
+ * Initialize the entry according to the adaptive interrupt moderation table.
+ */
+void ena_com_get_intr_moderation_entry(struct ena_com_dev *ena_dev,
+				       enum ena_intr_moder_level level,
+				       struct ena_intr_moder_entry *entry);
+
+static inline bool ena_com_get_adaptive_moderation_state(struct ena_com_dev *ena_dev)
+{
+	return ena_dev->adaptive_coalescing;
+}
+
+static inline void ena_com_set_adaptive_moderation_state(struct ena_com_dev *ena_dev,
+							 bool state)
+{
+	ena_dev->adaptive_coalescing = state;
+}
+
+/* ena_com_calculate_interrupt_delay - Calculate new interrupt delay
+ * @ena_dev: ENA communication layer struct
+ * @pkts: Number of packets since the last update
+ * @bytes: Number of bytes received since the last update.
+ * @smoothed_interval: Returned interval
+ * @moder_tbl_idx: Current table level as input update new level as return
+ * value.
+ */
+static inline void ena_com_calculate_interrupt_delay(struct ena_com_dev *ena_dev,
+						     unsigned int pkts,
+						     unsigned int bytes,
+						     unsigned int *smoothed_interval,
+						     unsigned int *moder_tbl_idx)
+{
+	enum ena_intr_moder_level curr_moder_idx, new_moder_idx;
+	struct ena_intr_moder_entry *curr_moder_entry;
+	struct ena_intr_moder_entry *pred_moder_entry;
+	struct ena_intr_moder_entry *new_moder_entry;
+	struct ena_intr_moder_entry *intr_moder_tbl = ena_dev->intr_moder_tbl;
+	unsigned int interval;
+
+	/* We apply adaptive moderation on Rx path only.
+	 * Tx uses static interrupt moderation.
+	 */
+	if (!pkts || !bytes)
+		/* Tx interrupt, or spurious interrupt,
+		 * in both cases we just use same delay values
+		 */
+		return;
+
+	curr_moder_idx = *moder_tbl_idx;
+	if (unlikely(curr_moder_idx >=  ENA_INTR_MAX_NUM_OF_LEVELS)) {
+		ena_trc_err("Wrong moderation index %u\n", curr_moder_idx);
+		return;
+	}
+
+	curr_moder_entry = &intr_moder_tbl[curr_moder_idx];
+	new_moder_idx = curr_moder_idx;
+
+	if (curr_moder_idx == ENA_INTR_MODER_LOWEST) {
+		if ((pkts > curr_moder_entry->pkts_per_interval) ||
+		   (bytes > curr_moder_entry->bytes_per_interval))
+			new_moder_idx = curr_moder_idx + 1;
+	} else {
+		pred_moder_entry = &intr_moder_tbl[curr_moder_idx - 1];
+
+		if ((pkts <= pred_moder_entry->pkts_per_interval) ||
+		   (bytes <= pred_moder_entry->bytes_per_interval))
+			new_moder_idx = curr_moder_idx - 1;
+		else if ((pkts > curr_moder_entry->pkts_per_interval) ||
+			(bytes > curr_moder_entry->bytes_per_interval)) {
+			if (curr_moder_idx != ENA_INTR_MODER_HIGHEST)
+				new_moder_idx = curr_moder_idx + 1;
+		}
+	}
+	new_moder_entry = &intr_moder_tbl[new_moder_idx];
+
+	interval = new_moder_entry->intr_moder_interval;
+	*smoothed_interval = (
+		(interval * ENA_INTR_DELAY_NEW_VALUE_WEIGHT +
+		ENA_INTR_DELAY_OLD_VALUE_WEIGHT * (*smoothed_interval)) + 5) /
+		10;
+
+	*moder_tbl_idx = new_moder_idx;
+}
+
+/* ena_com_update_intr_reg - Prepare interrupt register
+ * @intr_reg: interrupt register to update.
+ * @rx_delay_interval: Rx interval in usecs
+ * @tx_delay_interval: Tx interval in usecs
+ * @unmask: unask enable/disable
+ *
+ * Prepare interrupt update register with the supplied parameters.
+ */
+static inline void ena_com_update_intr_reg(struct ena_eth_io_intr_reg *intr_reg,
+					   u32 rx_delay_interval,
+					   u32 tx_delay_interval,
+					   bool unmask)
+{
+	intr_reg->intr_control = 0;
+	intr_reg->intr_control |= rx_delay_interval &
+		ENA_ETH_IO_INTR_REG_RX_INTR_DELAY_MASK;
+
+	intr_reg->intr_control |=
+		(tx_delay_interval << ENA_ETH_IO_INTR_REG_TX_INTR_DELAY_SHIFT)
+		& ENA_ETH_IO_INTR_REG_RX_INTR_DELAY_MASK;
+
+	if (unmask)
+		intr_reg->intr_control |= ENA_ETH_IO_INTR_REG_INTR_UNMASK_MASK;
+}
+
 #endif /* !(ENA_COM) */
diff --git a/drivers/amazon/ena/ena_eth_com.c b/drivers/amazon/ena/ena_eth_com.c
index f4f9623..fa50b06 100644
--- a/drivers/amazon/ena/ena_eth_com.c
+++ b/drivers/amazon/ena/ena_eth_com.c
@@ -323,6 +323,10 @@ int ena_com_prepare_tx(struct ena_com_io_sq *io_sq,
 		ENA_ETH_IO_TX_DESC_REQ_ID_LO_SHIFT) &
 		ENA_ETH_IO_TX_DESC_REQ_ID_LO_MASK;
 
+	desc->meta_ctrl |= (ena_tx_ctx->df <<
+		ENA_ETH_IO_TX_DESC_DF_SHIFT) &
+		ENA_ETH_IO_TX_DESC_DF_MASK;
+
 	/* Bits 10-15 */
 	desc->len_ctrl |= ((ena_tx_ctx->req_id >> 10) <<
 		ENA_ETH_IO_TX_DESC_REQ_ID_HI_SHIFT) &
diff --git a/drivers/amazon/ena/ena_eth_com.h b/drivers/amazon/ena/ena_eth_com.h
index 9844dcb..fa222fb 100644
--- a/drivers/amazon/ena/ena_eth_com.h
+++ b/drivers/amazon/ena/ena_eth_com.h
@@ -36,6 +36,8 @@
 #include "ena_com.h"
 
 #define ENA_MAX_PUSH_PKT_SIZE 128
+/* head update threshold in units of (queue size / ENA_COMP_HEAD_THRESH) */
+#define ENA_COMP_HEAD_THRESH 4
 
 struct ena_com_tx_ctx {
 	struct ena_com_tx_meta ena_meta;
@@ -52,11 +54,12 @@ struct ena_com_tx_ctx {
 	 */
 	u16 header_len;
 
-	bool meta_valid;
-	bool tso_enable;
-	bool l3_csum_enable;
-	bool l4_csum_enable;
-	bool l4_csum_partial;
+	u8 meta_valid;
+	u8 tso_enable;
+	u8 l3_csum_enable;
+	u8 l4_csum_enable;
+	u8 l4_csum_partial;
+	u8 df; /* Don't fragment */
 };
 
 struct ena_com_rx_ctx {
@@ -86,9 +89,10 @@ int ena_com_add_single_rx_desc(struct ena_com_io_sq *io_sq,
 
 int ena_com_tx_comp_req_id_get(struct ena_com_io_cq *io_cq, u16 *req_id);
 
-static inline void ena_com_unmask_intr(struct ena_com_io_cq *io_cq)
+static inline void ena_com_unmask_intr(struct ena_com_io_cq *io_cq,
+				       struct ena_eth_io_intr_reg *intr_reg)
 {
-	writel(io_cq->unmask_val, io_cq->unmask_reg);
+	writel(intr_reg->intr_control, io_cq->unmask_reg);
 }
 
 static inline int ena_com_sq_empty_space(struct ena_com_io_sq *io_sq)
@@ -108,13 +112,33 @@ static inline int ena_com_write_sq_doorbell(struct ena_com_io_sq *io_sq)
 
 	tail = io_sq->tail;
 
-	ena_trc_dbg("write db for queue: %d tail: %d\n", io_sq->qid, tail);
+	ena_trc_dbg("write submission queue doorbell for queue: %d tail: %d\n",
+		    io_sq->qid, tail);
 
 	writel(tail, io_sq->db_addr);
 
 	return 0;
 }
 
+static inline int ena_com_update_dev_comp_head(struct ena_com_io_cq *io_cq)
+{
+	u16 unreported_comp, head;
+	bool need_update;
+
+	head = io_cq->head;
+	unreported_comp = head - io_cq->last_head_update;
+	need_update = unreported_comp > (io_cq->q_depth / ENA_COMP_HEAD_THRESH);
+
+	if (io_cq->cq_head_db_reg && need_update) {
+		ena_trc_dbg("Write completion queue doorbell for queue %d: head: %d\n",
+			    io_cq->qid, head);
+		writel(head, io_cq->cq_head_db_reg);
+		io_cq->last_head_update = head;
+	}
+
+	return 0;
+}
+
 static inline void ena_com_comp_ack(struct ena_com_io_sq *io_sq, u16 elem)
 {
 	io_sq->next_to_comp += elem;
diff --git a/drivers/amazon/ena/ena_eth_io_defs.h b/drivers/amazon/ena/ena_eth_io_defs.h
index 27120e7..bfbb2b2 100644
--- a/drivers/amazon/ena/ena_eth_io_defs.h
+++ b/drivers/amazon/ena/ena_eth_io_defs.h
@@ -368,6 +368,17 @@ struct ena_eth_io_rx_cdesc_ext {
 	u32 reserved_w7;
 };
 
+/* ENA Interrupt Unmask Register */
+struct ena_eth_io_intr_reg {
+	/* word 0 : */
+	/* 14:0 : rx_intr_delay - rx interrupt delay value
+	 * 29:15 : tx_intr_delay - tx interrupt delay value
+	 * 30 : intr_unmask - if set, unmasks interrupt
+	 * 31 : reserved
+	 */
+	u32 intr_control;
+};
+
 /* tx_desc */
 #define ENA_ETH_IO_TX_DESC_LENGTH_MASK GENMASK(15, 0)
 #define ENA_ETH_IO_TX_DESC_REQ_ID_HI_SHIFT 16
@@ -488,4 +499,11 @@ struct ena_eth_io_rx_cdesc_ext {
 #define ENA_ETH_IO_RX_CDESC_BASE_BUFFER_SHIFT 30
 #define ENA_ETH_IO_RX_CDESC_BASE_BUFFER_MASK BIT(30)
 
+/* intr_reg */
+#define ENA_ETH_IO_INTR_REG_RX_INTR_DELAY_MASK GENMASK(14, 0)
+#define ENA_ETH_IO_INTR_REG_TX_INTR_DELAY_SHIFT 15
+#define ENA_ETH_IO_INTR_REG_TX_INTR_DELAY_MASK GENMASK(29, 15)
+#define ENA_ETH_IO_INTR_REG_INTR_UNMASK_SHIFT 30
+#define ENA_ETH_IO_INTR_REG_INTR_UNMASK_MASK BIT(30)
+
 #endif /*_ENA_ETH_IO_H_ */
diff --git a/drivers/amazon/ena/ena_ethtool.c b/drivers/amazon/ena/ena_ethtool.c
index 0ec9eb0..dbca7be 100644
--- a/drivers/amazon/ena/ena_ethtool.c
+++ b/drivers/amazon/ena/ena_ethtool.c
@@ -80,6 +80,7 @@ static const struct ena_stats ena_stats_tx_strings[] = {
 	ENA_STAT_TX_ENTRY(doorbells),
 	ENA_STAT_TX_ENTRY(prepare_ctx_err),
 	ENA_STAT_TX_ENTRY(missing_tx_comp),
+	ENA_STAT_TX_ENTRY(bad_req_id),
 };
 
 static const struct ena_stats ena_stats_rx_strings[] = {
@@ -191,7 +192,7 @@ static void ena_get_ethtool_stats(struct net_device *netdev,
 	ena_dev_admin_queue_stats(adapter, &data);
 }
 
-static int ena_get_sset_count(struct net_device *netdev, int sset)
+int ena_get_sset_count(struct net_device *netdev, int sset)
 {
 	if (sset != ETH_SS_STATS)
 		return -EOPNOTSUPP;
@@ -294,31 +295,56 @@ static int ena_get_coalesce(struct net_device *net_dev,
 			    struct ethtool_coalesce *coalesce)
 {
 	struct ena_adapter *adapter = netdev_priv(net_dev);
+	struct ena_com_dev *ena_dev = adapter->ena_dev;
 
-	coalesce->tx_coalesce_usecs = adapter->tx_usecs;
-	coalesce->rx_coalesce_usecs = adapter->rx_usecs;
-	coalesce->rx_max_coalesced_frames = adapter->rx_frames;
-	coalesce->tx_max_coalesced_frames = adapter->tx_frames;
-	coalesce->use_adaptive_rx_coalesce = false;
+	if (!ena_com_interrupt_moderation_supported(ena_dev)) {
+		/* the devie doesn't support interrupt moderation */
+		return -EOPNOTSUPP;
+	}
+	coalesce->tx_coalesce_usecs =
+		ena_com_get_nonadaptive_moderation_interval_tx(ena_dev) /
+			ena_dev->intr_delay_resolution;
+	if (!ena_com_get_adaptive_moderation_state(ena_dev))
+		coalesce->rx_coalesce_usecs =
+			ena_com_get_nonadaptive_moderation_interval_rx(ena_dev)
+			/ ena_dev->intr_delay_resolution;
+	coalesce->use_adaptive_rx_coalesce =
+		ena_com_get_adaptive_moderation_state(ena_dev);
 
 	return 0;
 }
 
-static int ena_ethtool_set_coalesce(struct net_device *net_dev,
-				    struct ethtool_coalesce *coalesce)
+static void ena_update_tx_rings_intr_moderation(struct ena_adapter *adapter)
+{
+	unsigned int val;
+	int i;
+
+	val = ena_com_get_nonadaptive_moderation_interval_tx(adapter->ena_dev);
+
+	for (i = 0; i < adapter->num_queues; i++)
+		adapter->tx_ring[i].smoothed_interval = val;
+}
+
+static int ena_set_coalesce(struct net_device *net_dev,
+			    struct ethtool_coalesce *coalesce)
 {
 	struct ena_adapter *adapter = netdev_priv(net_dev);
-	bool tx_enable = true;
-	bool rx_enable = true;
-	int i, rc;
+	struct ena_com_dev *ena_dev = adapter->ena_dev;
+	int rc;
+
+	if (!ena_com_interrupt_moderation_supported(ena_dev)) {
+		/* the devie doesn't support interrupt moderation */
+		return -EOPNOTSUPP;
+	}
 
-	/* The above params are unsupported by our driver */
+	/* Note, adaptive coalescing settings are updated through sysfs */
 	if (coalesce->rx_coalesce_usecs_irq ||
+	    coalesce->rx_max_coalesced_frames ||
 	    coalesce->rx_max_coalesced_frames_irq ||
 	    coalesce->tx_coalesce_usecs_irq ||
+	    coalesce->tx_max_coalesced_frames ||
 	    coalesce->tx_max_coalesced_frames_irq ||
 	    coalesce->stats_block_coalesce_usecs ||
-	    coalesce->use_adaptive_rx_coalesce ||
 	    coalesce->use_adaptive_tx_coalesce ||
 	    coalesce->pkt_rate_low ||
 	    coalesce->rx_coalesce_usecs_low ||
@@ -333,61 +359,38 @@ static int ena_ethtool_set_coalesce(struct net_device *net_dev,
 	    coalesce->rate_sample_interval)
 		return -EINVAL;
 
-	if ((coalesce->rx_coalesce_usecs == 0) &&
-	    (coalesce->rx_max_coalesced_frames == 0))
-		return -EINVAL;
-
-	if ((coalesce->tx_coalesce_usecs == 0) &&
-	    (coalesce->tx_max_coalesced_frames == 0))
-		return -EINVAL;
-
-	if ((coalesce->rx_coalesce_usecs == 0) &&
-	    (coalesce->rx_max_coalesced_frames == 1))
-		rx_enable = false;
-
-	if ((coalesce->tx_coalesce_usecs == 0) &&
-	    (coalesce->tx_max_coalesced_frames == 1))
-		tx_enable = false;
-
-	/* Set tx interrupt moderation */
-	for (i = 0; i < adapter->num_queues; i++) {
-		rc = ena_com_set_interrupt_moderation(adapter->ena_dev,
-						      ENA_IO_TXQ_IDX(i),
-						      tx_enable,
-						      coalesce->tx_max_coalesced_frames,
-						      coalesce->tx_coalesce_usecs);
-		if (rc) {
-			netdev_info(adapter->netdev,
-				    "setting interrupt moderation for TX queue %d failed. err: %d\n",
-				    i, rc);
-			goto err;
+	rc = ena_com_update_nonadaptive_moderation_interval_tx(ena_dev,
+							       coalesce->tx_coalesce_usecs);
+	if (rc)
+		goto err;
+
+	ena_update_tx_rings_intr_moderation(adapter);
+
+	if (ena_com_get_adaptive_moderation_state(ena_dev)) {
+		if (!coalesce->use_adaptive_rx_coalesce) {
+			ena_com_set_adaptive_moderation_state(ena_dev, false);
+			rc = ena_com_update_nonadaptive_moderation_interval_rx(ena_dev,
+									       coalesce->rx_coalesce_usecs);
+			if (rc)
+				goto err;
+		} else {
+			/* was in adaptive mode and remains in it,
+			 * allow to update only tx_usecs
+			 */
+			if (coalesce->rx_coalesce_usecs)
+				return -EINVAL;
 		}
-	}
-
-	/* Set rx interrupt moderation */
-	for (i = 0; i < adapter->num_queues; i++) {
-		rc = ena_com_set_interrupt_moderation(adapter->ena_dev,
-						      ENA_IO_RXQ_IDX(i),
-						      rx_enable,
-						      coalesce->tx_max_coalesced_frames,
-						      coalesce->rx_coalesce_usecs);
-
-		if (rc) {
-			netdev_info(adapter->netdev,
-				    "setting interrupt moderation for RX queue %d failed. err: %d\n",
-				    i, rc);
+	} else { /* was in non-adaptive mode */
+		if (coalesce->use_adaptive_rx_coalesce) {
+			ena_com_set_adaptive_moderation_state(ena_dev, true);
+		} else {
+			rc = ena_com_update_nonadaptive_moderation_interval_rx(ena_dev,
+									       coalesce->rx_coalesce_usecs);
 			goto err;
 		}
 	}
 
-	adapter->tx_usecs = coalesce->tx_coalesce_usecs;
-	adapter->rx_usecs = coalesce->rx_coalesce_usecs;
-
-	adapter->rx_frames = coalesce->rx_max_coalesced_frames_high;
-	adapter->tx_frames = coalesce->tx_max_coalesced_frames_high;
-
 	return 0;
-
 err:
 	return rc;
 }
@@ -746,7 +749,7 @@ static const struct ethtool_ops ena_ethtool_ops = {
 	.nway_reset		= ena_nway_reset,
 	.get_link		= ethtool_op_get_link,
 	.get_coalesce		= ena_get_coalesce,
-	.set_coalesce		= ena_ethtool_set_coalesce,
+	.set_coalesce		= ena_set_coalesce,
 	.get_ringparam		= ena_get_ringparam,
 	.get_sset_count         = ena_get_sset_count,
 	.get_strings		= ena_get_strings,
@@ -765,16 +768,16 @@ void ena_set_ethtool_ops(struct net_device *netdev)
 	netdev->ethtool_ops = &ena_ethtool_ops;
 }
 
-void ena_dump_stats_to_dmesg(struct ena_adapter *adapter)
+static void ena_dump_stats_ex(struct ena_adapter *adapter, u8 *buf)
 {
 	struct net_device *netdev = adapter->netdev;
 	u8 *strings_buf;
 	u64 *data_buf;
 	int strings_num;
-	int i;
+	int i, rc;
 
 	strings_num = ena_get_sset_count(netdev, ETH_SS_STATS);
-	if (strings_num < 0) {
+	if (strings_num <= 0) {
 		netif_err(adapter, drv, netdev, "Can't get stats num\n");
 		return;
 	}
@@ -801,10 +804,34 @@ void ena_dump_stats_to_dmesg(struct ena_adapter *adapter)
 	ena_get_strings(netdev, ETH_SS_STATS, strings_buf);
 	ena_get_ethtool_stats(netdev, NULL, data_buf);
 
-	for (i = 0; i < strings_num; i++)
-		netif_err(adapter, drv, netdev, "%s: %llu\n",
-			  strings_buf + i * ETH_GSTRING_LEN, data_buf[i]);
+	/* If there is a buffer, dump stats, otherwise print them to dmesg */
+	if (buf)
+		for (i = 0; i < strings_num; i++) {
+			rc = snprintf(buf, ETH_GSTRING_LEN + sizeof(u64),
+				      "%s %llu\n",
+				      strings_buf + i * ETH_GSTRING_LEN,
+				      data_buf[i]);
+			buf += rc;
+		}
+	else
+		for (i = 0; i < strings_num; i++)
+			netif_err(adapter, drv, netdev, "%s: %llu\n",
+				  strings_buf + i * ETH_GSTRING_LEN,
+				  data_buf[i]);
 
 	devm_kfree(&adapter->pdev->dev, strings_buf);
 	devm_kfree(&adapter->pdev->dev, data_buf);
 }
+
+void ena_dump_stats_to_buf(struct ena_adapter *adapter, u8 *buf)
+{
+	if (!buf)
+		return;
+
+	ena_dump_stats_ex(adapter, buf);
+}
+
+void ena_dump_stats_to_dmesg(struct ena_adapter *adapter)
+{
+	ena_dump_stats_ex(adapter, NULL);
+}
diff --git a/drivers/amazon/ena/ena_netdev.c b/drivers/amazon/ena/ena_netdev.c
index d97c853..5e35060 100644
--- a/drivers/amazon/ena/ena_netdev.c
+++ b/drivers/amazon/ena/ena_netdev.c
@@ -39,6 +39,7 @@
 #include <linux/module.h>
 #include <linux/moduleparam.h>
 #include <linux/pci.h>
+#include <linux/utsname.h>
 #include <linux/version.h>
 #include <net/ip.h>
 
@@ -172,16 +173,23 @@ static void ena_init_io_rings(struct ena_adapter *adapter)
 		txr->netdev  = rxr->netdev  = adapter->netdev;
 		txr->napi    = rxr->napi    = &adapter->ena_napi[i].napi;
 		txr->adapter = rxr->adapter = adapter;
+		txr->ena_dev = rxr->ena_dev = adapter->ena_dev;
+		txr->per_napi_packets = rxr->per_napi_packets = 0;
+		txr->per_napi_bytes   = rxr->per_napi_bytes = 0;
 		u64_stats_init(&txr->syncp);
 		u64_stats_init(&rxr->syncp);
 
 		/* TX specific ring state */
 		txr->ring_size = adapter->tx_ring_size;
 		txr->tx_mem_queue_type = ena_dev->tx_mem_queue_type;
+		txr->smoothed_interval =
+			ena_com_get_nonadaptive_moderation_interval_tx(ena_dev);
 
 		/* RX specific ring state */
 		rxr->ring_size = adapter->rx_ring_size;
 		rxr->rx_small_copy_len = adapter->small_copy_len;
+		rxr->smoothed_interval =
+			ena_com_get_nonadaptive_moderation_interval_rx(ena_dev);
 	}
 }
 
@@ -194,11 +202,8 @@ static void ena_init_io_rings(struct ena_adapter *adapter)
 static int ena_setup_tx_resources(struct ena_adapter *adapter, int qid)
 {
 	struct ena_ring *tx_ring = &adapter->tx_ring[qid];
-	struct device *dev;
 	int size, i;
 
-	dev = &adapter->pdev->dev;
-
 	if (tx_ring->tx_buffer_info) {
 		netif_err(adapter, ifup,
 			  adapter->netdev, "tx_buffer_info info is not NULL");
@@ -207,14 +212,14 @@ static int ena_setup_tx_resources(struct ena_adapter *adapter, int qid)
 
 	size = sizeof(struct ena_tx_buffer) * tx_ring->ring_size;
 
-	tx_ring->tx_buffer_info = devm_kzalloc(dev, size, GFP_KERNEL);
+	tx_ring->tx_buffer_info = vzalloc(size);
 	if (!tx_ring->tx_buffer_info)
 		return -ENOMEM;
 
 	size = sizeof(u16) * tx_ring->ring_size;
-	tx_ring->free_tx_ids = devm_kzalloc(dev, size, GFP_KERNEL);
+	tx_ring->free_tx_ids = vzalloc(size);
 	if (!tx_ring->free_tx_ids) {
-		devm_kfree(dev, tx_ring->tx_buffer_info);
+		vfree(tx_ring->tx_buffer_info);
 		return -ENOMEM;
 	}
 
@@ -239,12 +244,11 @@ static int ena_setup_tx_resources(struct ena_adapter *adapter, int qid)
 static void ena_free_tx_resources(struct ena_adapter *adapter, int qid)
 {
 	struct ena_ring *tx_ring = &adapter->tx_ring[qid];
-	struct device *dev = &adapter->pdev->dev;
 
-	devm_kfree(dev, tx_ring->tx_buffer_info);
+	vfree(tx_ring->tx_buffer_info);
 	tx_ring->tx_buffer_info = NULL;
 
-	devm_kfree(dev, tx_ring->free_tx_ids);
+	vfree(tx_ring->free_tx_ids);
 	tx_ring->free_tx_ids = NULL;
 }
 
@@ -314,8 +318,7 @@ static int ena_setup_rx_resources(struct ena_adapter *adapter,
 	 */
 	size += sizeof(struct ena_rx_buffer);
 
-	rx_ring->rx_buffer_info = devm_kzalloc(&adapter->pdev->dev,
-					       size, GFP_KERNEL);
+	rx_ring->rx_buffer_info = vzalloc(size);
 	if (!rx_ring->rx_buffer_info)
 		return -ENOMEM;
 
@@ -339,7 +342,7 @@ static void ena_free_rx_resources(struct ena_adapter *adapter,
 {
 	struct ena_ring *rx_ring = &adapter->rx_ring[qid];
 
-	devm_kfree(&adapter->pdev->dev, rx_ring->rx_buffer_info);
+	vfree(rx_ring->rx_buffer_info);
 	rx_ring->rx_buffer_info = NULL;
 }
 
@@ -635,8 +638,33 @@ static void ena_destroy_all_io_queues(struct ena_adapter *adapter)
 	ena_destroy_all_rx_queues(adapter);
 }
 
-static int ena_clean_tx_irq(struct ena_ring *tx_ring,
-			    u32 budget)
+static int validate_tx_req_id(struct ena_ring *tx_ring, u16 req_id)
+{
+	struct ena_tx_buffer *tx_info = NULL;
+
+	if (likely(req_id < tx_ring->ring_size)) {
+		tx_info = &tx_ring->tx_buffer_info[req_id];
+		if (likely(tx_info->skb))
+			return 0;
+	}
+
+	if (tx_info)
+		netif_err(tx_ring->adapter, tx_done, tx_ring->netdev,
+				  "tx_info doesn't have valid skb\n");
+	else
+		netif_err(tx_ring->adapter, tx_done, tx_ring->netdev,
+			  "Invalid req_id: %hu\n", req_id);
+
+	u64_stats_update_begin(&tx_ring->syncp);
+	tx_ring->tx_stats.bad_req_id++;
+	u64_stats_update_end(&tx_ring->syncp);
+
+	/* Trigger device reset */
+	tx_ring->adapter->trigger_reset = true;
+	return -EFAULT;
+}
+
+static int ena_clean_tx_irq(struct ena_ring *tx_ring, u32 budget)
 {
 	struct netdev_queue *txq;
 	bool above_thresh;
@@ -661,11 +689,13 @@ static int ena_clean_tx_irq(struct ena_ring *tx_ring,
 		if (rc)
 			break;
 
+		rc = validate_tx_req_id(tx_ring, req_id);
+		if (rc)
+			break;
+
 		tx_info = &tx_ring->tx_buffer_info[req_id];
 		skb = tx_info->skb;
 
-		ENA_ASSERT(skb, "SKB is NULL\n");
-
 		/* prefetch skb_end_pointer() to speedup skb_shinfo(skb) */
 		prefetch(&skb->end);
 
@@ -707,6 +737,7 @@ static int ena_clean_tx_irq(struct ena_ring *tx_ring,
 
 	tx_ring->next_to_clean = next_to_clean;
 	ena_com_comp_ack(tx_ring->ena_com_io_sq, total_done);
+	ena_com_update_dev_comp_head(tx_ring->ena_com_io_cq);
 
 	netdev_tx_completed_queue(txq, tx_pkts, tx_bytes);
 
@@ -734,6 +765,9 @@ static int ena_clean_tx_irq(struct ena_ring *tx_ring,
 		__netif_tx_unlock(txq);
 	}
 
+	tx_ring->per_napi_bytes += tx_bytes;
+	tx_ring->per_napi_packets += tx_pkts;
+
 	return tx_pkts;
 }
 
@@ -922,8 +956,7 @@ static void ena_set_rx_hash(struct ena_ring *rx_ring,
  *
  * Returns the number of cleaned buffers.
  */
-static int ena_clean_rx_irq(struct ena_ring *rx_ring,
-			    struct napi_struct *napi,
+static int ena_clean_rx_irq(struct ena_ring *rx_ring, struct napi_struct *napi,
 			    u32 budget)
 {
 	u16 next_to_clean = rx_ring->next_to_clean;
@@ -991,7 +1024,8 @@ static int ena_clean_rx_irq(struct ena_ring *rx_ring,
 	} while (likely(res_budget));
 
 	work_done = budget - res_budget;
-
+	rx_ring->per_napi_bytes += total_len;
+	rx_ring->per_napi_packets += work_done;
 	u64_stats_update_begin(&rx_ring->syncp);
 	rx_ring->rx_stats.bytes += total_len;
 	rx_ring->rx_stats.cnt += work_done;
@@ -1004,8 +1038,10 @@ static int ena_clean_rx_irq(struct ena_ring *rx_ring,
 	refill_threshold = rx_ring->ring_size / ENA_RX_REFILL_THRESH_DEVIDER;
 
 	/* Optimization, try to batch new rx buffers */
-	if (refill_required > refill_threshold)
+	if (refill_required > refill_threshold) {
+		ena_com_update_dev_comp_head(rx_ring->ena_com_io_cq);
 		ena_refill_rx_bufs(rx_ring, refill_required);
+	}
 
 	return work_done;
 
@@ -1023,10 +1059,32 @@ error:
 	return 0;
 }
 
+inline void ena_adjust_intr_moderation(struct ena_ring *rx_ring,
+				       struct ena_ring *tx_ring)
+{
+	/* We apply adaptive moderation on Rx path only.
+	 * Tx uses static interrupt moderation.
+	 */
+	ena_com_calculate_interrupt_delay(rx_ring->ena_dev,
+					  rx_ring->per_napi_packets,
+					  rx_ring->per_napi_bytes,
+					  &rx_ring->smoothed_interval,
+					  &rx_ring->moder_tbl_idx);
+
+	/* Reset per napi packets/bytes */
+	tx_ring->per_napi_packets = 0;
+	tx_ring->per_napi_bytes = 0;
+	rx_ring->per_napi_packets = 0;
+	rx_ring->per_napi_bytes = 0;
+}
+
+
 static int ena_io_poll(struct napi_struct *napi, int budget)
 {
 	struct ena_napi *ena_napi = container_of(napi, struct ena_napi, napi);
 	struct ena_ring *tx_ring, *rx_ring;
+	struct ena_eth_io_intr_reg intr_reg;
+
 	u32 tx_work_done;
 	u32 rx_work_done;
 	int tx_budget;
@@ -1045,20 +1103,30 @@ static int ena_io_poll(struct napi_struct *napi, int budget)
 		napi_complete(napi);
 
 		napi_comp_call = 1;
-		/* Tx and Rx share the same interrupt vector so the driver
-		 *  can unmask either of the interrupts
-		 */
-		ena_com_unmask_intr(rx_ring->ena_com_io_cq);
+		/* Tx and Rx share the same interrupt vector */
+		if (ena_com_get_adaptive_moderation_state(rx_ring->ena_dev))
+			ena_adjust_intr_moderation(rx_ring, tx_ring);
+
+		/* Update intr register: rx intr delay, tx intr delay and
+		 * interupt unmask */
+		ena_com_update_intr_reg(&intr_reg,
+					rx_ring->smoothed_interval,
+					tx_ring->smoothed_interval,
+					true);
+
+		/*It is a shared MSI-X. Tx and Rx CQ have pointer to it.
+		 * So we use one of them to reach the intr reg */
+		ena_com_unmask_intr(rx_ring->ena_com_io_cq, &intr_reg);
 
 		ret = rx_work_done;
 	} else {
 		ret = budget;
 	}
 
-	u64_stats_update_begin(&rx_ring->syncp);
+	u64_stats_update_begin(&tx_ring->syncp);
 	tx_ring->tx_stats.napi_comp += napi_comp_call;
 	tx_ring->tx_stats.tx_poll++;
-	u64_stats_update_end(&rx_ring->syncp);
+	u64_stats_update_end(&tx_ring->syncp);
 
 	return ret;
 }
@@ -1104,9 +1172,7 @@ static int ena_enable_msix(struct ena_adapter *adapter,
 		  "trying to enable MSI-X, vectors %d\n",
 		  msix_vecs);
 
-	adapter->msix_entries = devm_kzalloc(&adapter->pdev->dev,
-					     msix_vecs * sizeof(struct msix_entry),
-					     GFP_KERNEL);
+	adapter->msix_entries = vzalloc(msix_vecs * sizeof(struct msix_entry));
 
 	if (!adapter->msix_entries) {
 		netif_err(adapter, probe, adapter->netdev,
@@ -1280,7 +1346,7 @@ static void ena_disable_msix(struct ena_adapter *adapter)
 	adapter->msix_enabled = false;
 
 	if (adapter->msix_entries)
-		devm_kfree(&adapter->pdev->dev, adapter->msix_entries);
+		vfree(adapter->msix_entries);
 	adapter->msix_entries = NULL;
 }
 
@@ -1669,22 +1735,24 @@ static void ena_tx_csum(struct ena_com_tx_ctx *ena_tx_ctx, struct sk_buff *skb)
 	struct ena_com_tx_meta *ena_meta = &ena_tx_ctx->ena_meta;
 
 	if ((skb->ip_summed == CHECKSUM_PARTIAL) || mss) {
-		ena_tx_ctx->l4_csum_enable = true;
+		ena_tx_ctx->l4_csum_enable = 1;
 		if (mss) {
-			ena_tx_ctx->tso_enable = true;
+			ena_tx_ctx->tso_enable = 1;
 			ena_meta->l4_hdr_len = tcp_hdr(skb)->doff;
-			ena_tx_ctx->l4_csum_partial = false;
+			ena_tx_ctx->l4_csum_partial = 0;
 		} else {
-			ena_tx_ctx->tso_enable = false;
+			ena_tx_ctx->tso_enable = 0;
 			ena_meta->l4_hdr_len = 0;
-			ena_tx_ctx->l4_csum_partial = true;
+			ena_tx_ctx->l4_csum_partial = 1;
 		}
 
 		switch (skb->protocol) {
 		case htons(ETH_P_IP):
 			ena_tx_ctx->l3_proto = ENA_ETH_IO_L3_PROTO_IPV4;
+			if (ip_hdr(skb)->frag_off & htons(IP_DF))
+				ena_tx_ctx->df = 1;
 			if (mss)
-				ena_tx_ctx->l3_csum_enable = true;
+				ena_tx_ctx->l3_csum_enable = 1;
 			if (ip_hdr(skb)->protocol == IPPROTO_TCP)
 				ena_tx_ctx->l4_proto = ENA_ETH_IO_L4_PROTO_TCP;
 			else
@@ -1704,10 +1772,10 @@ static void ena_tx_csum(struct ena_com_tx_ctx *ena_tx_ctx, struct sk_buff *skb)
 		ena_meta->mss = mss;
 		ena_meta->l3_hdr_len = skb_network_header_len(skb);
 		ena_meta->l3_hdr_offset = skb_network_offset(skb);
-		ena_tx_ctx->meta_valid = true;
+		ena_tx_ctx->meta_valid = 1;
 
 	} else {
-		ena_tx_ctx->meta_valid = false;
+		ena_tx_ctx->meta_valid = 0;
 	}
 }
 
@@ -1949,6 +2017,70 @@ static u16 ena_select_queue(struct net_device *dev, struct sk_buff *skb,
 	return qid;
 }
 
+static void ena_fill_host_info(struct ena_adapter *adapter)
+{
+	struct ena_admin_host_info *host_info =
+		adapter->ena_dev->host_attr.host_info;
+	struct net_device *netdev = adapter->netdev;
+
+	if (!host_info)
+		return;
+
+	host_info->os_type = ENA_ADMIN_OS_LINUX;
+	host_info->kernel_ver = LINUX_VERSION_CODE;
+	strncpy(host_info->kernel_ver_str, utsname()->version, 32);
+	host_info->os_dist = 0;
+	strncpy(host_info->os_dist_str, utsname()->release, 128);
+	host_info->driver_version =
+		(DRV_MODULE_VER_MAJOR) |
+		(DRV_MODULE_VER_MINOR << ENA_ADMIN_HOST_INFO_MINOR_SHIFT) |
+		(DRV_MODULE_VER_SUBMINOR << ENA_ADMIN_HOST_INFO_SUB_MINOR_SHIFT);
+	host_info->supported_network_features[0] =
+		netdev->features & GENMASK_ULL(31, 0);
+	host_info->supported_network_features[1] =
+		(netdev->features & GENMASK_ULL(63, 32)) >> 32;
+}
+
+static void ena_config_host_attribute(struct ena_adapter *adapter)
+{
+	u32 debug_area_size;
+	int rc, ss_count;
+	ss_count = ena_get_sset_count(adapter->netdev, ETH_SS_STATS);
+	if (ss_count <= 0) {
+		netif_err(adapter, drv, adapter->netdev,
+			  "SS count is negative\n");
+		return;
+	}
+
+	/* allocate 32 bytes for each string and 64bit for the value */
+	debug_area_size = ss_count * ETH_GSTRING_LEN + sizeof(u64) * ss_count;
+
+	rc = ena_com_allocate_host_attribute(adapter->ena_dev,
+					     debug_area_size);
+	if (rc) {
+		netif_err(adapter, drv, adapter->netdev,
+			  "Cannot allocate host attributes\n");
+		return;
+	}
+
+	ena_fill_host_info(adapter);
+
+	rc = ena_com_set_host_attributes(adapter->ena_dev);
+	if (rc) {
+		if (rc == -EPERM)
+			netif_warn(adapter, drv, adapter->netdev,
+				   "Cannot set host attributes\n");
+		else
+			netif_err(adapter, drv, adapter->netdev,
+				  "Cannot set host attributes\n");
+		goto err;
+	}
+
+	return;
+err:
+	ena_com_delete_host_attribute(adapter->ena_dev);
+}
+
 static struct rtnl_link_stats64 *ena_get_stats64(struct net_device *netdev,
 						 struct rtnl_link_stats64 *stats)
 {
@@ -2074,6 +2206,7 @@ static int ena_device_init(struct ena_com_dev *ena_dev, struct pci_dev *pdev,
 			   struct ena_com_dev_get_features_ctx *get_feat_ctx)
 {
 	struct device *dev = &pdev->dev;
+	bool readless_supported;
 	u32 aenq_groups;
 	int dma_width;
 	int rc;
@@ -2084,6 +2217,12 @@ static int ena_device_init(struct ena_com_dev *ena_dev, struct pci_dev *pdev,
 		return rc;
 	}
 
+	/* The PCIe configuration space revision id indicate if mmio reg
+	 * read is disabled
+	 */
+	readless_supported = !(pdev->revision & ENA_MMIO_DISABLE_REG_READ);
+	ena_com_set_mmio_read_mode(ena_dev, readless_supported);
+
 	rc = ena_com_dev_reset(ena_dev);
 	if (rc) {
 		dev_err(dev, "Can not reset device\n");
@@ -2144,14 +2283,15 @@ static int ena_device_init(struct ena_com_dev *ena_dev, struct pci_dev *pdev,
 
 	if (enable_wd) {
 		if (get_feat_ctx->aenq.supported_groups &
-		    BIT(ENA_ADMIN_KEEP_ALIVE)) {
-			aenq_groups |= (1 << ENA_ADMIN_KEEP_ALIVE);
-		} else {
+		    BIT(ENA_ADMIN_KEEP_ALIVE))
+			aenq_groups |= BIT(ENA_ADMIN_KEEP_ALIVE);
+		else
 			enable_wd = 0;
-			dev_err(dev, "Keep alive event isn't supported by the device, disable WD\n");
-		}
 	}
 
+	dev_info(dev, "Device watchdog is %s\n",
+		 enable_wd ? "Enabled" : "Disabled");
+
 	aenq_groups &= get_feat_ctx->aenq.supported_groups;
 	dev_dbg(dev, "enable aenq flags: %x\n", aenq_groups);
 
@@ -2204,15 +2344,19 @@ err_disable_msix:
 	return rc;
 }
 
-static int ena_fw_reset_device(struct ena_adapter *adapter)
+static void ena_fw_reset_device(struct work_struct *work)
 {
 	struct ena_com_dev_get_features_ctx get_feat_ctx;
+	struct ena_adapter *adapter =
+		container_of(work, struct ena_adapter, reset_task);
 	struct net_device *netdev = adapter->netdev;
 	struct ena_com_dev *ena_dev = adapter->ena_dev;
 	struct pci_dev *pdev = adapter->pdev;
 	bool dev_up;
 	int rc;
 
+	del_timer_sync(&adapter->timer_service);
+
 	rtnl_lock();
 
 	dev_up = adapter->up;
@@ -2281,11 +2425,13 @@ static int ena_fw_reset_device(struct ena_adapter *adapter)
 		}
 	}
 
+	mod_timer(&adapter->timer_service, round_jiffies(jiffies + HZ));
+
 	rtnl_unlock();
 
 	dev_err(&pdev->dev, "Device reset completed successfully\n");
 
-	return 0;
+	return;
 
 err_sysfs_terminate:
 	ena_sysfs_terminate(&pdev->dev);
@@ -2299,8 +2445,6 @@ err:
 
 	dev_err(&pdev->dev,
 		"Reset attempt failed. Can not reset the device\n");
-
-	return rc;
 }
 
 static void check_for_missing_tx_completions(struct ena_adapter *adapter)
@@ -2337,6 +2481,11 @@ static void check_for_missing_tx_completions(struct ena_adapter *adapter)
 				missed_tx = tx_ring->tx_stats.missing_tx_comp++;
 				u64_stats_update_end(&tx_ring->syncp);
 
+				/* Clear last jiffies so the lost buffer won't
+				 * be counted twice.
+				 */
+				tx_buf->last_jiffies = 0;
+
 				if (unlikely(missed_tx > MAX_NUM_OF_TIMEOUTED_PACKETS))
 					adapter->trigger_reset = true;
 			}
@@ -2350,50 +2499,58 @@ static void check_for_missing_tx_completions(struct ena_adapter *adapter)
 	adapter->last_monitored_tx_qid = i % adapter->num_queues;
 }
 
-static void ena_timer_service(unsigned long data)
+/* Check for keep alive expiration */
+static void check_for_missing_keep_alive(struct ena_adapter* adapter)
 {
-	struct ena_adapter *adapter = (struct ena_adapter *)data;
 	unsigned long keep_alive_expired;
-	int rc;
 
-	/* Check for keep alive expression */
-	if (enable_wd) {
-		keep_alive_expired = round_jiffies(adapter->last_keep_alive_jiffies +
-						   ENA_DEVICE_KALIVE_TIMEOUT);
-		if (unlikely(time_is_before_jiffies(keep_alive_expired))) {
-			netif_err(adapter, drv, adapter->netdev,
-				  "Watchdog timer expired! Adapter will be reset\n");
+	if (!enable_wd)
+		return;
 
-			u64_stats_update_begin(&adapter->syncp);
-			adapter->dev_stats.wd_expired++;
-			u64_stats_update_end(&adapter->syncp);
-			adapter->trigger_reset = true;
-		}
+	keep_alive_expired = round_jiffies(adapter->last_keep_alive_jiffies
+					   + ENA_DEVICE_KALIVE_TIMEOUT);
+	if (unlikely(time_is_before_jiffies(keep_alive_expired))) {
+		netif_err(adapter, drv, adapter->netdev,
+			  "Keep alive watchdog timeout.\n");
+		u64_stats_update_begin(&adapter->syncp);
+		adapter->dev_stats.wd_expired++;
+		u64_stats_update_end(&adapter->syncp);
+		adapter->trigger_reset = true;
 	}
+}
 
+static void check_for_admin_com_state(struct ena_adapter* adapter)
+{
 	if (unlikely(!ena_com_get_admin_running_state(adapter->ena_dev))) {
 		netif_err(adapter, drv, adapter->netdev,
-			  "ENA admin queue is not in running state! Adapter will be reset\n");
-
+			  "ENA admin queue is not in running state!\n");
 		u64_stats_update_begin(&adapter->syncp);
 		adapter->dev_stats.admin_q_pause++;
 		u64_stats_update_end(&adapter->syncp);
 		adapter->trigger_reset = true;
 	}
+}
+
+static void ena_timer_service(unsigned long data)
+{
+	struct ena_adapter *adapter = (struct ena_adapter *)data;
+	u8 *debug_area = adapter->ena_dev->host_attr.debug_area_virt_addr;
+
+	check_for_missing_keep_alive(adapter);
+
+	check_for_admin_com_state(adapter);
 
 	check_for_missing_tx_completions(adapter);
 
+	if (debug_area)
+		ena_dump_stats_to_buf(adapter, debug_area);
+
 	if (unlikely(adapter->trigger_reset)) {
 		netif_err(adapter, drv, adapter->netdev,
 			  "Trigger reset is on\n");
 		adapter->trigger_reset = false;
 		ena_dump_stats_to_dmesg(adapter);
-		rc = ena_fw_reset_device(adapter);
-		if (rc) {
-			netif_err(adapter, drv, adapter->netdev,
-				  "Failed to reset the device, stopped the timer service\n");
-			return;
-		}
+		schedule_work(&adapter->reset_task);
 	}
 
 	/* Reset the timer */
@@ -2435,17 +2592,12 @@ static int ena_calc_io_queue_num(struct pci_dev *pdev,
 	return io_queue_num;
 }
 
-static int ena_set_push_mode(struct pci_dev *pdev, struct ena_com_dev *ena_dev,
-			     struct ena_com_dev_get_features_ctx *get_feat_ctx)
+static int ena_set_push_mode(struct pci_dev *pdev, struct ena_com_dev *ena_dev)
 {
-	bool has_mem_bar;
-
-	has_mem_bar = pci_select_bars(pdev, IORESOURCE_MEM) & BIT(ENA_MEM_BAR);
-
 	switch (push_mode) {
 	case 0:
 		/* Enable push mode if device supports LLQ */
-		if (has_mem_bar && get_feat_ctx->max_queues.max_llq_num > 0)
+		if (pdev->device == PCI_DEV_ID_ENA_LLQ_VF)
 			ena_dev->tx_mem_queue_type =
 				ENA_ADMIN_PLACEMENT_POLICY_DEV;
 		else
@@ -2456,7 +2608,7 @@ static int ena_set_push_mode(struct pci_dev *pdev, struct ena_com_dev *ena_dev,
 		ena_dev->tx_mem_queue_type = ENA_ADMIN_PLACEMENT_POLICY_HOST;
 		break;
 	case ENA_ADMIN_PLACEMENT_POLICY_DEV:
-		if (!has_mem_bar || get_feat_ctx->max_queues.max_llq_num == 0)
+		if (pdev->device != PCI_DEV_ID_ENA_LLQ_VF)
 			return -1;
 		ena_dev->tx_mem_queue_type = ENA_ADMIN_PLACEMENT_POLICY_DEV;
 		break;
@@ -2490,21 +2642,19 @@ static void ena_set_dev_offloads(struct ena_com_dev_get_features_ctx *feat,
 	if (feat->offload.tx & ENA_ADMIN_FEATURE_OFFLOAD_DESC_TSO_ECN_MASK)
 		dev_features |= NETIF_F_TSO_ECN;
 
-	if (feat->offload.tx &
+	if (feat->offload.rx_supported &
 		ENA_ADMIN_FEATURE_OFFLOAD_DESC_RX_L4_IPV4_CSUM_MASK)
 		dev_features |= NETIF_F_RXCSUM;
 
-	if (feat->offload.tx &
+	if (feat->offload.rx_supported &
 		ENA_ADMIN_FEATURE_OFFLOAD_DESC_RX_L4_IPV6_CSUM_MASK)
 		dev_features |= NETIF_F_RXCSUM;
 
-	if (feat->offload.rx_supported &
-	    ENA_ADMIN_FEATURE_OFFLOAD_DESC_RX_HASH_MASK)
-		dev_features |= NETIF_F_RXHASH;
-
 	netdev->features =
 		dev_features |
 		NETIF_F_SG |
+		NETIF_F_NTUPLE |
+		NETIF_F_RXHASH |
 		NETIF_F_HIGHDMA;
 
 	netdev->hw_features |= netdev->features;
@@ -2579,7 +2729,10 @@ static void ena_release_bars(struct ena_com_dev *ena_dev, struct pci_dev *pdev)
 {
 	int release_bars;
 
-	release_bars = pci_select_bars(pdev, IORESOURCE_MEM) & ENA_BAR_MASK;
+	release_bars = (1 << ENA_REG_BAR);
+	if (ena_dev->tx_mem_queue_type == ENA_ADMIN_PLACEMENT_POLICY_DEV)
+		release_bars |= (1 << ENA_MEM_BAR);
+
 	pci_release_selected_regions(pdev, release_bars);
 }
 
@@ -2602,7 +2755,7 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	struct ena_com_dev *ena_dev = NULL;
 	static int adapters_found;
 	int io_queue_num;
-	int bars;
+	int regions;
 	int rc;
 
 	dev_dbg(&pdev->dev, "%s\n", __func__);
@@ -2619,15 +2772,23 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	pci_set_master(pdev);
 	pci_save_state(pdev);
 
-	ena_dev = devm_kzalloc(&pdev->dev, sizeof(struct ena_com_dev),
-			       GFP_KERNEL);
+	ena_dev = vzalloc(sizeof(struct ena_com_dev));
 	if (!ena_dev) {
 		rc = -ENOMEM;
 		goto err_disable_device;
 	}
 
-	bars = pci_select_bars(pdev, IORESOURCE_MEM) & ENA_BAR_MASK;
-	rc = pci_request_selected_regions(pdev, bars, DRV_MODULE_NAME);
+	rc = ena_set_push_mode(pdev, ena_dev);
+	if (rc) {
+		dev_err(&pdev->dev, "Invalid module param(push_mode)\n");
+		goto err_free_ena_dev;
+	}
+
+	regions = (1 << ENA_REG_BAR);
+	if (ena_dev->tx_mem_queue_type == ENA_ADMIN_PLACEMENT_POLICY_DEV)
+		regions |= (1 << ENA_MEM_BAR);
+
+	rc = pci_request_selected_regions(pdev, regions, DRV_MODULE_NAME);
 	if (rc) {
 		dev_err(&pdev->dev, "pci_request_selected_regions failed %d\n",
 			rc);
@@ -2642,32 +2803,32 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 		goto err_free_region;
 	}
 
-	ena_dev->dmadev = &pdev->dev;
-
-	rc = ena_device_init(ena_dev, pdev, &get_feat_ctx);
-	if (rc) {
-		dev_err(&pdev->dev, "ena device init failed\n");
-		goto err_free_region;
-	}
-
-	rc = ena_set_push_mode(pdev, ena_dev, &get_feat_ctx);
-	if (rc) {
-		dev_err(&pdev->dev, "Invalid module param(push_mode)\n");
-		goto err_device_destroy;
-	}
-
 	if (ena_dev->tx_mem_queue_type == ENA_ADMIN_PLACEMENT_POLICY_DEV) {
 		ena_dev->mem_bar = ioremap_wc(pci_resource_start(pdev, ENA_MEM_BAR),
 					      pci_resource_len(pdev, ENA_MEM_BAR));
 		if (!ena_dev->mem_bar) {
 			rc = -EFAULT;
-			goto err_device_destroy;
+			goto err_free_region;
 		}
 	}
 
 	dev_info(&pdev->dev, "mapped bars to %p %p", ena_dev->reg_bar,
 		 ena_dev->mem_bar);
 
+	ena_dev->dmadev = &pdev->dev;
+
+	/* initial Tx interrupt delay, Assumes 1 usec granularity.
+	* Updated during device initialization with the real granularity
+	*/
+	ena_dev->intr_moder_tx_interval = ENA_INTR_INITIAL_TX_INTERVAL_USECS;
+	rc = ena_device_init(ena_dev, pdev, &get_feat_ctx);
+	if (rc) {
+		dev_err(&pdev->dev, "ena device init failed\n");
+		if (rc == -ETIME)
+			rc = -EPROBE_DEFER;
+		goto err_free_region;
+	}
+
 	io_queue_num = ena_calc_io_queue_num(pdev, ena_dev, &get_feat_ctx);
 	dev_info(&pdev->dev, "creating %d io queues\n", io_queue_num);
 
@@ -2703,6 +2864,12 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 
 	snprintf(adapter->name, ENA_NAME_MAX_LEN, "ena_%d", adapters_found);
 
+	rc = ena_com_init_intrrupt_moderation(adapter->ena_dev);
+	if (rc) {
+		dev_err(&pdev->dev,
+			"Failed to query interrupt moderation feature\n");
+		goto err_netdev_destroy;
+	}
 	ena_init_io_rings(adapter);
 
 	netdev->netdev_ops = &ena_netdev_ops;
@@ -2722,6 +2889,7 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 
 	INIT_WORK(&adapter->suspend_io_task, ena_device_io_suspend);
 	INIT_WORK(&adapter->resume_io_task, ena_device_io_resume);
+	INIT_WORK(&adapter->reset_task, ena_fw_reset_device);
 
 	rc = ena_enable_msix_and_set_admin_interrupts(adapter, io_queue_num);
 	if (rc) {
@@ -2742,6 +2910,8 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 		goto err_terminate_sysfs;
 	}
 
+	ena_config_host_attribute(adapter);
+
 	memcpy(adapter->netdev->perm_addr, adapter->mac_addr, netdev->addr_len);
 
 	rc = register_netdev(netdev);
@@ -2759,6 +2929,7 @@ static int ena_probe(struct pci_dev *pdev, const struct pci_device_id *ent)
 	return 0;
 
 err_rss:
+	ena_com_delete_host_attribute(ena_dev);
 	ena_com_rss_destroy(ena_dev);
 err_terminate_sysfs:
 	ena_sysfs_terminate(&pdev->dev);
@@ -2767,9 +2938,11 @@ err_free_msix:
 	ena_free_mgmnt_irq(adapter);
 	ena_disable_msix(adapter);
 err_worker_destroy:
+	ena_com_destroy_interrupt_moderation(ena_dev);
 	del_timer(&adapter->timer_service);
 	cancel_work_sync(&adapter->suspend_io_task);
 	cancel_work_sync(&adapter->resume_io_task);
+err_netdev_destroy:
 	free_netdev(netdev);
 err_device_destroy:
 	ena_com_admin_destroy(ena_dev);
@@ -2777,7 +2950,7 @@ err_free_region:
 	ena_release_bars(ena_dev, pdev);
 err_free_ena_dev:
 	pci_set_drvdata(pdev, NULL);
-	devm_kfree(&pdev->dev, ena_dev);
+	vfree(ena_dev);
 err_disable_device:
 	pci_disable_device(pdev);
 	return rc;
@@ -2840,6 +3013,8 @@ static void ena_remove(struct pci_dev *pdev)
 
 	del_timer_sync(&adapter->timer_service);
 
+	cancel_work_sync(&adapter->reset_task);
+
 	cancel_work_sync(&adapter->suspend_io_task);
 
 	cancel_work_sync(&adapter->resume_io_task);
@@ -2862,11 +3037,15 @@ static void ena_remove(struct pci_dev *pdev)
 
 	ena_com_rss_destroy(ena_dev);
 
+	ena_com_delete_host_attribute(ena_dev);
+
 	pci_set_drvdata(pdev, NULL);
 
 	pci_disable_device(pdev);
 
-	devm_kfree(&pdev->dev, ena_dev);
+	ena_com_destroy_interrupt_moderation(ena_dev);
+
+	vfree(ena_dev);
 }
 
 static struct pci_driver ena_pci_driver = {
diff --git a/drivers/amazon/ena/ena_netdev.h b/drivers/amazon/ena/ena_netdev.h
index fdb050b..92e4e80 100644
--- a/drivers/amazon/ena/ena_netdev.h
+++ b/drivers/amazon/ena/ena_netdev.h
@@ -33,7 +33,6 @@
 #ifndef ENA_H
 #define ENA_H
 
-#include <linux/bitops.h>
 #include <linux/etherdevice.h>
 #include <linux/inetdevice.h>
 #include <linux/interrupt.h>
@@ -43,11 +42,18 @@
 #include "ena_com.h"
 #include "ena_eth_com.h"
 
+#define DRV_MODULE_VER_MAJOR	0
+#define DRV_MODULE_VER_MINOR	4
+#define DRV_MODULE_VER_SUBMINOR	0
+
 #define DRV_MODULE_NAME		"ena"
 #ifndef DRV_MODULE_VERSION
-#define DRV_MODULE_VERSION      "0.3"
+#define DRV_MODULE_VERSION \
+	__stringify(DRV_MODULE_VER_MAJOR) "."	\
+	__stringify(DRV_MODULE_VER_MINOR) "."	\
+	__stringify(DRV_MODULE_VER_SUBMINOR)
 #endif
-#define DRV_MODULE_RELDATE      "2015-10-14"
+#define DRV_MODULE_RELDATE      "2016-02-15"
 
 #define DEVICE_NAME	"Elastic Network Adapter (ENA)"
 
@@ -56,7 +62,6 @@
 
 #define ENA_REG_BAR			0
 #define ENA_MEM_BAR			2
-#define ENA_BAR_MASK (BIT(ENA_REG_BAR) | BIT(ENA_MEM_BAR))
 
 #define ENA_DEFAULT_TX_DESCS	(1024)
 #define ENA_DEFAULT_RX_DESCS	(1024)
@@ -119,6 +124,8 @@
  */
 #define ENA_DEVICE_KALIVE_TIMEOUT	(3 * HZ)
 
+#define ENA_MMIO_DISABLE_REG_READ	BIT(0)
+
 struct ena_irq {
 	irq_handler_t handler;
 	void *data;
@@ -172,6 +179,7 @@ struct ena_stats_tx {
 	u64 tx_poll;
 	u64 doorbells;
 	u64 missing_tx_comp;
+	u64 bad_req_id;
 };
 
 struct ena_stats_rx {
@@ -199,6 +207,7 @@ struct ena_ring {
 	struct pci_dev *pdev;
 	struct napi_struct *napi;
 	struct net_device *netdev;
+	struct ena_com_dev *ena_dev;
 	struct ena_adapter *adapter;
 	struct ena_com_io_cq *ena_com_io_cq;
 	struct ena_com_io_sq *ena_com_io_sq;
@@ -214,7 +223,10 @@ struct ena_ring {
 	enum ena_admin_placement_policy_type tx_mem_queue_type;
 
 	struct ena_com_rx_buf_info ena_bufs[ENA_PKT_MAX_BUFS];
-
+	u32  smoothed_interval;
+	u32  per_napi_packets;
+	u32  per_napi_bytes;
+	enum ena_intr_moder_level moder_tbl_idx;
 	struct u64_stats_sync syncp;
 	union {
 		struct ena_stats_tx tx_stats;
@@ -281,6 +293,7 @@ struct ena_adapter {
 	struct ena_irq irq_tbl[ENA_MAX_MSIX_VEC(ENA_MAX_NUM_IO_QUEUES)];
 
 	/* timer service */
+	struct work_struct reset_task;
 	struct work_struct suspend_io_task;
 	struct work_struct resume_io_task;
 	struct timer_list timer_service;
@@ -298,4 +311,8 @@ void ena_set_ethtool_ops(struct net_device *netdev);
 
 void ena_dump_stats_to_dmesg(struct ena_adapter *adapter);
 
+void ena_dump_stats_to_buf(struct ena_adapter *adapter, u8 *buf);
+
+int ena_get_sset_count(struct net_device *netdev, int sset);
+
 #endif /* !(ENA_H) */
diff --git a/drivers/amazon/ena/ena_sysfs.c b/drivers/amazon/ena/ena_sysfs.c
index 797ab8f..75f3878 100644
--- a/drivers/amazon/ena/ena_sysfs.c
+++ b/drivers/amazon/ena/ena_sysfs.c
@@ -39,6 +39,7 @@
 #include "ena_netdev.h"
 #include "ena_sysfs.h"
 
+#define to_ext_attr(x) container_of(x, struct dev_ext_attribute, attr)
 static int ena_validate_small_copy_len(struct ena_adapter *adapter,
 				       unsigned long len)
 {
@@ -91,12 +92,163 @@ static struct device_attribute dev_attr_small_copy_len = {
 	.store = ena_store_small_copy_len,
 };
 
+
+/* adaptive interrupt moderation */
+
+static ssize_t ena_show_intr_moderation(struct device *dev,
+					struct device_attribute *attr,
+					char *buf)
+{
+	struct ena_intr_moder_entry entry;
+	struct dev_ext_attribute *ea = to_ext_attr(attr);
+	enum ena_intr_moder_level level = (enum ena_intr_moder_level)ea->var;
+	struct ena_adapter *adapter = dev_get_drvdata(dev);
+	ssize_t rc = 0;
+
+	ena_com_get_intr_moderation_entry(adapter->ena_dev, level, &entry);
+
+	rc = sprintf(buf, "%u %u %u\n",
+		     entry.intr_moder_interval,
+		     entry.pkts_per_interval,
+		     entry.bytes_per_interval);
+
+	return rc;
+}
+
+static ssize_t ena_store_intr_moderation(struct device *dev,
+					 struct device_attribute *attr,
+					 const char *buf,
+					 size_t count)
+{
+	struct ena_intr_moder_entry entry;
+	struct dev_ext_attribute *ea = to_ext_attr(attr);
+	struct ena_adapter *adapter = dev_get_drvdata(dev);
+	enum ena_intr_moder_level level = (enum ena_intr_moder_level)ea->var;
+	int cnt;
+
+	cnt = sscanf(buf, "%u %u %u",
+		     &entry.intr_moder_interval,
+		     &entry.pkts_per_interval,
+		     &entry.bytes_per_interval);
+
+	if (cnt != 3)
+		return -EINVAL;
+
+	ena_com_init_intr_moderation_entry(adapter->ena_dev, level, &entry);
+
+	return count;
+}
+
+static ssize_t ena_store_intr_moderation_restore_default(struct device *dev,
+							 struct device_attribute *attr,
+							 const char *buf,
+							 size_t len)
+{
+	struct ena_adapter *adapter = dev_get_drvdata(dev);
+	struct ena_com_dev *ena_dev = adapter->ena_dev;
+	unsigned long restore_default;
+	int err;
+
+	err = kstrtoul(buf, 10, &restore_default);
+	if (err < 0)
+		return err;
+
+	if (ena_com_interrupt_moderation_supported(ena_dev) && restore_default) {
+		ena_com_config_default_interrupt_moderation_table(ena_dev);
+		ena_com_set_adaptive_moderation_state(ena_dev, true);
+	}
+
+	return len;
+}
+
+static ssize_t ena_store_enable_adaptive_intr_moderation(struct device *dev,
+							 struct device_attribute *attr,
+							 const char *buf,
+							 size_t len)
+{
+	struct ena_adapter *adapter = dev_get_drvdata(dev);
+	unsigned long enable_moderation;
+	bool state;
+	int err;
+
+	err = kstrtoul(buf, 10, &enable_moderation);
+	if (err < 0)
+		return err;
+
+	if ((state != 0) || (state != 1))
+		return -1;
+
+	ena_com_set_adaptive_moderation_state(adapter->ena_dev, state);
+
+	return len;
+}
+
+static ssize_t ena_show_enable_adaptive_intr_moderation(struct device *dev,
+				       struct device_attribute *attr, char *buf)
+{
+	struct ena_adapter *adapter = dev_get_drvdata(dev);
+
+	return sprintf(buf, "%d\n",
+		       ena_com_get_adaptive_moderation_state(adapter->ena_dev));
+}
+
+static struct device_attribute dev_attr_enable_adaptive_intr_moderation = {
+	.attr = {.name = "enable_adaptive_intr_moderation", .mode = (S_IRUGO | S_IWUSR)},
+	.show = ena_show_enable_adaptive_intr_moderation,
+	.store = ena_store_enable_adaptive_intr_moderation,
+};
+static struct device_attribute dev_attr_intr_moderation_restore_default = {
+	.attr = {.name = "intr_moderation_restore_default", .mode = (S_IWUSR | S_IWGRP)},
+	.show = NULL,
+	.store = ena_store_intr_moderation_restore_default,
+};
+
+
+#define INTR_MODERATION_PREPARE_ATTR(_name, _type) {			\
+	__ATTR(intr_moderation_##_name, (S_IRUGO | S_IWUSR | S_IWGRP),	\
+		ena_show_intr_moderation, ena_store_intr_moderation), \
+		(void *)_type }
+
+/* Device attrs - intr moderation */
+static struct dev_ext_attribute dev_attr_intr_moderation[] = {
+	INTR_MODERATION_PREPARE_ATTR(lowest, ENA_INTR_MODER_LOWEST),
+	INTR_MODERATION_PREPARE_ATTR(low, ENA_INTR_MODER_LOW),
+	INTR_MODERATION_PREPARE_ATTR(mid, ENA_INTR_MODER_MID),
+	INTR_MODERATION_PREPARE_ATTR(high, ENA_INTR_MODER_HIGH),
+	INTR_MODERATION_PREPARE_ATTR(highest, ENA_INTR_MODER_HIGHEST),
+};
+
 /******************************************************************************
  *****************************************************************************/
 int ena_sysfs_init(struct device *dev)
 {
+	int i, rc;
+	struct ena_adapter *adapter = dev_get_drvdata(dev);
 	if (device_create_file(dev, &dev_attr_small_copy_len))
-		dev_info(dev, "failed to create small_copy_len sysfs entry");
+		dev_err(dev, "failed to create small_copy_len sysfs entry");
+
+	if (ena_com_interrupt_moderation_supported(adapter->ena_dev)) {
+		if (device_create_file(dev,
+				       &dev_attr_intr_moderation_restore_default))
+			dev_err(dev,
+				"failed to create intr_moderation_restore_default");
+
+		if (device_create_file(dev,
+				       &dev_attr_enable_adaptive_intr_moderation))
+			dev_err(dev,
+				"failed to create adaptive_intr_moderation_enable");
+
+		for (i = 0; i < ARRAY_SIZE(dev_attr_intr_moderation); i++) {
+			rc = sysfs_create_file(&dev->kobj,
+					       &dev_attr_intr_moderation[i].attr.attr);
+			if (rc) {
+				dev_err(dev,
+					"%s: sysfs_create_file(intr_moderation %d) failed\n",
+					__func__, i);
+				return rc;
+			}
+		}
+	}
 
 	return 0;
 }
@@ -105,5 +257,16 @@ int ena_sysfs_init(struct device *dev)
  *****************************************************************************/
 void ena_sysfs_terminate(struct device *dev)
 {
+	struct ena_adapter *adapter = dev_get_drvdata(dev);
+	int i;
 	device_remove_file(dev, &dev_attr_small_copy_len);
+	if (ena_com_interrupt_moderation_supported(adapter->ena_dev)) {
+		for (i = 0; i < ARRAY_SIZE(dev_attr_intr_moderation); i++)
+			sysfs_remove_file(&dev->kobj,
+					  &dev_attr_intr_moderation[i].attr.attr);
+		device_remove_file(dev,
+				   &dev_attr_enable_adaptive_intr_moderation);
+		device_remove_file(dev,
+				   &dev_attr_intr_moderation_restore_default);
+	}
 }
-- 
2.7.4

